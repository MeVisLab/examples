[{"date":"1674259200","url":"https://mevislab.github.io/examples/tutorials/summary/summary7/","title":"Step 7: Refine - Re-Build Installer","summary":"Step 7: Refine - Re-Build Installer Introduction In this step you are re-creating your application installer after changing the UI in previous Step 6: Refine - Update Application.\nSteps to do Update the *.mlinstall file You do not need to use the Project Wizard now, because you already have a valid *.mlinstall file. The location should be in your package, under .\\Configuration\\Installers\\TutorialSummary. Open the file in any text editor and search for the $VERSION 0.","content":"Step 7: Refine - Re-Build Installer Introduction In this step you are re-creating your application installer after changing the UI in previous Step 6: Refine - Update Application.\nSteps to do Update the *.mlinstall file You do not need to use the Project Wizard now, because you already have a valid *.mlinstall file. The location should be in your package, under .\\Configuration\\Installers\\TutorialSummary. Open the file in any text editor and search for the $VERSION 0.5. Change the version to something else, in our case we now have our first major release 1.0.\nInfo:\u0026nbsp; You can also run the Project Wizard again but keep in mind that manual changes on your *.mlinstall file might be overwritten. The wizard re-creates your *.mlinstall file whereas the ToolRunner just uses it. Use MeVisLab ToolRunner Save the file and open MeVisLab ToolRunner.\nMeVisLab ToolRunner Open the *.mlinstall file in ToolRunner and select the file. Click Run on Selection.\nRun on Selection The ToolRunner automatically builds your new installer using version 1.0.\nInstall application again Execute your installable executable again. You do not have to uninstall previous version(s) of your application first. Already existing applications will be replaced by new installation - at least if you select the same target directory.\nInstall new version The installer already shows your updated version 1.0. It is not necessary to select your Runtime license again because it has not been touched during update.\nApplication version 1.0 The new installed application now provides your new UI element for defining the alpha value of the overlay.\nSummary Updates of your application installer can be applied by using the MeVisLab ToolRunner The executable can be updated on your customers system(s) and your changes on the Macro Module and network(s) are applied ","tags":["Advanced","Tutorial","Prototyping","Tool Runner","Installer"],"section":"tutorials"},{"date":"1674172800","url":"https://mevislab.github.io/examples/tutorials/summary/summary6/","title":"Step 6: Refine - Update Application","summary":"Step 6: Refine - Update Application Introduction In previous step you developed an application which can be installed on your customers systems for usage. In this step we are going to integrate simple feedback into our executable and re-create the installer.\nWe want to show you how easy it is to update your application using MeVisLab.\nYour customer requests an additional requirement to define the transparency of your 2D overlay in addition to defining the color.","content":"Step 6: Refine - Update Application Introduction In previous step you developed an application which can be installed on your customers systems for usage. In this step we are going to integrate simple feedback into our executable and re-create the installer.\nWe want to show you how easy it is to update your application using MeVisLab.\nYour customer requests an additional requirement to define the transparency of your 2D overlay in addition to defining the color.\nRequirement 5.2: It shall be possible to define the alpha value of the overlay Steps to do Adapt your Macro Module Use the module search to add your Macro Module to your workspace. We need an additional UI element for setting the alpha value of the overlay.\nRight-click your module and select [ Related Files \u0026rarr; \u0026lt;MACRO_NAME\u0026gt;.script ].\nIn MATE, add another field to your Parameters section and re-use the field by setting the internalName. Add the field to the Settings section of your Window, maybe directly after the color selection.\n\u0026lt;MACRO_NAME\u0026gt;.script\nInterface { ... Parameters { ... Field selectOverlayTransparency { internalName = SoView2DOverlay.alphaFactor } ... } } Window { ... Box Settings { ... Field selectOverlayTransparency { title = Alpha } ... } ... } Back in MeVisLab IDE, your user interface should now provide the possibility to define an alpha value of the overlay. Changes are applied automatically because you re-used the field of the SoView2DOverlay module directly.\nUpdated User Interface You can also update your Python files for new or updated requirements. In this example we just want to show the basic principles, therefore we only add this new element to the Script file.\nIf you want to write an additional Python test case, you can also do that.\nSummary Your application can be updated by modifying the Macro Module and/or internal network of your application Any changes will be applied to your installable executable in the next step \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Prototyping"],"section":"tutorials"},{"date":"1674086400","url":"https://mevislab.github.io/examples/tutorials/summary/summary5/","title":"Step 5: Review - Installer creation","summary":"Step 5: Review - Installer creation Introduction Your Macro Module has been tested manually and/or automatically? Then you should create your first installable executable and deliver it to your customer(s) for final evaluation.\nLicensing:\u0026nbsp; This step requires a valid MeVisLab ApplicationBuilder license. It extends the MeVisLab SDK so that you can generate an installer of your developed Macro Module. Free evaluation licenses of the MeVisLab ApplicationBuilder, time-limited to 3 months, can be requested at sales(at)mevislab.","content":"Step 5: Review - Installer creation Introduction Your Macro Module has been tested manually and/or automatically? Then you should create your first installable executable and deliver it to your customer(s) for final evaluation.\nLicensing:\u0026nbsp; This step requires a valid MeVisLab ApplicationBuilder license. It extends the MeVisLab SDK so that you can generate an installer of your developed Macro Module. Free evaluation licenses of the MeVisLab ApplicationBuilder, time-limited to 3 months, can be requested at sales(at)mevislab.de. Steps to do Install tools necessary for installer generation The MeVisLab Project Wizard for Standalone Applications [ File \u0026rarr; Run Project Wizard... \u0026rarr; Standalone Application ] provides a check for all necessary tools you need to install before generating an installer.\nMeVisLab Project Wizard Click on Check if required tools are installed. The following dialog opens:\nCheck required tools You can see that NSIS and either Dependency Walker or Dependencies are necessary to create an installable executable. MeVisLab provides information about the necessary version(s).\nDownload and install/extract NSIS and Dependency Walker or Dependencies. Add both executables to your PATH environment variable, for example C:\\Program Files\\depends and C:\\Program Files (x86)\\NSIS.\nRestart MeVisLab and open Project Wizard again. All required tools should now be available.\nUse MeVisLab Project Wizard to generate the installer Select your Macro Module and the package and click Next.\nWelcome The general settings dialog allows you to define a name for your application. You can also define a version, in our case we decide not to be finished and have a version 0.5. You can include debug files and decide to build a desktop or web application. We want to build an Application Installer for a desktop system. You can decide to precompile your Python files and you have to select your MeVisLab MeVisLab ApplicationBuilder license.\nGeneral Settings Define your license text which is shown during installation of your executable. You can decide to use our pre-defined text, select a custom file or do not include any license text.\nLicense Text The next dialog can be skipped for now, you can include additional files into your installer which are not automatically added by MeVisLab from the dependency analysis.\nManual File Lists Define how the window of your application shall look.\nApplication Options Skip the next dialog, we do not need additional installer options.\nInstaller Options The MeVisLab ToolRunner starts generating your installer. After finishing installer generation, you will find a link to the target directory.\nMeVisLab ToolRunner The directory contains the following files (and some more maybe):\nBatch (*.bat) file Installer (*.exe) file MeVisLab Install (*.mlinstall) file Shell (*.sh) script ThirdParty list (*.csv) Batch file The batch file allows you to generate the executable again via a Windows batch file. You do not need the Project Wizard anymore now.\nInstaller file The resulting installer file for your application is an executable\nMeVisLab Install file The *.mlinstall file provides all information you just entered into the wizard. We will need this in Step 7: Refine - Re-Build Installer again.\nThe file is initially generated by the Project Wizard. Having a valid file already, you can create new versions by using the MeVisLab ToolRunner.\nShell skript The shell skript allows you to generate the executable again via a Unix shell like bash. You do not need the Project Wizard anymore now.\nThirdParty file The third party file contains all third party software tools MeVisLab integrated into your installer from dependency analysis. The file contains the tool name, version, license and general information about the tool.\nInstall your executable You can now execute the installer of your application.\nThe installer initially shows a welcome screen showing the name and version of your application.\nInstaller Next, you will see your selected license agreement from the project wizard and a selection to install for anyone or just for the current user.\nLicense Agreement You can also select to create shortcuts and desktop icons.\nShortcuts and icons The last step is to select the target directory for your application.\nTarget directory After the installer finished the setup, you will find a desktop icon and a start menu entry for your application.\nStartmenu Desktop Licensing:\u0026nbsp; MeVisLab executables require an additional MeVisLab Runtime license. It makes sure that your resulting application needs to be licensed, too. Free evaluation licenses of the MeVisLab ApplicationBuilder and MeVisLab Runtime licenses for testing purposes can be requested at sales(at)mevislab.de. Runtime License After entering your license file, the application runs and you can use it on a customer system.\nInstalled Application Info:\u0026nbsp; By default, your user interface uses a standard stylesheet for colors and appearance of your user interface elements. The style can be customized easily. Summary The MeVisLab ApplicationBuilder allows you to create installable executables from your MeVisLab networks The resulting application can be customized to your needs via Project Wizard Your application will be licensed separately so that you can completely control the usage ","tags":["Advanced","Tutorial","Prototyping","Application Builder","Installer"],"section":"tutorials"},{"date":"1674000000","url":"https://mevislab.github.io/examples/tutorials/summary/summary4/","title":"Step 4: Review - Automated Tests","summary":"Step 4: Review - Automated Tests Introduction In the previous chapters you developed a Macro Module with User Interface and Python scripting. In this step you will see how to implement an automated test to verify and validate the Requirements defined in Overview.\nSteps to do Create a test network using your Macro Module Create a new and empty network and save it as *.mlab file. Remember the location.\nUse Module Search and add your Macro Module developed in previous steps to your Workspace.","content":"Step 4: Review - Automated Tests Introduction In the previous chapters you developed a Macro Module with User Interface and Python scripting. In this step you will see how to implement an automated test to verify and validate the Requirements defined in Overview.\nSteps to do Create a test network using your Macro Module Create a new and empty network and save it as *.mlab file. Remember the location.\nUse Module Search and add your Macro Module developed in previous steps to your Workspace.\nMacro Module You can see that the module does not have any inputs or outputs. You cannot connect it to other modules. For testing purposes it makes sense to provide the viewers and images as outputs so that you can use them for generating screenshots.\nOpen the *.script file in MATE as already explained in Step 3. In the Outputs section, add the following:\n\u0026lt;MACRO_NAME\u0026gt;.script\nInterface { Inputs {} Outputs { Field out2D { internalName = LocalImage.outImage } Field out3D { internalName = SoSwitch.self } Field outSegmentationMask { internalName = CloseGap.output0 } } ... } Macro Module with outputs You can now add a viewer or any other module to your Macro Module and use them for testing. In our example, we add a CalculateVolume module to the segmentation mask and a SoCameraInteraction with two OffscreenRenderer modules to the 3D output. In the end, we need an ImageCompare module to compare expected and real image in our test.\nTest Network Create test case Open MeVisLab TestCaseManager via [ File \u0026rarr; Run TestCaseManager... ]. On tab Test Creation define a name of your test case, for example TutorialSummaryTest. Select Type as Macros, define the package and use the same as for your Macro Module, select Import Network and Select your saved *.mlab file from the step above. Click Create.\nTest Creation MATE automatically opens the Python file of your test case and it appears in MeVisLab TestCaseManager.\nTest Creation Write test functions in Python Preparations Before writing a test case, we need some helper functions in Python, which we will use in our test cases. The first thing we need is a function to load images.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\nfrom mevis import * from TestSupport import Base, Fields, Logging, ScreenShot from TestSupport.Macros import * path_to_image = \u0026#34;$(DemoDataPath)/BrainMultiModal/ProbandT1.dcm\u0026#34; marker_location = [-29, -26, 45] marker_location_new = [-20, -30, 35] new_color = [0.5, 0.5, 0] def loadImage(full_path): MLAB.log(\u0026#34;Setting image path to \u0026#39;\u0026#34; + full_path + \u0026#34;\u0026#39;...\u0026#34;) ctx.field(\u0026#34;TutorialSummary.openFile\u0026#34;).value = full_path We define the path to a file to be loaded. The function loadImage sets the openFile field of the TutorialSummary module.\nThe arrays for the marker location and color will be used later.\nNext we need a function to check if the loaded image available at the first output of our Macro Module (out2D) is valid.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... def isImageValid(): MLAB.log(\u0026#34;Checking if image is valid...\u0026#34;) data_valid = ctx.field(\u0026#34;TutorialSummary.out2D\u0026#34;).isValid() if data_valid: return True else: return False ... We also need to set a marker in our Macro Module.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... def setMarkerPosition(vector): MLAB.log(\u0026#34;Setting marker position to [\u0026#34; + str(vector[0]) + \u0026#34;,\u0026#34; + str(vector[1]) + \u0026#34;,\u0026#34; + str(vector[2]) + \u0026#34;]...\u0026#34;) ctx.field(\u0026#34;TutorialSummary.markerPosition\u0026#34;).setValue(vector[0], vector[1], vector[2]) ctx.field(\u0026#34;TutorialSummary.applyMarker\u0026#34;).touch() MLAB.processEvents() while not ctx.field(\u0026#34;TutorialSummary.outSegmentationMask\u0026#34;).isValid(): MLAB.msleep(100) MLAB.processEvents() MLAB.log(\u0026#34;Marker position set to \u0026#39;\u0026#34; + str(ctx.field(\u0026#34;TutorialSummary.markerPosition\u0026#34;).value) + \u0026#34;\u0026#39;...\u0026#34;) ... The setMarkerPosition function gets a 3-dimensional vector and sets the markerPosition field of our module. Then the applyMarker trigger is touched. As the region growing algorithm might need some time to segment, we need to wait until the outSegmentationMask output field is valid, meaning that there is a valid segmentation mask at the segmentation mask output of our Macro Module.\nFinally, we need to reset the application to its initial state, so that each test case has the initial start conditions of the application. A test case should never depend on another test case so that they all can be executed exclusively.\nExample: Having one test case for the requirement to load images and one for setting the marker depending on the image to be loaded by the previous test case, you will never be able to execute the marker test case without executing the load image first.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... def reset(): MLAB.log(\u0026#34;Resetting application...\u0026#34;) ctx.field(\u0026#34;TutorialSummary.resetApplication\u0026#34;).touch() ... For a reset, we just touch the resetApplication field of our Macro Module TutorialSummary.\nRequirement 1: The application shall be able to load DICOM data The first requirement we want to test is the possibility to load DICOM data. After setting the file to be loaded, the output provides a valid image. Resetting the application shall unload the image.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... # Requirement 1: The application shall be able to load DICOM data def TEST_LoadDICOMData(): # Set path to image and expect a valid image loadImage(path_to_image) ASSERT_TRUE(isImageValid()) # Reset again and expect an invalid image reset() ASSERT_FALSE(isImageValid()) ... Requirement 4: The 2D viewer shall provide the possibility to segment parts of the image based on a RegionGrowing algorithm Requirement 4.1: It shall be possible to click into the image for defining a marker position for starting the RegionGrowing This test case shall make sure the RegionGrowing module calculates the total volume and number of voxels to be larger than 0 in case a marker has been set. Without loading an image or after resetting the application, the values shall be 0.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... # Requirement 4: The 2D viewer shall provide the possibility to segment parts of the image based on a RegionGrowing algorithm # Requirement 4.1: It shall be possible to click into the image for defining a marker position for starting the RegionGrowing def TEST_RegionGrowing(): # Load image and expect volumes and voxels without marker to be 0 loadImage(path_to_image) region_growing_voxels = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.numSegmentedVoxels\u0026#34;).value region_growing_volume = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.segmentedVolume_ml\u0026#34;).value ASSERT_EQ(region_growing_voxels, 0) ASSERT_EQ(region_growing_volume, 0) # Set marker and expect volumes and voxels to be larger than 0 setMarkerPosition(marker_location) region_growing_voxels = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.numSegmentedVoxels\u0026#34;).value region_growing_volume = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.segmentedVolume_ml\u0026#34;).value ASSERT_GT(region_growing_voxels, 0) ASSERT_GT(region_growing_volume, 0) # Reset application and expect volumes and voxels to be 0 again reset() region_growing_voxels = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.numSegmentedVoxels\u0026#34;).value region_growing_volume = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.segmentedVolume_ml\u0026#34;).value ASSERT_EQ(region_growing_voxels, 0) ASSERT_EQ(region_growing_volume, 0) ... Requirement 4.2: It shall be possible to define a threshold for the RegionGrowing algorithm For the threshold of the region growing it makes sense to extend the previous test case instead of writing a new one. We already have a segmentation based on the default threshold value and can just change the threshold and compare the resulting volumes.\nIncreasing the threshold shall result in larger volumes, decreasing shall result in smaller values.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... # Requirement 4: The 2D viewer shall provide the possibility to segment parts of the image based on a RegionGrowing algorithm # Requirement 4.1: It shall be possible to click into the image for defining a marker position for starting the RegionGrowing # Requirement 4.2: It shall be possible to define a threshold for the RegionGrowing algorithm def TEST_RegionGrowing(): # Load image and expect volumes and voxels without marker to be 0 loadImage(path_to_image) region_growing_voxels = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.numSegmentedVoxels\u0026#34;).value region_growing_volume = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.segmentedVolume_ml\u0026#34;).value ASSERT_EQ(region_growing_voxels, 0) ASSERT_EQ(region_growing_volume, 0) # Set marker and expect volumes and voxels to be larger than 0 setMarkerPosition(marker_location) region_growing_voxels = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.numSegmentedVoxels\u0026#34;).value region_growing_volume = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.segmentedVolume_ml\u0026#34;).value ASSERT_GT(region_growing_voxels, 0) ASSERT_GT(region_growing_volume, 0) # Test the threshold functionality by changing the value and comparing the results current_threshold = ctx.field(\u0026#34;TutorialSummary.thresholdInterval\u0026#34;).value current_threshold = current_threshold + 0.5 ctx.field(\u0026#34;TutorialSummary.thresholdInterval\u0026#34;).value = current_threshold region_growing_voxels_new = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.numSegmentedVoxels\u0026#34;).value region_growing_volume_new = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.segmentedVolume_ml\u0026#34;).value ASSERT_GT(region_growing_voxels_new, region_growing_voxels) ASSERT_GT(region_growing_volume_new, region_growing_volume) current_threshold = current_threshold - 0.7 ctx.field(\u0026#34;TutorialSummary.thresholdInterval\u0026#34;).value = current_threshold region_growing_voxels_new = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.numSegmentedVoxels\u0026#34;).value region_growing_volume_new = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.segmentedVolume_ml\u0026#34;).value ASSERT_LT(region_growing_voxels_new, region_growing_voxels) ASSERT_LT(region_growing_volume_new, region_growing_volume) # Reset application and expect volumes and voxels to be 0 again reset() region_growing_voxels = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.numSegmentedVoxels\u0026#34;).value region_growing_volume = ctx.field(\u0026#34;TutorialSummary.RegionGrowing.segmentedVolume_ml\u0026#34;).value ASSERT_EQ(region_growing_voxels, 0) ASSERT_EQ(region_growing_volume, 0) ... Requirement 5: The 2D viewer shall display the segmentation results as a semi-transparent overlay Requirement 5.1: It shall be possible to define the color of the overlay The requirement 5 can not be tested automatically. Transparencies should be tested by a human being.\nNevertheless, we can write an automated test checking the possibility to define the color of the overlay and the 3D segmentation.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... def TEST_OverlayColor(): reset() loadImage(path_to_image) setMarkerPosition(marker_location) ctx.field(\u0026#34;SoCameraInteraction.viewAll\u0026#34;).touch() ctx.field(\u0026#34;SoCameraInteraction.viewFromLeft\u0026#34;).touch() MLAB.processInventorQueue() ctx.field(\u0026#34;OffscreenRenderer.update\u0026#34;).touch() MLAB.processInventorQueue() current_color = ctx.field(\u0026#34;TutorialSummary.selectOverlayColor\u0026#34;).value ctx.field(\u0026#34;TutorialSummary.selectOverlayColor\u0026#34;).setValue(new_color) ctx.field(\u0026#34;SoCameraInteraction.viewAll\u0026#34;).touch() ctx.field(\u0026#34;SoCameraInteraction.viewFromLeft\u0026#34;).touch() MLAB.processInventorQueue() ctx.field(\u0026#34;OffscreenRenderer1.update\u0026#34;).touch() MLAB.processInventorQueue() ASSERT_NE(current_color, ctx.field(\u0026#34;TutorialSummary.selectOverlayColor\u0026#34;).value) ASSERT_EQ(ctx.field(\u0026#34;TutorialSummary.selectOverlayColor\u0026#34;).value, ctx.field(\u0026#34;TutorialSummary.SoView2DOverlay.baseColor\u0026#34;).value) ASSERT_EQ(ctx.field(\u0026#34;TutorialSummary.selectOverlayColor\u0026#34;).value, ctx.field(\u0026#34;TutorialSummary.SoWEMRendererSegmentation.faceDiffuseColor\u0026#34;).value) ASSERT_FALSE(ctx.field(\u0026#34;ImageCompare.testPassed\u0026#34;).value) ... Again, we reset the application to an initial state, load the image and set a marker. We remember the initial color and set a new color for our Macro Module. Then we check if the new color differs from the old color and if the colors used by the internal modules SoWEMRendererSegmentation and SoView2DOverlay changed to our new color.\nFinally an image comparison is done for the 3D rendering using the old and the new color. The images shall differ.\nThe call MLAB.processInventorQueue() is sometimes necessary if an inventor scene changed via Python scripting, because the viewers might not update immediately after changing the field. MeVisLab is now forced to process the queue in inventor and to update the renderings.\nRequirement 8: The total volume of the segmented area shall be calculated and shown (in ml) For the correctness of the volume calculation, we added the CalculateVolume module to our test network. The volume given by our macro is compared to the volume of the segmentation from output outSegmentationMask calculated by the CalculateVolume module.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... # Requirement 8: The total volume of the segmented area shall be calculated and shown (in ml) def TEST_VolumeCalculation(): # Reset and expect all volumes and number of voxels to be 0 reset() reference_volume = ctx.field(\u0026#34;CalculateVolume.totalVolume\u0026#34;).value ASSERT_EQ(reference_volume, 0) # Load patient, set marker and expect all volumes and number of voxels to be \u0026gt; 0 loadImage(path_to_image) reference_volume = ctx.field(\u0026#34;CalculateVolume.totalVolume\u0026#34;).value ASSERT_EQ(reference_volume, 0) setMarkerPosition(marker_location) reference_volume = ctx.field(\u0026#34;CalculateVolume.totalVolume\u0026#34;).value current_volume = ctx.field(\u0026#34;TutorialSummary.totalVolume\u0026#34;).value # Expect the total volume of the application to be the same as our additional CalculateVolume module ASSERT_GT(reference_volume, 0) ASSERT_EQ(reference_volume, current_volume) #set marker to a different location and check if volumes change. setMarkerPosition(marker_location_new) reference_volume_new = ctx.field(\u0026#34;CalculateVolume.totalVolume\u0026#34;).value current_volume_new = ctx.field(\u0026#34;TutorialSummary.totalVolume\u0026#34;).value ASSERT_NE(reference_volume, reference_volume_new) ASSERT_NE(current_volume, current_volume_new) ASSERT_EQ(reference_volume_new, current_volume_new) ... Requirement 9: It shall be possible to toggle the visible 3D objects Requirement 9.1: Original data Requirement 9.2: Segmentation results Requirement 9.3: All In the end, we want to develop a testcase for the 3D toggling of the view. We can not exactly test if the rendering is correct, therefore we will check if the 3D rendering image changes when toggling the 3D view. We will use the modules OffscreenRenderer, ImageCompare and SoCameraInteraction which we added to our test network.\nInitially, without any marker and segmentation, the views Both and Head show the same result. After adding a marker, we are going to test if different views result in different images.\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... # Requirement 9: It shall be possible to toggle the visible 3D objects # Requirement 9.1: Original data # Requirement 9.2: Segmentation results # Requirement 9.3: All def TEST_Toggle3DVolumes(): # Set ImageCompare.postErrorOnDiff to False because otherwise differences will lead to a failed test ctx.field(\u0026#34;ImageCompare.postErrorOnDiff\u0026#34;).value = False # Reset application and check if number of voxels is 0 on output reset() loadImage(path_to_image) # Without marker, the content of the 3D viewer should be the same for File and All ctx.field(\u0026#34;TutorialSummary.selected3DView\u0026#34;).value = \u0026#34;Both\u0026#34; MLAB.processInventorQueue() ctx.field(\u0026#34;SoCameraInteraction.viewFromLeft\u0026#34;).touch() MLAB.processInventorQueue() ctx.field(\u0026#34;OffscreenRenderer.update\u0026#34;).touch() ctx.field(\u0026#34;TutorialSummary.selected3DView\u0026#34;).value = \u0026#34;File\u0026#34; MLAB.processInventorQueue() ctx.field(\u0026#34;OffscreenRenderer1.update\u0026#34;).touch() ctx.field(\u0026#34;ImageCompare.compare\u0026#34;).touch() ASSERT_TRUE(ctx.field(\u0026#34;ImageCompare.testPassed\u0026#34;).value) # With marker, the content of the 3D viewer should be different setMarkerPosition(marker_location) ctx.field(\u0026#34;TutorialSummary.selected3DView\u0026#34;).value = \u0026#34;Both\u0026#34; MLAB.processInventorQueue() ctx.field(\u0026#34;OffscreenRenderer.update\u0026#34;).touch() ctx.field(\u0026#34;TutorialSummary.selected3DView\u0026#34;).value = \u0026#34;File\u0026#34; ctx.field(\u0026#34;OffscreenRenderer1.update\u0026#34;).touch() MLAB.processInventorQueue() ctx.field(\u0026#34;ImageCompare.compare\u0026#34;).touch() ASSERT_FALSE(ctx.field(\u0026#34;ImageCompare.testPassed\u0026#34;).value) ctx.field(\u0026#34;TutorialSummary.selected3DView\u0026#34;).value = \u0026#34;Segmented\u0026#34; ctx.field(\u0026#34;OffscreenRenderer1.update\u0026#34;).touch() MLAB.processInventorQueue() ctx.field(\u0026#34;ImageCompare.compare\u0026#34;).touch() ASSERT_FALSE(ctx.field(\u0026#34;ImageCompare.testPassed\u0026#34;).value) ctx.field(\u0026#34;TutorialSummary.selected3DView\u0026#34;).value = \u0026#34;Both\u0026#34; ctx.field(\u0026#34;OffscreenRenderer.update\u0026#34;).touch() MLAB.processInventorQueue() ctx.field(\u0026#34;ImageCompare.compare\u0026#34;).touch() ASSERT_FALSE(ctx.field(\u0026#34;ImageCompare.testPassed\u0026#34;).value) ... Sorting order in TestCaseManager The MeVisLab TestCaseManager sorts your test cases alphabetically. Your test cases should look like this now:\nTestCaseManager Sorting Generally, test cases should not depend on each other and the order of their execution does not matter. Sometimes it makes sense though to execute tests in a certain order, for example for performance reasons. In this case you can add numeric prefixes to your test cases. This might look like this then:\nTestCaseManager Custom Sorting Not testable requirements As already mentioned, some requirements can not be tested in an automated environment. Human eyesight cannot be replaced completely.\nIn our application, the following tests have not been tested automatically:\nRequirement 2: The application shall provide a 2D and a 3D viewer. Requirement 3: The 2D viewer shall display the loaded images Requirement 5: The 2D viewer shall display the segmentation results as a semi-transparent overlay Requirement 6: The 3D viewer shall visualize the loaded data in a 3-dimensional volume rendering Requirement 7: The 3D viewer shall additionally show the segmentation result as a 3-dimensional mesh Test Reports The results of your tests are shown in a Report Viewer. You can also export the results to JUnit for usage in build environments like Jenkins.\nReportViewer Screenshots You can also add screenshots of your inventor scene to the report. Add the following to your Python script and a Snapshot of your 3D scene is attached to your test report:\n\u0026lt;TEST_CASE_NAME\u0026gt;.py\n... result = ScreenShot.createOffscreenScreenShot(\u0026#34;SoCameraInteraction.self\u0026#34;, \u0026#34;screenshot.png\u0026#34;) Logging.showImage(\u0026#34;My screenshot\u0026#34;, result) Logging.showFile(\u0026#34;Link to screenshot file\u0026#34;, result) ... Summary Define accessible fields for Macro Modules so that they can be set in Python tests Add outputs to your Macro Modules for automated testing and connecting testing modules Testcase numbering allows you to sort them and define execution order Info:\u0026nbsp; Additional information about MeVisLab TestCenter can be found in TestCenter Manual \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Prototyping","Automated Tests","Python"],"section":"tutorials"},{"date":"1673913600","url":"https://mevislab.github.io/examples/tutorials/summary/summary3/","title":"Step 3: Prototyping - User Interface and Python scripting","summary":"Step 3: Prototyping - User Interface and Python scripting Introduction In this step, we will develop a user interface and add Python scripting to the Macro Module you created in Step 2.\nSteps to do Develop the User Interface A mockup of the user interface you are going to develop is available here. The interface provides the possibility to load files and shows a 2D and a 3D viewer. In addition to that, some settings and information for our final application are available.","content":"Step 3: Prototyping - User Interface and Python scripting Introduction In this step, we will develop a user interface and add Python scripting to the Macro Module you created in Step 2.\nSteps to do Develop the User Interface A mockup of the user interface you are going to develop is available here. The interface provides the possibility to load files and shows a 2D and a 3D viewer. In addition to that, some settings and information for our final application are available.\nSearch for your Macro Module and add it to your workspace. Right-click and select [ Related Files \u0026rarr; \u0026lt;MACRO_MODULE_NAME\u0026gt;.script ].\nThe MeVisLab text editor MATE opens showing the *.script file of your module.\nLayout You can see that the interface is divided into 4 parts in vertical direction:\nSource or file/directory selection Viewing (2D and 3D) Settings Info Inside the vertical parts, the elements are placed next to each other horizontally.\nAdd a Window section to your *.script file. Inside the Window, we need a Vertical for the 4 parts and a Box for each part. Name the Boxes Source, Viewing, Settings and Info. The layout inside each Box shall be Horizontal.\nIn addition to that, we define the minimal size of the Window as 400 x 300 pixels.\n\u0026lt;MACRO_NAME\u0026gt;.script\nWindow { // Define minimum width and height minimumWidth = 400 minimumHeight = 300 // Vertical Layout and 4 Boxes with Horizontal Layout Vertical { Box Source { layout = Horizontal } Box Viewing { layout = Horizontal } Box Settings { layout = Horizontal } Box Info { layout = Horizontal } } } You can preview your initial layout in MeVisLab by double-clicking your module .\nInitial Window Layout You can see the 4 vertical aligned parts as defined in the *.script file. Now we are going to add the content of the Boxes.\nAdditional:\u0026nbsp; An overview over the existing layout elements in MeVisLab Definition Language (MDL) can be found here Adding the UI elements Source The Source Box shall provide the possibility to select a file for loading into the viewers. You have many options to achieve that in MeVisLab and Python. The easiest way is to re-use the existing field of the LocalImage module in your internal network.\nAdd a field to the Parameters section of your *.script file. Name the field openFile and set type to String and internalName to LocalImage.name.\nThen add another field to your Box for the Source and use the field name from Parameters section, in this case openFile. Set browseButton = True and browseMode = open and save your script.\n\u0026lt;MACRO_NAME\u0026gt;.script\nInterface { Inputs {} Outputs {} Parameters { Field openFile { type = String internalName = LocalImage.name } } } ... Window { // Define minimum width and height minimumWidth = 400 minimumHeight = 300 // Vertical Layout and 4 Boxes with Horizontal Layout Vertical { Box Source { layout = Horizontal Field openFile { browseButton = True browseMode = open } } Box Viewing { layout = Horizontal } Box Settings { layout = Horizontal } Box Info { layout = Horizontal } } } Again, you can preview your user interface in MeVisLab directly. You can already select a file to open. The image is available at the output of the LocalImage module in your internal network but the Viewers are missing in our interface.\nSource Box Viewing Add the 2 viewer modules to the Viewing section of your *.script file and define their field as View2D.self and SoExaminerViewer.self. Set expandX = Yes and expandY = Yes for both viewing modules. We want them to resize in case the size of the Window changes.\nSet the 2D Viewer type to SoRenderArea and the 3D Viewer type to SoExaminerViewer and inspect your new user interface in MeVisLab.\n\u0026lt;MACRO_NAME\u0026gt;.script\n... Box Viewing { layout = Horizontal Viewer View2D.self { expandX = True expandY = True type = SoRenderArea } Viewer SoExaminerViewer.self { expandX = True expandY = True type = SoExaminerViewer } } ... 2D and 3D Viewer The images selected in the Source section are shown in 2D and 3D. We simply re-used the existing fields and viewers from your internal network and are already able to interact with the images. As the View2D of your internal network itself provides the possibility to accept markers and starts the RegionGrowing, this is also already possible and the segmentations are shown in 2D and 3D.\nSettings Let\u0026rsquo;s define the Settings section. Once again we first define the necessary fields. For automated tests which we are going to develop later, it makes sense to make some of the fields of the internal network available from outside.\nThe following shall be accessible as Field for our Macro Module:\nFilename to be opened Color of the 2D overlay and 3D segmentation Transparency of the 3D image Threshold to be used for RegionGrowing Iso value of the 3D surface to use for rendering Position of the Marker to use for RegionGrowing Selection for 3D visualization (image, segmentation or both) Trigger to reset the application to its initial state We already defined the filename as a field. Next we want to change the color of the overlay. Add another field to your Parameters section as selectOverlayColor. Define internalName = SoView2DOverlay.baseColor and type = Color. You may also define a title for the field, for example Color.\nThe baseColor field of the SoView2DOverlay already has a parameter connection to the color of the SoWEMRendererSegmentation. This has been done in the internal network. The defined color is used for 2D and 3D automatically.\n\u0026lt;MACRO_NAME\u0026gt;.script\nInterface { Inputs {} Outputs {} Parameters { ... Field selectOverlayColor { internalName = SoView2DOverlay.baseColor type = Color } } } ... Box Settings { layout = Horizontal Field selectOverlayColor { title = Color } } ... The next elements follow the same rules, therefore the final script will be available at the end for completeness.\nIn order to set the transparency of the 3D image, we need another field re-using the SoWEMRendererImage.faceAlphaValue. Add a field imageAlpha to the Parameters section. Define internalName = SoWEMRendererImage.faceAlphaValue, type = Integer, min = 0 and max = 1.\nAdd the field to the Settings Box and set step = 0.1 and slider = True.\nFor the RegionGrowing threshold, add the field thresholdInterval to Parameters section and set type = Integer, min = 1, max = 100 and internalName = RegionGrowing.autoThresholdIntervalSizeInPercent.\nAdd the field to the Settings UI and define step = 0.1 and slider = True.\nDefine a field isoValueImage in the Parameters section and set internalName = IsoSurfaceImage.isoValue, type = Integer, min = 1 and max = 1000.\nIn the Settings section of the UI, set step = 2 and slider = True.\n\u0026lt;MACRO_NAME\u0026gt;.script\nInterface { Inputs {} Outputs {} Parameters { Field openFile { type = String internalName = LocalImage.name } Field selectOverlayColor { internalName = SoView2DOverlay.baseColor type = Color } Field imageAlpha { internalName = SoWEMRendererImage.faceAlphaValue type = Integer min = 0 max = 1 } Field thresholdInterval { internalName = RegionGrowing.autoThresholdIntervalSizeInPercent type = Integer min = 0 max = 100 } Field isoValueImage { internalName = IsoSurfaceImage.isoValue type = Integer min = 0 max = 1000 } } } Commands { source = $(LOCAL)/TutorialSummary.py } Window { // Define minimum width and height minimumWidth = 400 minimumHeight = 300 // Vertical Layout and 4 Boxes with Horizontal Layout Vertical { Box Source { layout = Horizontal Field openFile { browseButton = True browseMode = open } } Box Viewing { layout = Horizontal Viewer View2D.self { expandX = True expandY = True type = SoRenderArea } Viewer SoExaminerViewer.self { expandX = True expandY = True type = SoExaminerViewer } } Box Settings { layout = Horizontal Field selectOverlayColor { title = Color } Field imageAlpha { step = 0.1 slider = True } Field thresholdInterval { step = 0.1 slider = True } Field isoValueImage { step = 2 slider = True } } Box Info { layout = Horizontal } } } Your user interface of the Macro Module should now look similar to this:\nUser Interface without Python Scripting For the next elements, we require Python scripting. Nevertheless, you are already able to use your application and perform the basic functionalities without writing any line of code.\nPython scripting Python scripting is always necessary in case you do not want to re-use an existing field for your user interface but implement functions to define what happens in case of any event.\nEvents can be raised by the user (i.e. by clicking a button) or by the application itself (i.e. when the window is opened).\n3D visualization selection You will now add a selection possibility for the 3D viewer. This allows you to define the visibility of the 3D objects Image, Segmentation or Both.\nAdd another field to your Parameters section. Define the field as selected3DView and set type = Enum and values =Segmentation,Image,Both.\nAdd a ComboBox to your Settings and use the field name defined above. Set alignX = Left and editable = False and open the Window of the Macro Module in MeVisLab.\nThe values of the field can be selected, but nothing happens in our viewers. We need to implement a FieldListener in Python which reacts on any value changes of the field selected3DView.\nOpen your script file and go to the Commands section. Add a FieldListener and re-use the name of our internal field selected3DView. Add a Command to the FieldListener calling a Python function viewSelectionChanged.\n\u0026lt;MACRO_NAME\u0026gt;.script\nCommands { source = $(LOCAL)/TutorialSummary.py FieldListener selected3DView { command = viewSelectionChanged } } Right-click the command and select [ Create Python Function \u0026#39;viewSelectionChanged\u0026#39; ]. MATE automatically opens the Python file of your Macro Module and creates a function viewSelectionChanged.\n\u0026lt;MACRO_NAME\u0026gt;.py\nfrom mevis import * def viewSelectionChanged(field): if field.value == \u0026#34;Segmentation\u0026#34;: ctx.field(\u0026#34;SoSwitch.whichChild\u0026#34;).value = 0 if field.value == \u0026#34;Image\u0026#34;: ctx.field(\u0026#34;SoSwitch.whichChild\u0026#34;).value = 1 if field.value == \u0026#34;Both\u0026#34;: ctx.field(\u0026#34;SoSwitch.whichChild\u0026#34;).value = 2 The function sets the SoSwitch to the child value depending on the selected field value from the ComboBox and you should now be able to switch the 3D rendering by selecting an entry in the user interface.\nSetting the Marker The Marker for the RegionGrowing is defined by the click position as Vector3. Add another field markerPosition to the Parameters section and define type = Vector3.\nThen, add a trigger field applyMarker to your Parameters section. Set type = Trigger and title = Add.\n\u0026lt;MACRO_NAME\u0026gt;.script\n... Field markerPosition { type = Vector3 } Field applyMarker { type = Trigger title = Add } ... Add another FieldListener to both fields: \u0026lt;MACRO_NAME\u0026gt;.script\n... FieldListener markerPosition { command = insertPosition } FieldListener applyMarker { command = applyPosition } ... Finally, add both fields to the Settings section of your user interface: \u0026lt;MACRO_NAME\u0026gt;.script\n... Field markerPosition {} Field applyMarker {} ... The Python functions should look like this: \u0026lt;MACRO_NAME\u0026gt;.py\n... def insertPosition(field): ctx.field(\u0026#34;SoView2DMarkerEditor.newPosXYZ\u0026#34;).value = field.value def applyPosition(): ctx.field(\u0026#34;SoView2DMarkerEditor.useInsertTemplate\u0026#34;).value = True ctx.field(\u0026#34;SoView2DMarkerEditor.add\u0026#34;).touch() ... Whenever the field markerPosition changes its value, the value is automatically applied to the SoView2DMarkerEditor.newPosXYZ. Clicking SoView2DMarkerEditor.add adds the new Vector to the SoView2DMarkerEditor and the region growing starts.\nInfo:\u0026nbsp; The Field SoView2DMarkerEditor.useInsertTemplate needs to be set to True in order to allow adding markers via Python. Reset Add a new field resetApplication to the Parameters section and set type = Trigger and title = Reset.\nAdd another FieldListener to your Commands and define command = resetApplication.\nAdd the field to your Source region.\n\u0026lt;MACRO_NAME\u0026gt;.script\n... Parameters { Field resetApplication { type = Trigger title = Reset } } ... Commands { ... FieldListener resetApplication { command = resetApplication } } ... Box Source { layout = Horizontal Field openFile { browseButton = True browseMode = open } Field resetApplication { } } ... What shall happen when we reset the application?\nThe loaded image shall be unloaded, the Viewer shall be empty The marker shall be reset if available Add the Python function resetApplication and implement the following: \u0026lt;MACRO_NAME\u0026gt;.py\nfrom mevis import * def resetApplication(): ctx.field(\u0026#34;RegionGrowing.clear\u0026#34;).touch() ctx.field(\u0026#34;SoView2DMarkerEditor.deleteAll\u0026#34;).touch() ctx.field(\u0026#34;LocalImage.close\u0026#34;).touch() You can also reset the application to initial state by adding a initCommand to your Window. Call the resetApplication function here, too and whenever the window is opened, the application is reset to its initial state.\n\u0026lt;MACRO_NAME\u0026gt;.script\nWindow { // Define minimum width and height minimumWidth = 400 minimumHeight = 300 initCommand = resetApplication ... } This can also be used for setting/resetting to default values of the application. For example update your Python function resetApplication the following way:\n\u0026lt;MACRO_NAME\u0026gt;.py\nfrom mevis import * def resetApplication(): ctx.field(\u0026#34;RegionGrowing.clear\u0026#34;).touch() ctx.field(\u0026#34;SoView2DMarkerEditor.deleteAll\u0026#34;).touch() ctx.field(\u0026#34;LocalImage.close\u0026#34;).touch() ctx.field(\u0026#34;imageAlpha\u0026#34;).value = 0.5 ctx.field(\u0026#34;thresholdInterval\u0026#34;).value = 1.0 ctx.field(\u0026#34;isoValueImage\u0026#34;).value = 200 ctx.field(\u0026#34;selected3DView\u0026#34;).value = \u0026#34;Both\u0026#34; Information In the end, we want to provide some information about the volume of the segmented area (in ml).\nAdd one more field to your Parameters section and re-use the internal network fields CalculateVolume.totalVolume. Set field to editable = False\nAdd the field to the Info section of your window.\nOpening the window of your Macro Module in MeVisLab now provides all functionalities we wanted to achieve. You can also play around in the window and define some additional Boxes or MDL controls but the basic application prototype is now done.\nFinal Macro Module Final Script and Python files \u0026lt;MACRO_NAME\u0026gt;.script\nInterface { Inputs {} Outputs {} Parameters { Field openFile { type = String internalName = LocalImage.name } Field selectOverlayColor { internalName = SoView2DOverlay.baseColor type = Color } Field imageAlpha { internalName = SoWEMRendererImage.faceAlphaValue type = Integer min = 0 max = 1 } Field thresholdInterval { internalName = RegionGrowing.autoThresholdIntervalSizeInPercent type = Integer min = 0 max = 100 } Field isoValueImage { internalName = IsoSurfaceImage.isoValue type = Integer min = 0 max = 1000 } Field selected3DView { type = Enum values = Segmented,File,Both } Field totalVolume { internalName = CalculateVolume.totalVolume editable = False } Field resetApplication { type = Trigger title = Reset } Field markerPosition { type = Vector3 } Field applyMarker { type = Trigger title = Add } } } Commands { source = $(LOCAL)/\u0026lt;MACRO_NAME\u0026gt;.py FieldListener selected3DView { command = viewSelectionChanged } FieldListener resetApplication { command = resetApplication } FieldListener markerPosition { command = insertPosition } FieldListener applyMarker { command = applyPosition } } Window { // Define minimum width and height minimumWidth = 400 minimumHeight = 300 initCommand = resetApplication // Vertical Layout and 4 Boxes with Horizontal Layout Vertical { Box Source { layout = Horizontal Field openFile { browseButton = True browseMode = open } Field resetApplication { } } Box Viewing { layout = Horizontal Viewer View2D.self { expandX = True expandY = True type = SoRenderArea } Viewer SoExaminerViewer.self { expandX = True expandY = True type = SoExaminerViewer } } Box Settings { layout = Horizontal Field selectOverlayColor { title = Color } Field imageAlpha { step = 0.1 slider = True } Field thresholdInterval { step = 0.1 slider = True } Field isoValueImage { step = 2 slider = True } Field markerPosition {} Field applyMarker {} ComboBox selected3DView { alignX = Left editable = False } } Box Info { layout = Horizontal Field totalVolume {} } } } \u0026lt;MACRO_NAME\u0026gt;.py\nfrom mevis import * def viewSelectionChanged(field): if field.value == \u0026#34;Segmentation\u0026#34;: ctx.field(\u0026#34;SoSwitch.whichChild\u0026#34;).value = 0 if field.value == \u0026#34;Image\u0026#34;: ctx.field(\u0026#34;SoSwitch.whichChild\u0026#34;).value = 1 if field.value == \u0026#34;Both\u0026#34;: ctx.field(\u0026#34;SoSwitch.whichChild\u0026#34;).value = 2 def resetApplication(): ctx.field(\u0026#34;RegionGrowing.clear\u0026#34;).touch() ctx.field(\u0026#34;SoView2DMarkerEditor.deleteAll\u0026#34;).touch() ctx.field(\u0026#34;LocalImage.close\u0026#34;).touch() ctx.field(\u0026#34;imageAlpha\u0026#34;).value = 0.5 ctx.field(\u0026#34;thresholdInterval\u0026#34;).value = 1.0 ctx.field(\u0026#34;isoValueImage\u0026#34;).value = 200 ctx.field(\u0026#34;selected3DView\u0026#34;).value = \u0026#34;Both\u0026#34; def insertPosition(field): ctx.field(\u0026#34;SoView2DMarkerEditor.newPosXYZ\u0026#34;).value = field.value def applyPosition(): ctx.field(\u0026#34;SoView2DMarkerEditor.useInsertTemplate\u0026#34;).value = True ctx.field(\u0026#34;SoView2DMarkerEditor.add\u0026#34;).touch() Summary You now added a user interface to your Macro Module. The window opens automatically on double-click Fields defined in the Parameters section can be modified in the MeVisLab Module Inspector Python allows to implement functions executed on events raised by the user or by the application itself. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Prototyping","User Interface","Python"],"section":"tutorials"},{"date":"1673827200","url":"https://mevislab.github.io/examples/tutorials/summary/summary2/","title":"Step 2: Prototyping - Create a Macro Module","summary":"Step 2: Prototyping - Create a Macro Module Introduction In this example, we encapsulate the previously developed prototype network into a Macro Module for future application development and automated testing.\nSteps to do Make sure to have your *.mlab file from previous Step 1 available.\nPackage creation Packages are described in detail in Example 2.1: Package creation. If you already have your own package, you can skip this part and continue creating a Macro Module.","content":"Step 2: Prototyping - Create a Macro Module Introduction In this example, we encapsulate the previously developed prototype network into a Macro Module for future application development and automated testing.\nSteps to do Make sure to have your *.mlab file from previous Step 1 available.\nPackage creation Packages are described in detail in Example 2.1: Package creation. If you already have your own package, you can skip this part and continue creating a Macro Module.\nOpen Project Wizard via [ File \u0026rarr; Run Project Wizard... ] and select New Package. Run the Wizard and enter details of your new package and click Create.\nPackage wizard MeVisLab reloads and you can start creating your Macro Module.\nCreate a Macro Module Open Project Wizard via [ File \u0026rarr; Run Project Wizard... ] and select Macro Module. Run the Wizard and enter details of your new Macro Module.\nMacro Module wizard Select the created package and click Next.\nMacro Module wizard Select your *.mlab file from Step 1 and check Add Python file. Click Next.\nMacro Module wizard You do not have to define fields of your Macro Module now, we will do that later. Click Create. The Windows Explorer opens showing the directory of your Macro Module. It should be the same directory you selected for your Package.\nDirectory Structure of a Macro Module The directory structure for a Macro Module is as follows:\nFrom Package Wizard: Package target directory is the root directory of the module The next directory is the package group and package name From Macro Module Wizard: The name of the Macro Module defines the directory containing all files of your module An additional directory Modules is created containing the following files: \u0026lt;MACRO_NAME\u0026gt;.def \u0026lt;MACRO_NAME\u0026gt;.mlab \u0026lt;MACRO_NAME\u0026gt;.py \u0026lt;MACRO_NAME\u0026gt;.script Directory Structure Definition (*.def) file The initial *.def file contains information you entered into the Wizard for the Macro Module.\n\u0026lt;MACRO_NAME\u0026gt;.def\nMacroModule TutorialSummary { genre = \u0026#34;VisualizationMain\u0026#34; author = \u0026#34;MeVis Medical Solutions AG\u0026#34; comment = \u0026#34;Macro Module for MeVisLab Tutorials\u0026#34; keywords = \u0026#34;2D 3D RegionGrowing\u0026#34; seeAlso = \u0026#34;\u0026#34; externalDefinition = \u0026#34;$(LOCAL)/TutorialSummary.script\u0026#34; } An externalDefinition to a script file is also added (see below for the *.script file).\nMeVisLab Network (*.mlab) file The *.mlab file is a copy of the *.mlab file you developed in Step 1 and re-used in the wizard. In the next chapters, this file will be used as internal network.\nPython (*.py) file The initial *.py file only contains the import of MeVisLab specific objects and functions. In the future steps, we will add functionalities to our application in Python.\n\u0026lt;MACRO_NAME\u0026gt;.py\nfrom mevis import * Script (*.script) file The script (*.script) file defines fields accessible from outside the Macro Module, inputs and outputs and allows you to develop a User Interface for your prototype and your final application.\n\u0026lt;MACRO_NAME\u0026gt;.script\nInterface { Inputs {} Outputs {} Parameters {} } Commands { source = $(LOCAL)/TutorialSummary.py } The source also defines your Python file to be used when calling functions and events from the User Interface.\nUsing your Macro Module As you created a global macro Module, you can search for it in the MeVisLab Module Search.\nModule Search We did not define inputs or outputs. You cannot connect your module to others. In addition to that, we did not develop a User Interface. Double-clicking your module only opens the Automatic Panel showing the instanceName.\nAutomatic Panel Right-click on your module allows you to open the internal network as developed in Step 1.\nSummary Macro Modules encapsulate an entire MeVisLab network including all modules. The internal network can be shown (and edited) via right-click [ Show Internal Network ] The Wizard already creates the necessary folder structure and generates files for User Interface and Python development. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Prototyping","Macro Modules"],"section":"tutorials"},{"date":"1673740800","url":"https://mevislab.github.io/examples/tutorials/summary/summary1/","title":"Step 1: Prototyping - Develop your Network","summary":"Step 1: Prototyping - Develop your Network Introduction In this example, we will develop a network which fulfills the requirements from the overview page. The network will be developed by re-using existing modules and defining basic field values.\nSteps to do 2D viewer The 2D viewer shall visualize the loaded images. In addition to that, it shall be possible to click into the image for starting a RegionGrowing algorithm segmenting parts of the loaded image based on a threshold.","content":"Step 1: Prototyping - Develop your Network Introduction In this example, we will develop a network which fulfills the requirements from the overview page. The network will be developed by re-using existing modules and defining basic field values.\nSteps to do 2D viewer The 2D viewer shall visualize the loaded images. In addition to that, it shall be possible to click into the image for starting a RegionGrowing algorithm segmenting parts of the loaded image based on a threshold.\nThe following requirements from Overview will be implemented:\nRequirement 1: The application shall be able to load DICOM data. Requirement 3: The 2D viewer shall display the loaded images Requirement 4: The 2D viewer shall provide the possibility to segment parts of the image based on a RegionGrowing algorithm Requirement 4.1: It shall be possible to click into the image for defining a marker position for starting the RegionGrowing Requirement 4.2: It shall be possible to define a threshold for the RegionGrowing algorithm Requirement 5: The 2D viewer shall display the segmentation results as a semi-transparent overlay Requirement 5.1: It shall be possible to define the color of the overlay Add a LocalImage and a View2D module to your workspace. You are now able to load an image and view the slices.\nLoading an image For the RegionGrowing, we need a SoView2DMarkerEditor, a SoView2DOverlay and a RegionGrowing module. Add them and connect them as seen below. Configure the RegionGrowing module to use a 3D-6-Neighborhood (x,y,z) relation and an automatic threshold value of 1.500. Also select Auto-Update.\nSet SoView2DMarkerEditor to allow only 1 Marker by defining Max Size = 1 and Overflow Mode = Remove All. For our application we only want 1 Marker to be set for defining the RegionGrowing.\nIf you now click into your loaded image via left mouse button , the RegionGrowing module segments all neighborhood pixels with a mean intensity value plus/minus defined percentage value from your click position.\nThe overlay is shown in white.\nRegionGrowing via marker editor Open the SoView2DOverlay module, change Blend Mode to Blend and select any color and Alpha Factor for your overlay. The changes are applied automatically in the viewer.\nOverlay color and transparency The segmented results from the RegionGrowing module might contain some holes because of differences in the intensity value of neighboring pixels. You can close those holes by using a CloseGap module. Connect it between the RegionGrowing and the SoView2DOverlay and configure Filter Mode as Binary Dilatation, Border Handling as Pad Dst Fill and set KernelZ to 3.\nIn the end we want to calculate the volume of the segmented parts. Add a CalculateVolume module to the CloseGap.\nThe 2D viewer now provides the basic functionalities. For a better overview, you should select all modules except the LocalImage and select [ Grouping \u0026rarr; Add to new Group... ]. Name the group 2D Viewer. Your network should now look like this:\nGroup 2D Viewer 3D Viewer The 3D viewer shall visualize your loaded image in 3D and additionally provide the possibility to render your segmentation results. It shall be possible to switch between different views for showing image and segmentation, only image or only segmentation.\nIn the end, the volume (in ml) of your segmentation results shall be calculated.\nThe following requirements from Overview will be implemented:\nRequirement 2: The application shall provide a 2D and a 3D viewer. Requirement 6: The 3D viewer shall visualize the loaded data in a 3-dimensional volume rendering Requirement 7: The 3D viewer shall additionally show the segmentation result as a 3-dimensional mesh Requirement 8: The total volume of the segmented area shall be calculated and shown (in ml) Requirement 9: It shall be possible to toggle the visible 3D objects Requirement 9.1: Original data Requirement 9.2: Segmentation results Requirement 9.3: All Add a SoExaminerViewer, a SoWEMRenderer and an IsoSurface to your existing network and connect it to the LocalImage. Configure the IsoSurface to use an IsoValue of 200, a Resolution of 1 and check Auto-Update and Auto-Apply.\n3D Viewer The result should be a 3-dimensional rendering of your image.\nSoExaminerViewer Info:\u0026nbsp; If you do not see the rendering immediately, click Apply in your IsoSurface module. Define the field instanceName of your IsoSurface module as IsoSurfaceImage and add another IsoSurface to your network. Set the instanceName to IsoSurfaceSegmentation and connect the module to the output of the CloseGap module from the image segmentation. Set IsoValue to 420, a Resolution of 1 and check Auto-Update and Auto-Apply.\nSet instanceName of the SoWEMRenderer to SoWEMRendererImage and add another SoWEMRenderer. Set this instanceName to SoWEMRendererSegmentation and connect it to the IsoSurfaceSegmentation. Selecting the output of the new SoWEMRenderer shows the segmented parts as a 3D object in Output Inspector.\nSegmentation preview in Output Inspector Once again, we should group the modules used for 3D viewing and name the new group 3D Viewer.\nGrouped network We now want to allow the user to toggle the different 3D visualizations as defined by the requirements above. It shall be possible to show:\nOriginal data only Segmentation only Both Add a SoSwitch to your network. Connect the switch to both of your SoWEMRenderer and to the SoExaminerViewer.\nSoSwitch The default input of the switch is None. Your 3D viewer remains black. Using the arrows on the SoSwitch allows you to toggle between the segmentation and the image. Input 0 shows the segmented brain, input 1 shows the head. You are now able to toggle between them. A view with both objects is still missing.\nExample1_Segmentation Example1_Image Add a SoGroup and connect both SoWEMRenderer as input. The output needs to be connected to the right input of the SoSwitch.\nSoGroup You can now also toggle Input 2 of the switch showing both 3D objects. The only problem is: You cannot see the brain because it is located inside the head. Open the SoWEMRendererImage panel and set faceAlphaValue to 0.5. The viewer now shows the head semi transparent and you can see the brain inside. Transparencies are difficult to render. You need to add a SoDepthPeelRenderer and connect it to the semi transparent SoWEMRendererImage. Set Layers of the renderer to 1.\nSoDepthPeelRenderer You have a 2D and a 3D viewer now. In the end, we want to define the colors of the overlay to be re-used for the 3D segmentation.\nParameter connections for visualization Open the panels of the SoView2DOverlay and the SoWEMRendererSegmentation. Draw a parameter connection from SoView2DOverlay.baseColor to SoWEMRendererSegmentation.faceDiffuseColor.\nSynchronized segmentation colors Now the 3D visualization uses the same color as the 2D overlay.\nSummary You now built a network providing the basic functionalities of your application. Actions inside your application need to be executed by changing fields in your network or by manually touching a trigger. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Prototyping"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/coordinatesystems/coordinatesystems/","title":"Example 1.1: MeVisLab Coordinate Systems","summary":"Example 1.1: MeVisLab Coordinate Systems Three coordinate systems exist next to each other:\nWorld coordinates Voxel coordinates Device coordinates World coordinate systems in MeVisLab are always right handed.\nThe blue rectangle shows the same region in the three coordinate systems.\nCoordinate Systems in MeVisLab World coordinates World coordinates are:\nGlobal: Combine several objects in a view Isotropic: All directions are equivalent Orthogonal: Coordinate axes are orthogonal to each other The origin of the world coordinate system can be anywhere and is not clearly defined.","content":"Example 1.1: MeVisLab Coordinate Systems Three coordinate systems exist next to each other:\nWorld coordinates Voxel coordinates Device coordinates World coordinate systems in MeVisLab are always right handed.\nThe blue rectangle shows the same region in the three coordinate systems.\nCoordinate Systems in MeVisLab World coordinates World coordinates are:\nGlobal: Combine several objects in a view Isotropic: All directions are equivalent Orthogonal: Coordinate axes are orthogonal to each other The origin of the world coordinate system can be anywhere and is not clearly defined. Origins of the other coordinate systems can always be mapped to the world coordinate system. In case of DICOM images, this mapping is defined by DICOM tags.\nWorld coordinates in MeVisLab You can show the world coordinates in MeVisLab by using the following example network:\nWorld Coordinates in MeVisLab The ConstantImage module generates an artificial image with a certain size, data type and a constant fill value. The origin of the image is at the origin of the world coordinate system, therefore the SoCoordinateSystem module shows the world coordinate system.\nConstantImage Info Placing an object into the Open Inventor Scene of the SoExaminerViewer, in this case a SoCube with width, height and depth of 10, places the object to the origin of the world coordinate system.\nSoCube in world coordinate system Translations You can move an object in your scene, for example by using a SoTranslation module. Update your network and add the module before your cube. Defining a translation vector 50, 0, 0 moves your cube by 50 in x-direction based on the origin of the world coordinate system.\nSoTranslation Transformations More complex transformations can be done by using the SoTransform module. You can not only translate an existing object, but also rotate, scale and apply many other transformations.\nSoTransform \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. Voxel coordinates Voxel coordinates are:\nRelative to an image Continuous from [0..x,0..y,0..z], voxel center at 0.5 Direct relation to voxel location in memory Voxel coordinates in MeVisLab You can show the voxel coordinates in MeVisLab by using the following example network:\nVoxel Coordinates Load the file Liver1_CT_venous.small.tif .The Info module shows detailed information about the image loaded by the LocalImage. Opening the SoExaminerViewer shows the voxel coordinate system of the loaded image. You may have to change the LUT in SoGVRVolumeRenderer so that the image looks better.\nVoxel coordinates of the loaded image The Advanced tab of the Info module shows the world coordinates of the image. In this case, the origin of the voxel coordinate system is located at -186.993, -173.993, -249.993.\nIn addition to that, you can see a scaling which has been done on the image. The voxel sizes are shown in the diagonal values of the matrix as 3.985792, 3.985792, 3.985798.\nWorld coordinates of the loaded image You can change the scaling to 1 by adding a Resample3D module to the network, Set the voxel size to 1, 1, 1 and inspect the Info module.\nResample3D Image Info after Resampling The voxel size is now 1.\nYou can add this network to the world coordinate system network developed above and see both coordinate systems.\nWorld coordinates of the loaded image Opening the SoExaminerViewer shows the world coordinate system in white and the voxel coordinate system in yellow.\nWorld and Voxel coordinates On the yellow axis, we can see that the coordinate systems are located as already seen in the Info module Advanced tab. On the x-axis, the voxel coordinate origin is translated by -186.993 and on the y-axis by -173.993.\nYou can also add a SoVertexProperty and a SoLineSet module and configure a line from the origin of the world coordinate system 0, 0, 0 to the origin of the voxel coordinate system as defined by the image -186.993, -173.993, -249.993.\nSoVertexProperty \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. Device coordinates Device coordinates are:\n2D coordinates in OpenGL viewport Measured in pixel Have their origin (0,0) in the top left corner of the device (with x-coordinates increasing to the right and y-coordinates increasing downwards) The viewport is the rectangle in pixels on your screen you want to render to. Affine transformations map abstract coordinates from your scene to physical pixels on your device.\nAll triangular vertices go through a projection matrix and end in a normalized range from -1 to 1 representing your field of view. To find which pixels the triangles actually cover on screen, those coordinates get linearly remapped from [−1, 1] to the range of the viewport rectangle in pixels. Technically that kind of mapping is called an affine transformation.\n","tags":["Beginner","Tutorial","Data Import","DICOM","Coordinate Systems"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/coordinatesystems/coordinatesystems2/","title":"Example 1.2: DICOM Coordinate Systems","summary":"Example 1.2: DICOM Coordinate Systems General Coordinate systems in DICOM are basically the same as world coordinates in MeVisLab (except for the 0.5 voxel offset). World coordinates also refer to the patient axes. They are:\nBased on the patient\u0026rsquo;s main body axes (transverse, coronal, sagittal) Measured as 1 coordinate unit = 1 millimeter Right-handed Not standardized regarding their origin World Coordinates in Context of the Human Body The DICOM (Digital Imaging and Communications in Medicine) standard defines a data format that groups information into data sets.","content":"Example 1.2: DICOM Coordinate Systems General Coordinate systems in DICOM are basically the same as world coordinates in MeVisLab (except for the 0.5 voxel offset). World coordinates also refer to the patient axes. They are:\nBased on the patient\u0026rsquo;s main body axes (transverse, coronal, sagittal) Measured as 1 coordinate unit = 1 millimeter Right-handed Not standardized regarding their origin World Coordinates in Context of the Human Body The DICOM (Digital Imaging and Communications in Medicine) standard defines a data format that groups information into data sets. This way, the image data is always kept together with all meta information like patient ID, study time, series time, acquisition data etc. The image slice is represented by another tag with pixel information.\nDICOM tags have unique numbers, encoded as two 16 bit numbers, usually shown in hexadecimal notation as two four-digit numbers (xxxx,xxxx). These numbers are the data group number and the data element number.\nInfo:\u0026nbsp; Although DICOM is a standard, often the data that is received / recorded does not follow the standard. Wrongly used tags or missing mandatory tags may cause problems in data processing. Some typical modules for DICOM handling:\nDirectDicomImport is a module for DICOM import that generates 3D or 4D images (as ML images) from a list of DICOM files which can directly be used by other modules. It has a lot of options to control the import process, which can, e.g., determine which slices are combined into an image stack. DicomImport is a new module for DICOM import. The new implementation does not yet provide all known functionalities from DirectDicomImport, most of them will be added in future releases. Its main advantage is that the import process is faster and happens asynchronously. You can view the the DICOM tags of a DICOM image or a processed ML image with the module DicomTagBrowser. You can view and cut out frame-specific tags with the module DicomFrameSelect. You can modify DICOM tags with the module DicomTagModify. You can also create a new DICOM header for an image file with the ImageSave module, tab Options, Save DICOM header file only. Saving of loaded DICOM data to the filesystem or sending to a PACS (Picture Archiving and Communication System) is possible with the DicomTool macro module. Basic support for querying and receiving DICOM data from a PACS is available via the DicomQuery and DicomReceiver modules. Info:\u0026nbsp; For handling and manipulating DICOM data in C++, the DICOM toolkit DCMTK (DICOM@offis) is recommended. Parts of this toolkit are also used in MeVisLab.\nAnother option for Python is pydicom.\nOrthogonal views The module OrthoView2D provides a 2D view displaying the input image in three orthogonal viewing directions. By default, the view is configured as Cube where the transverse view is placed in the top right segment, sagittal in bottom left and coronal in bottom right segment. Use the left mouse button to set a position in the data set. This position will be displayed in all available views and is available as field worldPosition.\nOrthoView2D As already learned in the previous example 1.1: MeVisLab Coordinate Systems, world and voxel positions are based on different coordinate systems. Selecting the top left corner of any of your views will not show a world position of 0, 0, 0. You can move the mouse cursor to the voxel position 0, 0, 0 as seen in the image information of the viewers in brackets (x, y, z). The field worldPosition then shows the location of the image in world coordinate system (see Info module).\nOrthoView2D Voxel- and World Position Another option is to use the module OrthoReformat3 which transforms the input image (by rotating and/or flipping) into the three main views commonly used:\nOutput 0: Sagittal view Output 1: Coronal view Output 2: Transverse view OrthoReformat3 The general View2D always uses the original view from the image data without reconstructing another view. In case of ProbandT1, this is the sagittal view.\n","tags":["Beginner","Tutorial","Data Import","DICOM","Coordinate Systems"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/","title":"Example 2: Macro Modules and Module Interaction","summary":"Example 2: Macro Modules Macro Modules and Module Interactions via User Interface and Python Scripting MeVisLab provides different types of modules, which can be distinguished by their color. The brown modules are called macro modules. Macro modules condense a whole network into one module. You can open the internal network by pressing the middle mouse button or via right mouse click and select [ Help \u0026rarr; Show Internal Network ]. Macro modules provide the possibility to create customized user interfaces and Python interactions.","content":"Example 2: Macro Modules Macro Modules and Module Interactions via User Interface and Python Scripting MeVisLab provides different types of modules, which can be distinguished by their color. The brown modules are called macro modules. Macro modules condense a whole network into one module. You can open the internal network by pressing the middle mouse button or via right mouse click and select [ Help \u0026rarr; Show Internal Network ]. Macro modules provide the possibility to create customized user interfaces and Python interactions.\nIn Chapter I - Basic Mechanics we built a contour filter and condensed all the modules into one local macro module. Until now, the local macro module containing the contour filter can only be used in the current network. In the following chapters, we like to make the macro module commonly available throughout projects and equip this macro module with panels and help pages. Commonly available macro modules are called global macros and can be found in MeVisLab [ Module Search ]. Global macros and projects are stored in packages. A package structure makes it easy to exchange projects and different functionalities between people.\n","tags":["Beginner","Tutorial","Macro","Macro Modules"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/package/","title":"Example 2.1: Package Creation","summary":"Example 2.1: Package creation \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction Packages are the way MeVisLab organizes different development projects.\nMacro modules and projects are stored in packages. If you like to create a global macro module, you need a package in which this macro module can be stored in. In this chapter, we will create our own package. We start our package creation by creating a package group, because every package needs to be stored in a package group.","content":"Example 2.1: Package creation \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction Packages are the way MeVisLab organizes different development projects.\nMacro modules and projects are stored in packages. If you like to create a global macro module, you need a package in which this macro module can be stored in. In this chapter, we will create our own package. We start our package creation by creating a package group, because every package needs to be stored in a package group. You can find detailed information about packages and package groups here and in the package documentation .\nSteps to do To create packages and package groups, we will use the Project Wizard. Open the Project Wizard via [ File \u0026rarr; Run Project Wizard ... ]. Then, select [ Package \u0026rarr; New Package ] and Run Wizard.\nThe Project Wizard Next you need to:\nFind a name for your package group, for example your company name or in our example the name MyPackageGroup.\nFind a name for your package, in our example we call it General.\nSelect the path your package group is supposed to be stored in (If you like to add a package to an existing package group, select its name and chose the path the package group is stored in)\nIf you now create the package, you can find a folder structure in the desired directory. The folder of your package group contains the folder of your package. We have now successfully created a package in which we can store our global macro module.\nPackage creation Summary Packages are needed to store global macro modules and projects. Package groups contain packages. Packages and package groups can be created using the Project Wizard. Detailed information about packages can be found in the package documentation . ","tags":["Beginner","Tutorial","Package"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/globalmacromodules/","title":"Example 2.2: Creation of Global Macro Modules","summary":"Example 2.2: Global Macro Modules \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this chapter you will learn how to create global macro modules. There are many ways to do this. You can convert local macros into global macro modules or you can directly create global macro modules using the Project Wizard. In contrast to local macro modules, global macro modules are commonly available throughout projects and can be found via module search and under [ Modules ].","content":"Example 2.2: Global Macro Modules \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this chapter you will learn how to create global macro modules. There are many ways to do this. You can convert local macros into global macro modules or you can directly create global macro modules using the Project Wizard. In contrast to local macro modules, global macro modules are commonly available throughout projects and can be found via module search and under [ Modules ].\nSteps to do Transform a local macro module into a global macro module To transform our local macro module Filter from Chapter I into a global macro module, right-click the macro module to open the context menu and select [ Extras \u0026rarr; Convert To Global Module... ]\nConvert local macro to global macro Define module properties Choose a unique module name\nState the module author\nSelect the genre of the module. For this, browse through the module genres to select the appropriate genre. In our case, as our macro module contains a contour filter, we will choose the genre Filters.\nThe Genre defines the location where your module will be shown in MeVisLab [ Modules ] menu.\nTick the box Add reference to example network to directly create the template for an example network for your macro module.\nSelect the package you like to store the module in. We choose the package we created before. Your module is saved in an .mlab format and can be found in \\MyPackageGroup\\General\\Modules\\Macros\\MyProject.\nInfo:\u0026nbsp; Make sure to chose Directory Structure as self-contained. This makes sure that all files of your module are stored in a single directory. Create global macro module Use the Project Wizard to create global macro modules Instead of converting a local macro module into a global macro module, you can also use the Project Wizard to create new macro modules. Open the Project Wizard via [ File \u0026rarr; Run Project Wizard ... ]. Then, select [ Modules (Scripting) \u0026rarr; Macro Module ] and Run Wizard.\nDefine module properties Choose a unique module name\nState the module author\nSelect the genre of the module. For this, browse through the module genres to select the appropriate genre. In our case, as our macro module contains a contour filter, we will choose the genre Filters.\nTick the box Add reference to example network to directly create the template for an example network for your macro module.\nSelect the package you like to store the module in. We choose the package we created before. Your module is saved in an .mlab format and can be found in \\MyPackageGroup\\General\\Modules\\Macros\\MyProject.\nInfo:\u0026nbsp; Make sure to chose Directory Structure as self-contained. This makes sure that all files of your module are stored in a single directory. Press Next \u0026gt; to edit further properties. You have the opportunity to directly define the internal network of the macro module, for example by copying an existing network. In this case, we could copy the network of the local macro module Filter we already created. In addition, you have the opportunity to directly create a Python file. Python scripting can be used for the implementation of module interactions and other module functionalities. More information about Python scripting can be found here.\nProjectWizard1 ProjectWizard2 Structure of global macro modules After creating your global macro module, you can find the created project MyProject in your package. This project contains your macro module Filter. For the macro module exist three files:\nFilter.def: Module definition file Filter.mlab: Network file which contains the internal network of your macro module Filter.script: MDL script file, which defines in- and outputs of your macro module as well as fields. This file defines the module panel, as well as references to python scripts. In addition, two folders may be created:\nmhelp: contains the help files of all modules of this project network: contains the example networks of all modules of this project Structure of global macro modules How to find global macro modules All available modules are categorized and can be found via [ Modules ] in the respective genre. After creating a global macro, the new module can be found via [ Modules \u0026rarr; Filters ]. In addition, you can now find your macro module via module search.\nFind module in menu Hint:\u0026nbsp; If you do not find your new global macro module, try to reload the module database. Reload module database Summary Via right-click [ Extras \u0026rarr; Convert To Global Module... ] global macro modules can be created out of local macro modules You can use the Project Wizard to create new macro modules You need to have a package structure to store your global macro module Global macro modules are available throughout projects and can be found via Module Search and under menu item [ Modules ]. ","tags":["Beginner","Tutorial","Macro","Macro Modules","Global Macro"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/helpfiles/","title":"Example 2.3: Creation of module help","summary":"Example 2.3: Creation of module help Generating help of a Macro Module is part of the video about Macro Modules from Example 2: Creation of Global Macro Modules \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this chapter, you will learn how to create a help page and an example network. For hands-on training, we will use the macro module Filter, which was created in the previous chapter.\nDepending on the way the macro module was created the default help page and example network might or might not exist.","content":"Example 2.3: Creation of module help Generating help of a Macro Module is part of the video about Macro Modules from Example 2: Creation of Global Macro Modules \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this chapter, you will learn how to create a help page and an example network. For hands-on training, we will use the macro module Filter, which was created in the previous chapter.\nDepending on the way the macro module was created the default help page and example network might or might not exist. In case they exist, the help page only contains information about module in- and outputs as well as module fields. The example network only contains the macro module itself. Both, the help page and the example network, can be created and edited after module creation.\nSteps to do Creation of help files using MeVisLab MATE We will start by creating a help file using the build in text editor MeVisLab MATE (MeVisLab Advanced Text Editor). If you open the context menu of your global macro module and select [ Help ], it might be, that no help page is given. We will start to create a help file by selecting [ Help \u0026rarr; Create Help ]. If a help page already exists, select [ Help \u0026rarr; Edit Help ].\nCreation of module help MeVisLab MATE opens. An *.mhelp file (Filter.mhelp) is created automatically and is stored in the folder your macro module Filter is stored in. You can find the folder structure in MATE on the left side. Editing the text field, you can edit the help file.\nEdit module help file via MATE When creating the help file of a module, all important information of the module down to the field specifications are extracted and created automatically. Thus, the basic module information is always available in the module help. Additional documentation should be added by the module author. On the left side, you can find the outline of the help file. Each section can be edited. In this example, we added the purpose of the module to the help file.\nEdit module help file via MATE MATE offers the possibility to format the text. By using the button M, module names can be formatted in such a way that links to the respective help file of the modules are created.\nEdit module help file via MATE After finishing your documentation, you can click Generate Help or F7 and your final help file is generated.\nExtra Infos:\u0026nbsp; More information on MeVisLab MATE can be found here\nThe Module Help Editor is explained here\nThe result can be seen when opening the help file via context menu in MeVisLab IDE (or by pressing F1 ).\nHelp file of the module Watch out:\u0026nbsp; Depending on the way the macro module was created, more or less features are automatically given in the help file and the example network. All missing features can be added manually. Creation of an example network To add an example network to your module, you need to add a reference to the respective *.mlab file to the module definition file (.def). Open the file Filter.def. You can find the line exampleNetwork = \u0026ldquo;$(LOCAL)/networks/FilterExample.mlab\u0026rdquo;, which defines the reference to the *.mlab file containing the example network. Per default the name of the example network is ModulenameExample.mlab. An *.mlab file containing only the module Filter is created insight the folder networks.\nIt is possible that the reference to the example network or the file FilterExample.mlab is missing. One reason could be, that its creation was not selected when creating the macro module. In this case, add the reference and the file manually.\nReference to Example Network To create the example network, open the file FilterExample.mlab in MeVisLab and create an appropriate example.\nExample Network Summary MeVisLab MATE is a build-in text editor which can be used to create module help files, module panels or to create module interactionss via Python scripting. You can create help files via the module context menu using MeVisLab Mate. You can add an example network to your macro module via the .def file ","tags":["Beginner","Tutorial","Macro","Macro Modules","Global Macro","Help"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/guidesign/","title":"Example 2.4: GUI development","summary":"Example 2.4: Building a Panel Layout: Interactions with Macro Modules \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction This chapter will give you an introduction into the creation of module panels and user interfaces. For the implementation you will need to use the MeVisLab Definition Language (MDL) .\nExtra Infos:\u0026nbsp; More information about GUI design in MeVisLab can be found here Creating a panel for the macro module flilter Creation of a module panel In Example 2.","content":"Example 2.4: Building a Panel Layout: Interactions with Macro Modules \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction This chapter will give you an introduction into the creation of module panels and user interfaces. For the implementation you will need to use the MeVisLab Definition Language (MDL) .\nExtra Infos:\u0026nbsp; More information about GUI design in MeVisLab can be found here Creating a panel for the macro module flilter Creation of a module panel In Example 2.2 we created the global macro module Filter. By now, this module does not have a proper panel. When double-clicking the module, the Automatic Panel is shown.\nThe Automatic Panel contains fields, as well as module in and outputs. In this case, no fields exists except the instanceName. Accordingly, there is no possibility to interact with the module. Only the input and the output of the module are given.\nAutomatic Panel To add and edit a panel, open the context menu and select [ Related Files \u0026rarr; Filter.script ]. The text-editor MATE opens. You can see the file Filter.script, which you can edit to define a custom User Interface for the Module.\nModule script file Module interface Per default, the *.script file contains the interface of the module. In the interface section (everything insight the curled brackets behind the name Interface) you can define the module inputs, the module outputs and also all module fields (or Parameters).\nFilter.script\nInterface { Inputs { Field input0 { internalName = Convolution.input0 } } Outputs { Field output0 { internalName = Arithmetic2.output0 } } } Module inputs and outputs To create an input/output, you need to define a Field in the respective input/output environment. Each input/output gets a name (here input0/output0) which you can use to reference this field. The module input maps to an input of the internal network. You need to define this mapping. In this case the input of the macro module Filter maps to the input of the module Convolution of the internal network (internalName = Convolution.input0). Similarly, you need to define which output of the internal network maps to the output of the macro module Filter. In this example, the output of the internal module Arithmethic2 maps to the output of our macro module Filter (internalName = Arithmetic2.output0).\nCreating an input/output causes:\nInput/output connectors are added to the module. You can find placeholders for the input and output in the internal network (see image). Input/output fields are added to the automatic panel. A description of the input/output fields is automatically added to the module help file, when opening the *.mhelp file after input/output creation. Helpfile creation is explained in Example 2.3. Internal Network of your macro module Module fields In the environment Parameters you can define fields of your macro module. These fields may map to existing fields of the internal network (internalName = \u0026hellip; ), but they do not need to and can also be completely new. You can reference these fields when creating a panel, to allow interactions with these fields. All fields appear in the Automatic Panel.\nModule panel layout To create your own User Interface, we need to create a Window . A window is one of the layout elements which exist in MDL. These layout elements are called controls . The curled brackets define the window environment, in which you can define properties of the window and insert further controls like a Box .\nInitially, we call the window MyWindowTitle, which can be used to reference this window.\nDouble-clicking on your Module now opens your first self developed User Interface.\nFilter.script\nInterface { Inputs { Field input0 { internalName = Convolution.input0 } } Outputs { Field output0 { internalName = Arithmetic2.output0 } } Parameters { } } Window MyWindowName { title = MyWindowTitle Box MyBox { } } Module Panel You can define different properties of your control. For a window, you can for example define a title, or whether the window should be shown in full screen (fullscreen = True).\nThese properties are called tags and are individually different for each control. Which tags exist for the control window can be found here . The control box has different tags. You can for example define a title for the box, but you can not define whether to present the box in full screen.\nIf you like to add more than one control to your window, for example one box and one label, you can specify their design like in the following examples:\nFilter.script\nWindow MyWindowName { title = MyWindowTitle w = 100 h = 50 Vertical { Box MyBox { title = \u0026#34;Title of my Box\u0026#34; } Label MyLabel { title = \u0026#34;This is a label below the box\u0026#34; } } } Vertical layout of Box and Text Filter.script\nWindow MyWindowName { title = MyWindowTitle w = 100 h = 50 Horizontal { Box MyBox { title = \u0026#34;Title of my Box\u0026#34; } Label MyLabel { title = \u0026#34;This is a label below the box\u0026#34; } } } Horizontal layout of Box and Text There are much more controls, which can be used. For example a CheckBox, a Table, a Grid, a Button, ... . To find out more, take a look into the MDL Reference .\nModule interactions Until now, we learned how to create the layout of a panel. As a next step, we like to get an overview over interactions.\nExtra Infos:\u0026nbsp; You can add the Module GUIExample to your workspace and play around with is. Access to existing fields of the internal network To interact with fields of the internal network in your User Interface, we need to access these fields. To access the field of the internal module Convolution, which defines the kernel, we need to use the internal network name. To find the internal field name, open the internal network of the macro module Filter (click on the module using the middle mouse button ).\nThen, open the panel of the module Convolution and right-click the field title Use of the box Predefined Kernel and select Copy Name. You now copied the internal network name of the field to your clipboard. The name is made up of ModuleName.FieldName, in this case Convolution.predefKernel.\nConvolution Module In the panel of the module Convolution, you can change this variable Kernel via a drop-down menu. In MDL a drop-down menu is called a ComboBox . We can take over the field predefKernel, its drop-down menu and all its properties by creating a new field in our panel and reference to the internal field Convolution.predefKernel, which already exist in the internal network.\nChanges of the properties of this field can be done in the curled brackets using tags (here, we changed the title).\nFilter.script\nWindow MyWindowName { title = MyWindowTitle Field Convolution.predefKernel { title = Kernel } } Selecting the kernel As an alternative, you can define the field kernel in the Parameters environment, and reference the defined field by its name. The result in the panel is the same. You can see a difference in the Automatic Panel. All fields, which are defined in the interface in the Parameters environment appear in the Automatic Panel. Fields of the internal network, which are used but not declared in the section Parameters of the module interface do not appear in the Automatic Panel.\nFilter.script\nInterface { Inputs { Field input0 { internalName = Convolution.input0 } } Outputs { Field output0 { internalName = Arithmetic2.output0 } } Parameters { Field kernel { internalName = Convolution.predefKernel title = Kernel: } } } Window MyWindowName { title = MyWindowTitle Field kernel {} } Commands We can not only use existing functionalities, but also add new interactions via Python scripting.\nIn below example we added a wakeupCommand to the Window and a simple command to the Button.\nFilter.script\nWindow MyWindowName { title = MyWindowTitle wakeupCommand = myWindowCommand Button MyButton { command = myButtonAction } } The wakeupCommand defines a Python function which is executed as soon as the Window is opened. The Button command is executed when the user clicks on the Button.\nBoth commands reference a Python function which is executed whenever both actions (open the Window or click the Button) are executed.\nIf you like to learn more about Python scripting, take a look at Example 2.5.\nWe need to define the Python script, which contains our Python functions. In order to do this, add a Command section outside your window and define the tag source.\nExample: Filter.script\nCommands { source = $(LOCAL)/Filter.py } Infos:\u0026nbsp; The section Source should already be available and generated automatically in case you enable the Wizard to add a Python file to your Module. You can right-click on the command (myWindowCommand or myButtonAction) in your *.script file and select [ Create Python Funtion...... ]. The text editor MATE opens automatically and generates an initial Python function for you. You can simply add a logging function or implement complex logic here.\nExample: Filter.py\ndef myWindowCommand: MLAB.log(\u0026#34;Window opened\u0026#34;) def myButtonAction: MLAB.log(\u0026#34;Button clicked\u0026#34;) Available examples MeVisLab provides a lot of example modules for GUI development. All of these examples provides the *.script file for UI development and the *.py file containing the Python script.\nLayouting examples TestVerticalLayout Module TestHorizontalLayout Module TestTableLayout Module TestGridLayout Module TestSplitterLayout Module TestBoxLayout Module TestTabViewLayout Module Other examples TestHyperText Module TestListBox Module TestListView Module TestIconView Module TestPopupMenu Module TestViewers Module TestEventFilter Module TestStyles Module TestButtonGroups Module TestImageMap Module Please use the Module Search with the prefix Test for more examples.\nSummary User interfaces and several module panels can be created for each macro module. You can create a panel, define inputs and outputs as well as interactions, in your *.script file in MATE by using the MeVisLab Definition Language (MDL) . Module interactions can be implemented using commands, which are linked to Python functions. You can implement field listeners, which trigger actions after a field value changes. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Macro","Macro Modules","Global Macro","User Interface","GUI"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/pythonscripting/","title":"Example 2.5: Interactions via Python scripting","summary":"Example 2.5: Module Interactions Using Python Scripting Introduction This chapter will give you an overview over Python scripting in MeVisLab. Here, no introduction into Python will be given. However, basic knowledge in Python is helpful. Instead, we will show how to integrate and use Python in the MeVisLab SDK.\nIn fact, nearly everything in MeVisLab can be done via Python scripting: You can add modules to your network, or remove modules, you can dynamically establish and remove connections and so on.","content":"Example 2.5: Module Interactions Using Python Scripting Introduction This chapter will give you an overview over Python scripting in MeVisLab. Here, no introduction into Python will be given. However, basic knowledge in Python is helpful. Instead, we will show how to integrate and use Python in the MeVisLab SDK.\nIn fact, nearly everything in MeVisLab can be done via Python scripting: You can add modules to your network, or remove modules, you can dynamically establish and remove connections and so on. But, much more important: You can access module inputs and outputs, as well as module fields to process their parameters and data. You can equip user interfaces and panel with custom functionalities. Python can be used to implement module interactions. When you open a panel or you press a button in a panel, the executed actions are implemented via Python scripting.\nBasics To see how to access modules, fields, and so on, open the Scripting Console Via [ Scripting \u0026rarr; Show Scripting Console ].\nInternal field names You can find the internal name of one module field in the respective network. Open a panel, for example the Automatic Panel and right-click the field\u0026rsquo;s title to open the field\u0026rsquo;s context menu. Now, you can select Copy Name, to copy the internal name of the field. This name can be used to access the field via scripting.\nScripting context When entering ctx to the console, you can see the context you are working with. In the context of the Scripting Console, you have access to your workspace, meaning the whole network, its modules and the module fields.\nScripting context Editing the workspace In the Scripting Console, you can add and connect modules using the following commands:\nctx.addModule(\u0026quot;\u0026lt; ModuleName \u0026gt;\u0026quot;) : Add the desired module to your workspace. ctx.field(\u0026quot; \u0026lt; ModuleName.FieldName\u0026gt; \u0026quot;) : Access a field of a module. ctx.field(\u0026quot; \u0026lt; ModuleInput \u0026gt; \u0026quot;).conntectFrom(\u0026quot; \u0026lt; ModuleOutput \u0026gt; \u0026quot;) : Draw a connection from one module\u0026rsquo;s output to another module\u0026rsquo;s input. In this case we added the modules DicomImport and View2D to the workspace and connected both modules.\nAdd and connect modules via scripting It is also possible to add notes to your workspace.\nAdd a note to your workspace Access modules and module fields You can access modules via ctx.module(\u0026quot; \u0026lt; ModuleName \u0026gt; \u0026quot;). From this object, you can access module fields, module inputs and outputs and everything in context of this module.\nYou can also directly access a module field via ctx.field(\u0026quot; \u0026lt; ModuleName.FieldName \u0026gt; \u0026quot;). Different methods can be called on this object. Take a look at the Scripting Reference to find out which methods can be called for which object or class. You can for example access the value of the respective field.\nAccess modules and module fields Python Scripting Reference Here , you can find the Scripting Reference. In the Scripting Reference you can find information about different Python classes used in MeVisLab and their methods.\nWhere and how to use Python scripting Scripting View Under [ View \u0026rarr; Views \u0026rarr; Scripting ] you can find the View Scripting. The view offers a standard Python console, without any meaningful network or module context. This means only general Python functionalities can be tested and used. Access to modules or your network is not possible.\nScripting Console You can open the Scripting Console via [ Scripting \u0026rarr; Show Scripting Console ]. In the context of your workspace, you can access your network and modules.\nScripting console of modules Every module offers a scripting console. Open the context menu of a module and select [ Show Window \u0026rarr; Scripting Console ]. You can work in the context (ctx.) of this module.\nModule RunPythonScript The module RunPythonScript allows to execute Python scripts from within a MeVisLab network. You can draw parameter connection from modules to RunPythonScript and back, to process parameter fields using Python scripting. An example for the usage of RunPythonScript can be found here.\nModule interactions via Python scripting You can reference to a Python function inside a *.script file of a macro module. With this, you can for example execute a Python function, whenever you open a panel, define the action which is executed when pressing a button or specify the command triggered by a field listener. An example for module interactions via Python scripting is given in the same example.\nTips and tricks Scripting Assistant Under [ View \u0026rarr; Views \u0026rarr; Scripting Assistant ] you can find the view Scripting Assistant. In this view, the actions you execute in the workspace are translated into Python script.\nFor example: Open the Scripting Assistant. Add the module WEMInitialize to your workspace. You can select a Model, for example the cube. In addition, you can change the Translation and press Apply. All these actions can be seen in the Scripting Assistant, translated into Python code. Therefore, the Scripting Assistant is a powerful tool to help you to script you actions.\nScripting Assistant Examples See the following examples for Python Scripting:\nThe module RunPythonScript Module interactions via Python scripting Summary Python can be used to access, create and process networks, modules, fields and panels. You can use Python via different scripting consoles. You can also define custom module interactions by referencing to Python functions from the *.script file ","tags":["Beginner","Tutorial","Macro","Macro Modules","Global Macro","Python","Scripting"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/scriptingexample1/","title":"Example 2.5.1: The module RunPythonScript","summary":"Example 2.5.1: The module RunPythonScript \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction The module RunPythonScript allows to execute Python scripts from within a MeVisLab network. You can draw parameter connection from modules to RunPythonScript and back, to process parameter fields using Python scripting.\nSteps to do Develop your network In this example, we like to dynamically change the color of a cube in an Open Inventor scene. For that, add and connect the following modules as shown.","content":"Example 2.5.1: The module RunPythonScript \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction The module RunPythonScript allows to execute Python scripts from within a MeVisLab network. You can draw parameter connection from modules to RunPythonScript and back, to process parameter fields using Python scripting.\nSteps to do Develop your network In this example, we like to dynamically change the color of a cube in an Open Inventor scene. For that, add and connect the following modules as shown.\nRunPythonScript Scripting using the moduule RunPythonScript Open the panel of RunPythonScript. There is an option to display input and output fields. For that, tick the box Fields on the top left side of the panel.\nYou can also name these fields individually, by ticking the box Edit field titles. Call the first input field TimeCounter and draw a parameter connection from the field Value of the panel of TimeCounter to the input field TimeCounter of the module RunPythonScript. We can name the first output field DiffuseColor and draw a parameter connection from this field to the field Diffuse Color in the panel of the module SoMaterial.\nTimeCounter The module TimeCounter counts in a defined Frequency. We like to randomly change the color of the cube in the frequency the TimeCounter counts. Add this code:\nIsoCSOs.py\nimport random red = TimeCounter * random.randrange(0,52)/255 green = TimeCounter * random.randrange(0,52)/255 blue = TimeCounter * random.randrange(0,52)/255 updateOutputValue(\u0026#34;DiffuseColor\u0026#34;, str(red) + \u0026#34; \u0026#34; + str(green) + \u0026#34; \u0026#34; + str(blue)) To update the output field DiffuseColor, it is important to use the methods updateOutputValue(name, value) or setOutputValue(name, value) instead of simply assigning a value to the output field.\nYou can now see a color change in the viewer SoExaminerViewer every time the TimeCounter counts.\nTriggered color change Summary The module RunPythonScript can be used to process module fields in your network using Python scripting. Use the methods updateOutputValue(name, value) or setOutputValue(name, value) to update output fields of RunPythonScript. ","tags":["Beginner","Tutorial","Python","Scripting","RunPythonScript"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/scriptingexample2/","title":"Example 2.5.2: Module interactions via Python scripting","summary":"Example 2.5.2: Module interactions via Python scripting \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, you will learn how to add Python scripting to your User Interface. The network used in Chapter V will be used for creating the Macro Module.\nSteps to do Creating the macro module First, we condense the example network into a macro module and then we create a panel for that module. To create a macro module use the Project Wizard, which you find under [ File \u0026rarr; Run Project Wizard ].","content":"Example 2.5.2: Module interactions via Python scripting \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, you will learn how to add Python scripting to your User Interface. The network used in Chapter V will be used for creating the Macro Module.\nSteps to do Creating the macro module First, we condense the example network into a macro module and then we create a panel for that module. To create a macro module use the Project Wizard, which you find under [ File \u0026rarr; Run Project Wizard ]. Select Macro Module and press Run.\nNow, you have to edit:\nName: The name of your module Package: Select the package you like to save the macro module in. Directory Structure: Change to Self-contained Project: Select you project name Press Next and edit the following:\nCopy existing network: Select the example network Check the box: Add Python file Now, create your macro module and reload MeVisLab. You can find your module via search in MeVisLab.\nCreating macro module Enable Python scripting To design a panel and create a user interface for the macro module, open the *.script file. You can see, that a Command environment exist, which defines the python file as source for all commands.\nOpen the script file Script file Creating a panel with tabs and viewers At first, we create a Window with two Tabs . One Main tab, in which both viewers of the network are represented and one tab for Settings. For generating tabs, we can use the control TabView , with its items TabViewItem . The control TabView enables to add a command, which is executed when opening the tab. For adding the viewers to the panel, we use the Control Viewer.\nIsoCSOs.script\nWindow { TabView { TabViewItem Main { Horizontal { Viewer View2D.self { type = SoRenderArea pw = 400 ph = 400 } Viewer SoExaminerViewer.self { type = SoExaminerViewer pw = 400 ph = 400 } } } TabViewItem Settings { } } } Panel with Tabs and Viewers Edit viewer settings in the panel You may want to change the design setting of the right viewer. This is still possible via the internal network of the macro module. Open the internal network either via the context menu or using the middle mouse button and click on the module. After that, open the Automatic Panel of the module SoExaminerViewer via context menu [ Show Windows \u0026rarr; Automatic Panel ] and change the field decoration to False. Keep in mind, as we did not create CSOs by now, the right viewer stays black.\nChange viewer settings Changed viewer settings Selection of images Next, we like to add the option to browse through the folders and select the image, we like to create CSOs from. This functionality is already given in the internal network in the module LocalImage. We can copy this functionality from LocalImage and add this option to the panel above both viewers. But, how should we know, which field name we reference to? To find this out, open the internal network of your macro module. Now you are able to open the panel of the module LocalImage. Right-click the desired field: In this case, right-click the label Name:. Select Copy Name, to copy the internal name of this field.\nCopy the field name Now, you can add this field as a new field to your window by pasting the name. All field settings are taken over from the internal field from the module LocalImage.\nIsoCSOs.script\nWindow { TabView { TabViewItem Main { Vertical { Field LocalImage.name {} Horizontal { Viewer View2D.self { type = SoRenderArea pw = 400 ph = 400 } Viewer SoExaminerViewer.self { type = SoExaminerViewer pw = 400 ph = 400 } } } } TabViewItem Settings { } } } Add name field Add buttons to your panel As a next step, we like to add a Browse...-Button, like in the module LocalImage, and also a button to create the CSOs.\nTo create the Browse...-Button:\nCreate a button containing the command fileDialog. Right-click the command to create the respective function in the Python file. Edit the function in the Python file, to enable the file dialog (similar function as in LocalImage.py). To create the Iso Generator Button:\nWe like to copy the field of the Update-Button from the internal module IsoCSOGenerator, but not its layout so:\nCreate a new Field in the interface, called IsoGenerator, which contains the internal field Update from the module IsoCSOGenerator. Create a new Button in your Window which uses the field IsoGenerator. After these steps, you can use the Iso Generator button to create CSOs.\nIsoCSOs.script\nInterface { Inputs {} Outputs {} Parameters { Field IsoGenerator { internalName = CSOIsoGenerator.apply } } } Commands { source = $(LOCAL)/IsoCSOs.py } Window { TabView { TabViewItem Main { Vertical { Horizontal { Field LocalImage.name {} Button { title = \u0026#34;Browse...\u0026#34; command = fileDialog } Button IsoGenerator { title = \u0026#34;Iso Generator\u0026#34; } } Horizontal { Viewer View2D.self { type = SoRenderArea pw = 400 ph = 400 } Viewer SoExaminerViewer.self { type = SoExaminerViewer pw = 400 ph = 400 } } } } TabViewItem Settings { } } } IsoCSOs.py\nfrom mevis import * def fileDialog(): exp = ctx.expandFilename(ctx.field(\u0026#34;LocalImage.name\u0026#34;).stringValue()) filename = MLABFileDialog.getOpenFileName(exp, \u0026#34;\u0026#34;, \u0026#34;Open file\u0026#34;) if filename: ctx.field(\u0026#34;LocalImage.name\u0026#34;).value = ctx.unexpandFilename(filename) Automatically generate CSOs based on Iso value Colorizing CSOs We like to colorize the CSO we hover over with our mouse in the 2D viewer. Additionally, when clicking a CSO with the left mouse key , this CSO shall be colorized in the 3D viewer. This functionality can be implemented via Python scripting (even though MeVisLab has a build-in function to do that). We can do this in the following way:\nEnable the View Scripting Assistant, which translates actions into Python code.\nScripting Assistant Enable a functionality which allows us to notice the id of the CSO we are currently hovering over with our mouse. For this open the internal network of our macro module. We will use the module SoView2DCSOExtensibleEditor. Open its panel and select the tab Advanced. You can check a box to enable Update CSO id under mouse. If you now hover over a CSO, you can see its id in the panel. We can save the internal network to save this functionality, but we can also solve our problem via scripting. The Scripting Assistant translated our action into code, which we can use.\nEnabling CSO id identification We like to activate this functionality when opening the panel of our macro module IsoCSOs. Thus, we add a starting command to the control Window. We can call this command for example enableFunctionalities.\nIn the *.script file:\nIsoCSOs.script\nWindow { windowActivatedCommand = enableFunctionalities TabView { TabViewItem Main { ... } } } In the Python file, we define the function enableFunctionalities. We see our action as Python code in the Scripting Assistant. Just copy the code into our Python function.\nIsoCSOs.py\ndef enableFunctionalities(): ctx.field(\u0026#34;SoView2DCSOExtensibleEditor.updateCSOIdUnderMouseCursor\u0026#34;).value = True Implement a field listener. This field listener will detect when you hover over a CSO and the CSO id changes. Triggered by a CSO id change, a colorization function will be executed, which will colorize the selected CSO. In the *.script file:\nIsoCSOs.script\nCommands { source = $(LOCAL)/IsoCSOs.py FieldListener SoView2DCSOExtensibleEditor.csoIdUnderMouseCursor { command = colorizeCSO } } In the Python file:\nIsoCSOs.py\n# global variables listCSOs = [] idxCSO = -1 def colorizeCSO(): if ctx.field(\u0026#34;CSOManager.numCSOs\u0026#34;) == 0: pass else: global listCSOs global idxCSO if listCSOs == []: listCSOs = ctx.field(\u0026#34;CSOManager.outCSOList\u0026#34;).object() # COLORIZATION OF CSO # Changing back color of previously selected CSO to default value if idxCSO \u0026gt;= 0: oldCSO = listCSOs.getCSOAt(idxCSO) oldCSO.setPathPointColor((1.0, 1.0, 0.0)) # Color change of CSO oldCSO.setPathPointWidth(1) # Line width change # Changing color and width of selected CSO idxCSO = ctx.field(\u0026#34;SoView2DCSOExtensibleEditor.csoIdUnderMouseCursor\u0026#34;).value - 1 # -1 because CSOs are indexed starting at 1 if idxCSO \u0026gt;= 0: currentCSO = listCSOs.getCSOAt(idxCSO) currentCSO.setPathPointColor((1.0, 0.0, 1.0)) currentCSO.setPathPointWidth(5) Reload your module ( F5 ) and open the panel. After generating CSOs, the CSO under your mouse is marked. Clicking this CSO enables the marking in the 3D viewer. If you like, you can add some settings to your Settings page. For example\nIsoCSOs.script\nTabViewItem Settings { Field CSOIsoGenerator.isoValue {} Field SoCSOVisualizationSettings.ghostingDepthInVoxel {} } Colored selection Summary The control Tabview creates tabs in panels. The control Viewer allows to add viewers to your panel. The control Button creates a button executing a Python function when pressed. The tag WindowActivationCommand of the control Window triggers Python functions executed when opening the panel. Field listeners can be used to activate Python functions triggered by a change of defined parameter fields. Use the view Scripting Assistant can be used to translate actions into Python code. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Macro","Macro Modules","Global Macro","Python","Scripting"],"section":"tutorials"},{"date":"1655276324","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/macromodules/viewerexample/","title":"Example 3: Creating a simple application","summary":"Example 3: Creating a simple application Introduction In the previous examples, you already learned how to create Macro Modules, user interfaces and how to interact with your UI via Python scripting.\nIn this example, you will learn how to create a simple Prototype application in MeVisLab including a User Interface with 2D and 3D viewer. You will learn how to implement field listeners and react on events.\nSteps to do Create your network Start with an empty network and add the Module ImageLoad to your workspace.","content":"Example 3: Creating a simple application Introduction In the previous examples, you already learned how to create Macro Modules, user interfaces and how to interact with your UI via Python scripting.\nIn this example, you will learn how to create a simple Prototype application in MeVisLab including a User Interface with 2D and 3D viewer. You will learn how to implement field listeners and react on events.\nSteps to do Create your network Start with an empty network and add the Module ImageLoad to your workspace. Then add a View2D and View3D to your workspace and connect the modules as seen below.\nLoading and viewing images Load an image Now double-click on the ImageLoad module and open any image. You can use the included file ./MeVisLab/Resources/DemoData/MRI_Head.dcm.\nOpening your viewers should now show the images in 2D and 3D.\nShow images in 2D and 3D Save your network Now, save your network as *.mlab file and remember the location.\nCreate a Macro Module Open the Project Wizard via [ File \u0026rarr; Run Project Wizard ] and run Wizard for a Macro Module. Name your module MyViewerApplication, enter your details and click Next \u0026gt;.\nModule Properties On the next screen, make sure to add a Python file and use the existing network you previously saved. Click Next \u0026gt;.\nMacro Module Properties You can leave all fields empty for now and just click Create.\nModule Field Interface MeVisLab reloads its internal database and you can open a new Tab. Search for your newly created module, in our case it was MyViewerApplication.\nMyViewerApplication In case you double-click your module now, you will see the Automatic Panel only showing the name of your module, because we did not add any own Window until now.\nDevelop your User Interface Before adding your own UI, open internal network of your Macro Module via right-click and [ Show Internal Network ]. Open the panel of your ImageLoad module and set filename to an empty string (clear). This is necessary for later.\nNow, right-click on your MyViewerApplication and select [ Related Files \u0026rarr; MyViewerApplication.script ]\nMATE opens showing your script file. You already learned how to create simple UI elements in Example 2.4. Now we will create a little more complex UI including your View2D and View3D.\nFirst we need a new Field in your Parameters section. Name the field filepath and set internalName to ImageLoad.filename.\nMyViewerApplication.script\nInterface { Inputs {} Outputs {} Parameters { Field filepath { internalName = ImageLoad.filename } } } We now re-use the filepath field from the ImageLoad module for our interface. Add a Window and a Vertical to the bottom of your *.script file. Add the just created parameter field filepath inside your Vertical as seen below.\nMyViewerApplication.script\nInterface { Inputs {} Outputs {} Parameters { Field filepath { internalName = ImageLoad.filename } } } Commands { source = $(LOCAL)/MyViewerApplication.py } Window { Vertical { Field filepath {} } } If you now double-click on your module, you can see your just created filepath field.\nFilepath field in UI Next, we will add your 2D and 3D Viewers and a Button to your Window. Change your *.script file as seen below:\nMyViewerApplication.script\nWindow { Vertical { Horizontal { Field filepath {} Button { title = \u0026#34;Reset\u0026#34; } } Horizontal { Viewer View2D.self { type = SoRenderArea pw = 400 ph = 400 expandX = yes expandY = yes } Viewer View3D.self { pw = 400 ph = 400 expandX = yes expandY = yes } } } } We have a vertical Layout having 2 items placed horizontally next to each other. The new Button gets the title Reset but does nothing, yet because we did not add a Python function to a command.\nAdditionally we added the View2D and the View3D to our Window and defined the height, width and the expandX/Y property to yes. This leads our viewers to resize together with our Window.\nExtra Infos:\u0026nbsp; Additional information about the View2D and View3D options can be found in the MeVisLab MDL Reference You can now play around with your module in MeVisLab SDK. Open the Window and select a file. You can see the 2 viewers showing the 2D and 3D images. You can interact with your viewers the same way as in your MeVisLab network. All functionalities are taken from the modules and transferred to your user interface.\n2D and 3D viewers in our application Develop a python function for your Button Next we want to reset the filepath to an empty string on clicking our Reset button. Add the reset command to your Button. MyViewerApplication.script\n... Button { title = \u0026#34;Reset\u0026#34; command = reset } ... Right-click on reset and select [ Create Python function \u0026#39;reset\u0026#39; ]. MATE opens the Python file of your module and automatically adds the function definition. Set the filename of the ImageLoad module to an empty string.\nMyViewerApplication.py\nfrom mevis import * def reset(): ctx.field(\u0026#34;filepath\u0026#34;).value = \u0026#34;\u0026#34; Clicking on Reset in your module now clears the filename field and the viewers do not show any images anymore.\nField listeners A field listener watches a given field in your network and reacts on any changes of the field value. You can define Python functions to execute in case a change has been detected.\nIn order to define such a listener, you need to add it to the Commands section in your *.script file.\nExample: MyViewerApplication.script\nCommands { source = $(LOCAL)/MyViewerApplication.py FieldListener View2D.startSlice { command = printCurrentSliceNumber } } In the above example, we react on changes of the field startSlice of the module View2D. Whenever the field value (currently displayed slice) changes, the Python function printCurrentSliceNumber is executed.\nIn your Python file Filter.py you can now add the following:\nFilter.py\ndef printCurrentSliceNumber(field): MLAB.log(field.value) Scrolling through slices in the View2D module now logs a message containing the slice number currently visible to the MeVisLab Debug Output.\nSummary You can add any Viewers to your application UI by reusing them in MDL. Parameter Fields using the internalName of an existing field in your network allows re-using this UI element in your own UI. Changes in your UI are applied to the field in the module. Field Listeners allow reacting on changes of a field value in Python. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Macro","Macro Modules","Global Macro","Python","Scripting"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/thirdparty/assimp/","title":"assimp","summary":"Asset-Importer-Lib (assimp) Introduction Assimp (Asset-Importer-Lib) is a library to load and process geometric scenes from various 3D data formats.\nThis chapter provides some examples of how 3D formats can be imported into MeVisLab. In general you always need a SoSceneLoader module. The SoSceneLoader allows to load meshes as Open Inventor points/lines/triangles/faces using the Open Asset Import Library.\nSoSceneLoader You can also use the SoSceneWriter module to export your 3D scenes from MeVisLab into any of the output formats listed below.","content":"Asset-Importer-Lib (assimp) Introduction Assimp (Asset-Importer-Lib) is a library to load and process geometric scenes from various 3D data formats.\nThis chapter provides some examples of how 3D formats can be imported into MeVisLab. In general you always need a SoSceneLoader module. The SoSceneLoader allows to load meshes as Open Inventor points/lines/triangles/faces using the Open Asset Import Library.\nSoSceneLoader You can also use the SoSceneWriter module to export your 3D scenes from MeVisLab into any of the output formats listed below.\nFile formats The Assimp-Lib currently supports the following file formats:\n3D Manufacturing Format (.3mf) Collada (.dae, .xml) Blender (.blend) Biovision BVH (.bvh) 3D Studio Max 3DS (.3ds) 3D Studio Max ASE (.ase) glTF (.glTF) glTF2.0 (.glTF) KHR_lights_punctual ( 5.0 ) KHR_materials_pbrSpecularGlossiness ( 5.0 ) KHR_materials_unlit ( 5.0 ) KHR_texture_transform ( 5.1 under test ) FBX-Format, as ASCII and binary (.fbx) Stanford Polygon Library (.ply) AutoCAD DXF (.dxf) IFC-STEP (.ifc) Neutral File Format (.nff) Sense8 WorldToolkit (.nff) Valve Model (.smd, .vta) Quake I (.mdl) Quake II (.md2) Quake III (.md3) Quake 3 BSP (.pk3) RtCW (.mdc) Doom 3 (.md5mesh, .md5anim, .md5camera) DirectX X (.x) Quick3D (.q3o, .q3s) Raw Triangles (.raw) AC3D (.ac, .ac3d) Stereolithography (.stl) Autodesk DXF (.dxf) Irrlicht Mesh (.irrmesh, .xml) Irrlicht Scene (.irr, .xml) Object File Format ( .off ) Wavefront Object (.obj) Terragen Terrain ( .ter ) 3D GameStudio Model ( .mdl ) 3D GameStudio Terrain ( .hmp ) Ogre ( .mesh.xml, .skeleton.xml, .material ) OpenGEX-Fomat (.ogex) Milkshape 3D ( .ms3d ) LightWave Model ( .lwo ) LightWave Scene ( .lws ) Modo Model ( .lxo ) CharacterStudio Motion ( .csm ) Stanford Ply ( .ply ) TrueSpace (.cob, .scn) XGL-3D-Format (.xgl) ","tags":["Beginner","Tutorial","assimp","3D"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/basic_mechanisms/","title":"Basic Mechanisms","summary":"Basic Mechanism Examples: The following examples are available:\n[1] Contour Filter [2] Creating a simple application [3] Panel for the contour filter [4] Python scripting ","content":"Basic Mechanism Examples: The following examples are available:\n[1] Contour Filter [2] Creating a simple application [3] Panel for the contour filter [4] Python scripting ","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/openinventor/","title":"Chapter II: Open Inventor","summary":"Open Inventor Modules Introduction Besides blue modules (ML Modules) and brown macro modules, there is a third type of modules, called Open Inventor modules. These modules are green and start with the letters So\\* (for Scene Objects). Open Inventor Modules process and render 3D scene objects and enable image interactions. Scene objects are transmitted via round input and output connectors. With the help of these modules, Open Inventor scenes can be implemented.","content":"Open Inventor Modules Introduction Besides blue modules (ML Modules) and brown macro modules, there is a third type of modules, called Open Inventor modules. These modules are green and start with the letters So\\* (for Scene Objects). Open Inventor Modules process and render 3D scene objects and enable image interactions. Scene objects are transmitted via round input and output connectors. With the help of these modules, Open Inventor scenes can be implemented.\nThis chapter will start with an example Open Inventor scene. Explanations to Open Inventor scenes will follow the example.\nOpen Inventor Scenes and Execution of Scene Graphs Inventor scenes are organized in structures called scene graphs. A scene graph is made up of nodes, which represent 3D objects to be drawn, properties of the 3D objects, nodes that combine other nodes and are used for hierarchical grouping, and others (cameras, lights, etc.). These nodes are accordingly called shape nodes, property nodes, group nodes and so on. Each node contains one or more pieces of information stored in fields. For example, the Sphere node contains only its radius, stored in its radius field. Open Inventor modules function as Inventor nodes, so they may have input connectors to add Inventor child nodes (modules) and output connectors to link themselves to Inventor parent nodes (modules).\nOpen Inventor Scenes:\u0026nbsp; The following shows the order in which the modules are executed. The red arrow shows the order of traversal, from top to bottom and left to right. The numbers designate the order in which each module is passed first, from 1 to 8. As shown in the example before, the order of transversal is important.\nTraversing in Open Inventor SoGroup and SoSeparator The SoGroup and Soseparator modules cam be used as a container for the child nodes. They both allow multiple inputs and combine the results as one single output as seen above. Nevertheless, there is a big difference in handling the traversal state of the scene graph.\nSoGroup vs. SoSeparator In the example above, we render 4 SoCone objects. The left side uses the SoSeparator modules, the right side uses the SoGroup. You can see a SoMaterial defining the cone object to be yellow on the left side. The SoMaterial is only applied to one cone, the other cone remains grey (default) because the SoSeparator isolates the separator\u0026rsquo;s children from the rest of the scene graph.\nOn the right side, we are using a SoGroup. The material of the cone is set to red. As the SoGroup module does NOT alter the traversal state in any way, the second cone in this group is also red.\nFor details, see the MeVisLab module reference for SoGroup and SoSeparator \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. Extra Info:\u0026nbsp; More Information about Open Inventor and Scene Graphs can be found here\nor else in the Open Inventor Overview\nand the Open Inventor Reference\n","tags":["Beginner","Tutorial","Open Inventor","3D"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/visualization/","title":"Chapter III: Visualization","summary":"Visualization in MeVisLab Introduction MeVisLab contains a whole toolkit to visualize data and images. 2D, 3D and 4D rendering is possible as well as the interaction with images and data objects.\nIn this chapter, we focus on 2D and 3D visualization and simple image interactions. Not only pixel- and voxel-based data can be visualized, but also scene objects and 3D scenes (see here).\nView2D and View3D An easy way to display data and images in 2D and 3D is by using the Modules View2D and View3D.","content":"Visualization in MeVisLab Introduction MeVisLab contains a whole toolkit to visualize data and images. 2D, 3D and 4D rendering is possible as well as the interaction with images and data objects.\nIn this chapter, we focus on 2D and 3D visualization and simple image interactions. Not only pixel- and voxel-based data can be visualized, but also scene objects and 3D scenes (see here).\nView2D and View3D An easy way to display data and images in 2D and 3D is by using the Modules View2D and View3D. What can you do with these viewers?\nView2D and View3D View2D Scroll through the slices using the mouse wheel and/or middle mouse button .\nChange the contrast of the image by clicking the right mouse button and move the mouse\nZoom in and out by pressing CTRL and middle mouse button Toggle between multiple timepoints (if available) via \u0026larr; ArrowLeft and \u0026rarr; ArrowRight More features can be found on the help page.\nAdditional Information:\u0026nbsp; In case you are not happy with the default View2D interactions, you can connect a View2DExtensions module for defining additional interactions like zoom or modify the behavior of the mouse buttons.\nView2DExtensions View3D Zoom in and out using the mouse wheel Drag the 3D objects via middle mouse button Change the contrast of the image by clicking the right mouse button and move the mouse\nRotate the object by pressing the left mouse button and move the object around. The present orientation is displayed by a cube in the bottom right corner.\nMore features, like recording movies, can be found on the help page.\nToggle between multiple timepoints (if available) via \u0026larr; ArrowLeft and \u0026rarr; ArrowRight Additional Information:\u0026nbsp; More Information about Image Processing in MeVisLab can be found here ","tags":["Beginner","Tutorial","Visualization","2D","3D"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/image_processing/","title":"Chapter IV: Image Processing","summary":"Image Processing in MeVisLab Digital image processing is the use of a digital computer to process digital images through an algorithm (see Wikipedia).\nMeVisLab provides multiple modules for image processing tasks, such as:\nFilters Masks Transformations Arithmetics Statistics For details about Image Processing in MeVisLab, see the MeVisLab Documentation In this chapter, you will find some examples for different types of image processing in MeVisLab.","content":"Image Processing in MeVisLab Digital image processing is the use of a digital computer to process digital images through an algorithm (see Wikipedia).\nMeVisLab provides multiple modules for image processing tasks, such as:\nFilters Masks Transformations Arithmetics Statistics For details about Image Processing in MeVisLab, see the MeVisLab Documentation In this chapter, you will find some examples for different types of image processing in MeVisLab.\n","tags":["Beginner","Tutorial","Image Processing"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/","title":"Chapter V: Data Objects","summary":"MeVisLab Tutorial Chapter V Data Objects in MeVisLab MeVisLab provides a lot of pre-defined data objects for usage such as Contours, Surface Objects (WEMs) and Markers.\nDifferences between these types are explained in the following chapters and example networks are built to learn how to use them.","content":"MeVisLab Tutorial Chapter V Data Objects in MeVisLab MeVisLab provides a lot of pre-defined data objects for usage such as Contours, Surface Objects (WEMs) and Markers.\nDifferences between these types are explained in the following chapters and example networks are built to learn how to use them.\n","tags":["Beginner","Tutorial","Data Objects","2D","Contours","3D","Surfaces"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/testing/","title":"Chapter VI: Testing","summary":"MeVisLab Tutorial Chapter VI Testing, Profiling and Debugging in MeVisLab The MeVisLab Integrated Development Environment (IDE) provides tools for writing automated tests in Python, profiling your network performance and debugging your Python code.\nIn this chapter, all of these tools will be explained.\nTesting The MeVisLab TestCenter is the starting point of your tests. Select [ File \u0026rarr; Run TestCaseManager ] to open the user interface of the TestCaseManager.\nMeVisLab TestCaseManager Test Selection The Test Selection allows you to define a selection of test cases to be executed.","content":"MeVisLab Tutorial Chapter VI Testing, Profiling and Debugging in MeVisLab The MeVisLab Integrated Development Environment (IDE) provides tools for writing automated tests in Python, profiling your network performance and debugging your Python code.\nIn this chapter, all of these tools will be explained.\nTesting The MeVisLab TestCenter is the starting point of your tests. Select [ File \u0026rarr; Run TestCaseManager ] to open the user interface of the TestCaseManager.\nMeVisLab TestCaseManager Test Selection The Test Selection allows you to define a selection of test cases to be executed. The list can be configured by defining a filter by manually selecting the packages (see Example 2.1: Package Creation) to be scanned for test cases. All test cases found in the selected packages are shown.\nOn the right side of the Test Selection tab, you can see a list of functions in the test case. Each list entry is related to a Python function. You can select the functions to be executed. If your test case contains a network, you can open the *.mlab file or edit the Python file in MATE.\nTest Reports The results of your tests are shown as a report after execution.\nTest Creation You can create your own test cases here. A package is necessary to store your network and Python file.\nConfiguration Here you can configure details of your tests and reports. The installation directory of your MeVisLab is configured automatically but maybe needs to be updated in case you have multiple versions of MeVisLab installed.\nProfiling Profiling allows you to get detailed information about the behavior of your modules and networks. You can add the profiling view via [ View \u0026rarr; Views \u0026rarr; Profiling ]. The Profiling will be shown in the Views Area of the MeVisLab IDE.\nMeVisLab Profiling With enabled profiling, your currently opened network will be inspected and the CPU and memory usage and many more details of each module and function are logged.\nDebugging Debugging can be enabled whenever the integrated text editor MATE is opened. Having a Python file opened, you can enable debugging via [ Debug \u0026rarr; Enable Debugging ]. You can define break points in Python, add variables to your watchlist and walk through your break points as known for other editors and debuggers.\nMeVisLab Debugging ","tags":["Beginner","Tutorial","Testing","Python","Automated Tests","Profiling","Debugging"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/summary/","title":"Chapter VII: Application Development","summary":"MeVisLab Tutorial Chapter VII Summary This chapter will summarize all previous chapters and you will develop a whole application in MeVisLab. The complete workflow from developing a prototype to delivering your final application to your customer is explained step-by-step.\nPrototype to Product Licensing:\u0026nbsp; Some of the features described here will require a separate license. Building an installable executable requires the MeVisLab ApplicationBuilder license. It extends the MeVisLab SDK so that you can generate an installer of your developed Macro Module.","content":"MeVisLab Tutorial Chapter VII Summary This chapter will summarize all previous chapters and you will develop a whole application in MeVisLab. The complete workflow from developing a prototype to delivering your final application to your customer is explained step-by-step.\nPrototype to Product Licensing:\u0026nbsp; Some of the features described here will require a separate license. Building an installable executable requires the MeVisLab ApplicationBuilder license. It extends the MeVisLab SDK so that you can generate an installer of your developed Macro Module.\nFree evaluation licenses of the MeVisLab ApplicationBuilder, time-limited to 3 months, can be requested at sales(at)mevislab.de.\nPrototype Step 1: Develop your network In the first step, you are developing an application based on the following requirements:\nRequirement 1: The application shall be able to load DICOM data. Requirement 2: The application shall provide a 2D and a 3D viewer. Requirement 3: The 2D viewer shall display the loaded images Requirement 4: The 2D viewer shall provide the possibility to segment parts of the image based on a RegionGrowing algorithm Requirement 4.1: It shall be possible to click into the image for defining a marker position for starting the RegionGrowing Requirement 4.2: It shall be possible to define a threshold for the RegionGrowing algorithm Requirement 5: The 2D viewer shall display the segmentation results as a semi-transparent overlay Requirement 5.1: It shall be possible to define the color of the overlay Requirement 6: The 3D viewer shall visualize the loaded data in a 3-dimensional volume rendering Requirement 7: The 3D viewer shall additionally show the segmentation result as a 3-dimensional mesh Requirement 8: The total volume of the segmented area shall be calculated and shown (in ml) Requirement 9: It shall be possible to toggle the visible 3D objects Requirement 9.1: Original data Requirement 9.2: Segmentation results Requirement 9.3: All Step 2: Create your Macro Module Your network will be encapsulated in a Macro Module for later application development. For details about Macro Modules, see Example 2.2: Global Macro Modules.\nStep 3: Develop a User Interface and add Python Scripting Develop the UI and Python Scripts based on your requirements from Step 1. The resulting UI will look like below mockup:\nUser Interface Design Review Step 4: Write automated tests for your Macro Module Test your Macro Module in MeVisLab. Your requirements from Step 1 are translated into test cases written in Python. The fields accessible via Python as defined in Step 2 shall be used to test your application.\nStep 5: Create an installable executable Create a standalone application by using the MeVisLab ApplicationBuilder and install the application on another system.\nRefine Step 6: Update your network and Macro Module Integrate feedback from customers having installed your executable and adapt your test cases from Step 4.\nStep 7: Update your installable executable Re-build your executable and release a new version of your application.\nThe above loop can easily be repeated until your product completely fulfills your defined requirements.\n","tags":["Advanced","Tutorial"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/thirdparty/","title":"Chapter VIII: ThirdParty components","summary":"MeVisLab Tutorial Chapter VIII Using ThirdParty software integrated into MeVisLab MeVisLab comes with a lot of software already integrated and ready to use. Even if these tools are not available as a module, like itk and vtk for example, they can be used via Python scripting. This chapter shall give some examples of how to use a selection of integrated ThirdParty components.\nOpenCV OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library.","content":"MeVisLab Tutorial Chapter VIII Using ThirdParty software integrated into MeVisLab MeVisLab comes with a lot of software already integrated and ready to use. Even if these tools are not available as a module, like itk and vtk for example, they can be used via Python scripting. This chapter shall give some examples of how to use a selection of integrated ThirdParty components.\nOpenCV OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV includes algorithms to:\ndetect and recognize faces, identify objects, classify human actions in video, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc. ","tags":["Advanced","Tutorial","ThirdParty"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/contours/contourexample1/","title":"Contour Example 1: Creation of Contours","summary":"Contour Example 1: Creation of Contours Introduction We like to start with the creation of CSOs. To create CSOs, you need a SoCSO*-Editor. There are several different editors, which can be used to create CSOs (see here). Some of them are introduced in this example.\nSteps to do Develop your network For this example, we need the following modules. Add the modules to your workspace, connect them as shown below and load the example image $(DemoDataPath)/BrainMultiModal/ProbandT1.","content":"Contour Example 1: Creation of Contours Introduction We like to start with the creation of CSOs. To create CSOs, you need a SoCSO*-Editor. There are several different editors, which can be used to create CSOs (see here). Some of them are introduced in this example.\nSteps to do Develop your network For this example, we need the following modules. Add the modules to your workspace, connect them as shown below and load the example image $(DemoDataPath)/BrainMultiModal/ProbandT1.tif.\nData Objects Contours Example 1 Edit rectangular CSO Now, open the module View2D. Use your left mouse key , to draw a rectangle, which is your first CSO.\nRectangle Contour The involved modules have the following tasks:\nSoCSORectangleEditor: Enables the creation of the CSO and defines the shape of the CSOs\nSoView2DCSOExtensibleEditor: Manages attached CSO editors and the appearance of CSOs\nCSOManager: Creates a list of all drawn CSOs and offers the possibility to group CSOs\nIf you now open the panel of the CSOManager, you will find one CSO, the one we created before. If you like, you can name the CSO.\nCSO Manager Change properties of CSO Now, add the module SoCSOVisualizationSettings to your workspace and connect it as shown below.\nCSO Manager Open the module to change the visualization settings of your CSOs. In this case, we change the line style (to dashed lines) and the color (to be red). Tick the Auto apply box at the bottom or press Apply.\nVisualization Settings CSOs of different shapes Exchange the module SoCSORectangleEditor with another editor, for example the SoSCOPolygonEditor or SoCSOSplineEditor. Other editors allow to draw CSOs of other shapes. For polygon-shaped CSOs or CSOs consisting of splines, left-click on the image viewer to add new points to form the CSO. Double\u0026ndash;click to finish the CSO.\nSoSCOPolygonEditor SoCSOSplineEditor Exercises Create CSOs with green color and ellipsoid shapes.\nSummary CSOs can be created using a SoCSO-Editor CSOs of different shapes can be created A list of CSOs can be stored in the CSOManager Properties of CSOs can be changed using SoCSOVisualizationSettings \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","2D","Contours","CSO"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/contours/contourexample2/","title":"Contour Example 2: Contour Interpolation","summary":"Contour Example 2: Creating Contours using Live Wire and Interpolation Introduction In this example, we like to create CSOs using the Live Wire Algorithm, which allows semi-automatic CSO creation. The algorithm uses edge detection to support the user creating CSOs.\nWe also like to interpolate CSOs over slices. That means additional CSOs are generated between manual segmentations based on a linear interpolation.\nAs a last step, we will group together CSOs of the same anatomical unit.","content":"Contour Example 2: Creating Contours using Live Wire and Interpolation Introduction In this example, we like to create CSOs using the Live Wire Algorithm, which allows semi-automatic CSO creation. The algorithm uses edge detection to support the user creating CSOs.\nWe also like to interpolate CSOs over slices. That means additional CSOs are generated between manual segmentations based on a linear interpolation.\nAs a last step, we will group together CSOs of the same anatomical unit.\nSteps to do Develop your network and create CSOs In order to do that, create the shown network. You can use the network from the previous example and exchange the SoCSO-Editor. In addition to that, load the example image $(DemoDataPath)/Thorax1_CT.small.tif . Now, create some CSOs on different, not consecutive slices. Afterwards, hover over the CSOManager and press the emerging plus-sign. This displays the amount of existing CSOs.\nData Objects Contours Example 2 Create CSO interpolations We like to generate interpolated contours for existing CSOs. In order to do that, add the module CSOSliceInterpolator to your workspace and connect it as shown.\nSlice Interpolation Open the panel of module CSOSliceInterpolator and change the Group Handling and the Mode as shown. If you now press Update interpolating CSOs are created.\nSlice Interpolation Settings You can see the interpolated CSOs are added to the CSOManager. If you now scroll through your slices, you can find the interpolated CSOs.\nYou can also take a look on all existing CSOs by inspecting the output of the CSOManager using the Output Inspector. Custom CSOs are displayed in white and interpolated CSOs are marked in yellow.\nInterpolated CSOs Group CSOs We like to segment both lobes of the lung. To distinguish the CSOs of both lungs, we like to group CSOs together, according to the lung, they belong to. First, we like to group together all CSOs belonging to the lung we already segmented. In order to do this, open the CSOManager. Create a new Group and label that Group. We chose the label Left Lung. Now, mark the created Group and all CSOs you want to include into that group and press Combine. If you click on the Group, all CSOs belonging to this Group are marked with a star.\nAttention:\u0026nbsp; Keep in mind, that the right lung might be displayed on the left side of the image and vice versa, depending on your view. Creating CSO Groups Creating CSO Groups As a next step, segment the right lung by creating new CSOs. Creation of further CSOs Create a new Group for all CSOs of the right lung. We labeled this Group Right Lung. Again, mark the group and the CSOs you like to combine and press Combine. Grouping remaining CSOs To visually distinguish the CSOs of both groups, change the color of each group under [ Group \u0026rarr; Visuals ]. We changed the color of the Left Lung to be green and of the Right Lung to be orange of path and seed points. In addition, we increased the Width of the path points. Interpolated CSOs As a last step, we need to disconnect the module SoCSOVisualizationSettings, as this module overwrites the visualization settings we enabled for each group in the CSOManager. Interpolated CSOs Summary SoCSOLiveWireEditor can be used to create CSOs semi-automatically CSO interpolations can be created using CSOSliceInterpolator CSOs can be grouped together using the CSOManager \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","2D","Contours","CSO","Interpolation"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/contours/contourexample3/","title":"Contour Example 3: 2D and 3D Visualization of Contours","summary":"Contour Example 3: Overlay Creation and 3D Visualization of Contours Introduction In this example, we like to use the created CSOs to display an overlay. This allows us to mark one of two lungs. In addition to that, we will display the whole segmented lobe of the lung in a 3D image.\nSteps to do Develop your network Use the network from the contour example 2 and add the modules VoxelizeCSO, SoView2DOverlay and View2D to your workspace.","content":"Contour Example 3: Overlay Creation and 3D Visualization of Contours Introduction In this example, we like to use the created CSOs to display an overlay. This allows us to mark one of two lungs. In addition to that, we will display the whole segmented lobe of the lung in a 3D image.\nSteps to do Develop your network Use the network from the contour example 2 and add the modules VoxelizeCSO, SoView2DOverlay and View2D to your workspace. Connect the module as shown. The module VoxelizeCSO allows to convert CSOs into voxel-images.\nData Objects Contours Example 3 Convert CSOs into voxel images Update the module VoxelizeCSOs to create overlays based on your CSOs. The result can be seen in View2D1.\nOverlay Next, we like to inspect the marked lobe of the lunge. This means, we like to inspect the object, build out of CSOs. In order to do that, add the View3D module. The 3D version of your lung can be seen in the viewer.\nAdditional 3D Viewer Extracted Object Summary The module VoxelizeCSO converts CSOs to voxel images Create an overlay out of voxel images using SoView2DOverlay \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","2D","Contours","CSO","3D"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/contours/contourexample4/","title":"Contour Example 4: Annotation of Images","summary":"Contour Example 4: Annotation of Images Introduction In this example we like to calculate the volume of our object, in this case the part of the lunge we have segmented.\nSteps to do Develop your network and calculate the lunge volume Add the module CalculateVolume and SoView2DAnnotation to your workspace and connect both modules as shown. Update the module CalculateVolume, which directly shows the volume of our object.\nData Objects Contours Example 4 Display the lung volume in the image We now like to display the volume in the image viewer.","content":"Contour Example 4: Annotation of Images Introduction In this example we like to calculate the volume of our object, in this case the part of the lunge we have segmented.\nSteps to do Develop your network and calculate the lunge volume Add the module CalculateVolume and SoView2DAnnotation to your workspace and connect both modules as shown. Update the module CalculateVolume, which directly shows the volume of our object.\nData Objects Contours Example 4 Display the lung volume in the image We now like to display the volume in the image viewer. For this, open the panel of the modules CalculateVolume and SoView2DAnnotation. Open the tab Input in the panel of the module SoView2DAnnotation. Now construct a parameter connection between Total Volume calculated in the module CalculateVolume and the input00 of the module SoView2DAnnotation. This connection projects the Total Volume to the input of SoView2DAnnotation.\nDisplay Volume Go back to the tab General to select the Annotation Mode User. A separate tab exists for each annotation mode.\nAnnotate Image We select the tab User which we like to work on. You can see four fields, which display four areas of a viewer in which you can add information text to the image.\nAnnotate Image In this example we only like to add the volume, so delete all present input and replace that by the shown text. Now, you can see that the volume is displayed in the image viewer. If this is not the case, switch the annotations of the viewer by pressing the keyboard shortcut A .\nDisplay Volume in Image Summary CalculateVolume can calculate the volume of a voxel image SoView2DAnnotation enables to manually change the annotation mode of a viewer Annotations shown in a View2D can be customized by using a SoView2DAnnotation module \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","2D","Contours","CSO","Annotations"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/contours/contourexample5/","title":"Contour Example 5: Contours and Ghosting","summary":"Contour Example 5: Visualizing Contours and Images Introduction In this example, we like to automatically create CSOs based on a predefined iso value.\nSteps to do Develop your network Add the following modules to your workspace and connect them as shown. Load the example image Bone.tiff.\nAutomatic creation of CSOs based on the iso value Now, open the panel of CSOIsoGenerator to set the Iso Value to 1200. If you press Update in the panel, you can see the creation of CSOs on every slide, when opening the module View2D.","content":"Contour Example 5: Visualizing Contours and Images Introduction In this example, we like to automatically create CSOs based on a predefined iso value.\nSteps to do Develop your network Add the following modules to your workspace and connect them as shown. Load the example image Bone.tiff.\nAutomatic creation of CSOs based on the iso value Now, open the panel of CSOIsoGenerator to set the Iso Value to 1200. If you press Update in the panel, you can see the creation of CSOs on every slide, when opening the module View2D. In addition to that the number of CSOs is displayed in the CSOManager. The module CSOIsoGenerator generates iso-contours for each slice at a fixed iso value. This means that closed CSOs are formed based on the detection of the voxel value of 1200 on every slice.\nData Objects Contours Example 5 Ghosting Now, we like to make CSOs of previous and subsequent slices visible (Ghosting). In order to do that, open the panel of SoCSOVisualizationSettings and open the tab Misc. Increase the parameter Ghosting depth in voxel, which shows you the number of slices above and below the current slice, which CSOs are also seen in the viewer. The result can be seen in the viewer.\nGhosting Display created CSOs At last, we like to make all CSOs visible in a 3D viewer. To do that, add the modules SoCSO3DRenderer and SoExaminerViewer to your network and connect them as shown. In the viewer SoExaminerViewer you can see all CSOs together. In this case all scanned bones can be seen.\nCSOs in 3D View Summary CSOIsoGenerator enables automatic COS generation based on an iso value Ghosting allows to display CSOs of previous and following slices \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","2D","Contours","CSO"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/contourobjects/","title":"Contour Objects (CSO)","summary":"Contour Segmented Objects (CSOs) in MeVisLab Introduction Structure of CSOs MeVisLab provides modules to create contours in images. 3D objects which encapsulate these contours are called Contour Segmented Objects (CSOs).\nIn the next image, you can see a rectangular shaped CSO. The pink circles you can see are called Seed Points.\nSeed Points define the shape of the CSO. In case of a rectangle, you need four Seed Points forming the corners, to define the whole rectangle.","content":"Contour Segmented Objects (CSOs) in MeVisLab Introduction Structure of CSOs MeVisLab provides modules to create contours in images. 3D objects which encapsulate these contours are called Contour Segmented Objects (CSOs).\nIn the next image, you can see a rectangular shaped CSO. The pink circles you can see are called Seed Points.\nSeed Points define the shape of the CSO. In case of a rectangle, you need four Seed Points forming the corners, to define the whole rectangle.\nThe points forming the blue lines are called Path Points.\nThe Path Points form the connection between the Seed Points whereby contour objects (CSOs) are generated. CSOs are often closed, but do not need to be.\nIn general, the Seed Points are created interactively using an editor module and the Path Points are generated automatically by interpolation or other algorithms.\nContour Segmented Object (CSO) CSO Editors As mentioned, when creating CSOs, you can do this interactively by using an editor.\nThe following images show editors available in MeVisLab for drawing CSOs:\nSoCSOPointEditor SoCSOAngleEditor SoCSOArrowEditor SoCSODistanceLineEditor SoCSODistancePolylineEditor SoCSOEllipseEditor SoCSORectangleEditor SoCSOSplineEditor SoCSOPolygonEditor SoCSOIsoEditor SoCSOLiveWireEditor Extra Infos:\u0026nbsp; The SoCSOIsoEditor and SoCSOLiveWireEditor are special, because they are using an algorithm to detect edges themselves.\nThe SoCSOIsoEditor generates iso-contours interactively. The SoCSOLiveWireEditor renders and semi-interactively generates CSOs based on the LiveWire algorithm. CSO Lists and CSO Groups All created CSOs are stored in CSO lists, which can be saved and loaded on demand. The lists can not only store the coordinates of the CSOs, but also additional information in the form of name-value pairs (using specialized modules or Python scripting).\nBasic CSO Network Each SoCSO*Editor requires a SoView2DCSOExtensibleEditor which manages attached CSO editors and renderers and offers an optional default renderer for all types of CSOs. In addition to that, the list of CSOs needs to be stored in a CSOManager.\nThe appearance of the CSO can be defined by using a SoCSOVisualizationSettings module.\nCSOs can also be grouped together. The following image shows two different CSO groups. Groups can be used to organize CSOs, in this case to distinguish the CSOs of the right and the left lung. Here you can find more information about CSO Groups.\nCSO Groups Extra Infos:\u0026nbsp; For more information, see CSO Overview ","tags":["Beginner","Tutorial","Data Objects","2D","Contours","CSO"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/curves/","title":"Curves","summary":"Curves in MeVisLab Introduction Curves can be used in MeVisLab to print the results of a function as two-dimensional mathematical curves into a diagram.\nCurves in MeVisLab In the given example, only modules available in commercial MeVisLab Professional SDK have been used. The non-commercial MeVisLab Standard SDK provides more modules for curves.","content":"Curves in MeVisLab Introduction Curves can be used in MeVisLab to print the results of a function as two-dimensional mathematical curves into a diagram.\nCurves in MeVisLab In the given example, only modules available in commercial MeVisLab Professional SDK have been used. The non-commercial MeVisLab Standard SDK provides more modules for curves.\n","tags":["Beginner","Tutorial","Data Objects","2D","Curves"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/data_objects/","title":"Data Objects","summary":"Data Object Examples: The following examples are available:\n[1] 2D and 3D visualization of contours [2] Annotation of images [3] Contour interpolation [4] Contours and ghosting [5] Creation of Contours [6] Creation of WEMs [7] Distance between markers [8] Drawing curves [9] Interactively moving WEM [10] Processing and modification of WEMs [11] WEM - Primitive Value Lists ","content":"Data Object Examples: The following examples are available:\n[1] 2D and 3D visualization of contours [2] Annotation of images [3] Contour interpolation [4] Contours and ghosting [5] Creation of Contours [6] Creation of WEMs [7] Distance between markers [8] Drawing curves [9] Interactively moving WEM [10] Processing and modification of WEMs [11] WEM - Primitive Value Lists ","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/thirdparty/assimp/assimpexample1/","title":"Example 1: 3D Printing in MeVisLab","summary":"Example 1: 3D Printing in MeVisLab Introduction This example uses the assimp library to load a 3D file and save the file as *.stl for 3D printing.\nSteps to do Develop your network Add the modules SoSceneLoader, SoBackground and SoExaminerViewer to your workspace and connect them as seen below.\nExample Network Open the 3D file Select the file vtkCow.obj from MeVisLab demo data directory. Open SoExaminerViewer and inspect the scene. You will see a 3D cow.","content":"Example 1: 3D Printing in MeVisLab Introduction This example uses the assimp library to load a 3D file and save the file as *.stl for 3D printing.\nSteps to do Develop your network Add the modules SoSceneLoader, SoBackground and SoExaminerViewer to your workspace and connect them as seen below.\nExample Network Open the 3D file Select the file vtkCow.obj from MeVisLab demo data directory. Open SoExaminerViewer and inspect the scene. You will see a 3D cow.\nInfo:\u0026nbsp; In case you cannot see the cow, it might be located outside your current camera location. Trigger the field rescanScene in case the cow is not visible. Cow in SoExaminerViewer Add a SoSphere to the workspace and connect it to your viewer. Define the Radius of your sphere to 2 and inspect your viewer.\nCow and Sphere in SoExaminerViewer You can also define a material for your sphere but what we wanted to show is: You can use the loaded 3D files in MeVisLab Open Inventor Scenes.\nCow and red Sphere in SoExaminerViewer Save your scene as *.stl file for 3D Printing Add a SoSceneWriter module to your workspace. The SoExaminerViewer has a hidden output which can be shown on pressing SPACE . Connect the SoSceneWriter to the output.\nName your output *.stl file and select Stl Ascii as output format so that we can inspect the result afterwards.\nSoSceneWriter Info:\u0026nbsp; The SoSceneWriter can save node color information when saving in Inventor (ASCII or binary) or in VRML format. The SoSceneWriter needs to be attached to a SoWEMRenderer that renders in ColorMode:NodeColor.\nThere are tools to convert from at least VRML to STL available for free.\nWrite your Scene and open the resulting file in your preferred editor. As an alternative, you can also open the file in an *.stl file reader like Microsoft 3D-Viewer.\nMicrosoft 3D-Viewer Load the file again For loading your *.stl file, you can use a SoSceneLoader and a SoExaminerViewer.\nInfo:\u0026nbsp; More information about the *.stl format can be found here SoSceneLoader Summary MeVisLab is able to load and write many different 3D file formats including *.stl format for 3D Printing. Inventor Scenes can be saved by using a SoExaminerViewer together with a SoSceneWriter ","tags":["Beginner","Tutorial","assimp","3D","3D Printing","stl"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/image_processing/image_processing1/","title":"Example 1: Arithmetic operations on two images","summary":"Example 1: Arithmetic operations on two images Introduction We are using the Arithmetic2 module to apply basic scalar functions on two images. The module provides 2 inputs for images and 1 output image for the result.\nSteps to do Develop your network Add two LocalImage modules to your workspace for the input images. Select $(DemoDataPath)/BrainMultiModal/ProbandT1.dcm and $(DemoDataPath)/BrainMultiModal/ProbandT2.dcm from MeVisLab demo data and add a SynchroView2D to your network.\nIn the end, add the Arithmetic2 module and connect them as seen below.","content":"Example 1: Arithmetic operations on two images Introduction We are using the Arithmetic2 module to apply basic scalar functions on two images. The module provides 2 inputs for images and 1 output image for the result.\nSteps to do Develop your network Add two LocalImage modules to your workspace for the input images. Select $(DemoDataPath)/BrainMultiModal/ProbandT1.dcm and $(DemoDataPath)/BrainMultiModal/ProbandT2.dcm from MeVisLab demo data and add a SynchroView2D to your network.\nIn the end, add the Arithmetic2 module and connect them as seen below.\nExample Network Your SynchroView2D shows two images. On the left hand side, you can see the original image from your left LocalImage module. The right image shows the result of the arithmetic operation executed by the Arithmetic2 module on the two input images.\nSynchroView2D The SynchroView2D module automatically synchronizes the visible slice of both input images, you can see the same slice with and without applied filter.\nArithmetic operations Double-click the Arithmetic2 module to select different functions to be applied.\nArithmetic2 The selected function is applied automatically.\nSummary Arithmetic operations on two images can be applied on images by using Arithmetic* modules. The SynchroView2D module allows to scroll through slices synchronized on two images. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Image Processing","Arithmetic"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/markers/markerexample1/","title":"Example 1: Distance between Markers","summary":"Example 1: Calculating the distance between markers Introduction In this example, we will measure the distance between one position in an image to a list of markers.\nSteps to do Develop your network Add the following modules and connect them as shown.\nWe changed the names of the modules SoView2DMarkerEditor and XMarkerLIstContainer, to distinguish these modules from two similar modules we will add later on. Open the panel of SoView2DMarkerEditor and select the tab Drawing.","content":"Example 1: Calculating the distance between markers Introduction In this example, we will measure the distance between one position in an image to a list of markers.\nSteps to do Develop your network Add the following modules and connect them as shown.\nWe changed the names of the modules SoView2DMarkerEditor and XMarkerLIstContainer, to distinguish these modules from two similar modules we will add later on. Open the panel of SoView2DMarkerEditor and select the tab Drawing. Now chose the Color red.\nMarker Color As a next step, add two more modules: SoView2DMarkerEditor and XMarkerLIstContainer.\nChange their names and the marker color to green and connect them as shown. We also like to change the mouse button you need to press, in order to create a marker. This allows to place both types of markers, the red ones and the green ones. In order to do this, open the panel of GreenMarker. Under Buttons you can adjust, which button needs to be pressed in order to place a marker. Select the Button2 (the middle button of your mouse ) instead of Button1 (the left mouse button ).\nIn addition to that, we like to allow only one green marker to be present. If we place a new marker, the old marker should vanish. For this, select the Max Size to be one and select Overflow Mode: Remove All.\nMarker Editor Settings Create markers of different type Now we can place as many red markers as we like, using the left mouse button and one green marker using the middle mouse button .\nTwo Types of Markers Calculate the distance between markers We like to calculate the minimum and maximum distance of the green marker to all the red markers. In order to do this, add the module DistanceFromXMarkerList and connect it to RedMarkerList. Open the panels of DistanceFromXMarkerList and GreenMarkerList. Now, draw a parameter connection from the coordinates of the green marker, which are stored in the field Current Item -\u0026gt; Position in the panel of GreenMarkerList to the field Position of DistanceFromXMarkerList. You can now press Calculate Distance in the panel of DistanceFromXMatkerList to see the result, meaning the distance of the green marker to all the red markers in the panel of DistanceFromXMarkerList.\nModule DistanceFromXMarkerList Automation of distance calculation To automatically update the calculation when placing a new marker, we need to tell the module DistanceFromXMarkerList when a new green marker is placed. Open the panels of DistanceFromXMarkerList and GreenMarker and draw a parameter connection from the field Currently busy in the panel of GreenMarker to Calculate Distance in the panel of DistanceFromXMarkerList. If you now place a new green marker, the distance from the new green marker to all red markers is automatically calculated. Calculation of Distance between Markers Summary Markers can be created using SoView2DMarkerEditor Markers can be stored and managed using XMarkerListContainer The distance between markers can be calculated using DistanceFromXMarkerList \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","2D","3D","Marker"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/curves/curvesexample1/","title":"Example 1: Drawing curves","summary":"Example 1: Drawing curves Introduction In this example, you will draw one or more curves into a diagram and define different styles for the curves.\nSteps to do Develop your network A curve requires x- and y-coordinates to be printed. You can use the CurveCreator module as input for these coordinates. The SoDiagram2D draws the curves into a SoRenderArea. You can also define the style of the curves by using the StylePalette module.","content":"Example 1: Drawing curves Introduction In this example, you will draw one or more curves into a diagram and define different styles for the curves.\nSteps to do Develop your network A curve requires x- and y-coordinates to be printed. You can use the CurveCreator module as input for these coordinates. The SoDiagram2D draws the curves into a SoRenderArea. You can also define the style of the curves by using the StylePalette module.\nAdd the modules to your workspace and connect them as seen below.\nExample Network Creating a curve Click on the output of the CurveCreator and open the Output Inspector.\nEmpty Output Inspector Double-click on the CurveCreator module and open the Panel.\nCurveCreator Module You can see a large input field Curve Table. Here you can enter the x and y values of your curve. The values of the first column will become the x-values and the 2nd any further column will become the y-series. Comment lines start with a \u0026lsquo;#\u0026rsquo; character.\nEnter the following into the Curve Table: Curve Table\n# My first curve 0 0 1 1 2 2 3 3 4 4 5 5 10 10 50 50 Now your Output Inspector shows a yellow line through the previously entered coordinates. Exactly the same curve is shown in the SoRenderArea.\nSoRenderArea Creating multiple curves Now, update the Curve Table so that you are using 3 columns and click Update : Curve Table\n# My first curve 0 0 0 1 1 2 2 2 4 3 3 6 4 4 8 5 5 10 10 10 20 50 50 100 You can see 2 curves. The second and third columns are printed as separate curves. Both appear yellow. After checking Split columns into data sets, you will see one yellow and one red curve.\nbefore_split after_split If the flag Split columns into data sets is set to TRUE, then a table with more than two columns is split into different CurveData objects. This gives the user the possibility to assign a different style and title for each series.\nTitles and styles Let\u0026rsquo;s do this. Open the panel of the SoDiagram2D module and check Draw legend. Enter \u0026ldquo;Curve1 Curve2\u0026rdquo; into the Title(s) text box and click Update .\nSoRenderArea with Legend You can also define a different location of the legend and set font sizes.\nNow open the panel of the StylePalette module.\nStylePalette The StylePalette allows you to define 12 different styles for curves. Initially without manual changes, the styles are applied one after the other. The first curve gets style 1, the second curve style 2, and so on.\nOpen the Panel of your CurveCreator again and define Curve Style(s) as \u0026ldquo;3 6\u0026rdquo;. Update your curves.\nStylePalette applied You now applied the style 3 for your first curve and 6 for the second. This is how you can create 12 different curves with unique appearance.\nUsing multiple tables for curve generation In addition to adding multiple columns for different y-coordinates, you can also define multiple tables as input, so that you can also have different x-coordinates for multiple curves.\nUpdate the Curve Table as defined below and click Update : Curve Table\n# My first curve 0 0 0 1 1 2 2 2 4 3 3 6 4 4 8 5 5 10 10 10 20 50 50 100 --- # My second curve 0 0 1 1 2 4 3 9 4 16 5 25 6 36 7 49 8 64 9 81 10 100 Also add another title to your curves and define a third style.\nMultiple tables as input Summary Curves can be created to draw 2-dimensional diagrams The StylePalette allows you to define the appearance of a curve Details of the different curves can be visualized by using the SoDiagram2D module \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","2D","Curves"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/openinventor/openinventorobjects/","title":"Example 1: Open Inventor Objects","summary":"Example 1: Open Inventor Objects \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example we like to construct an Open Inventor scene in which we display three 3D objects of different color and shape.\nSteps to do Generating Open Inventor Objects First, add the modules SoExaminerViewer and SoCone to the workspace and connect both modules as shown. The module SoCone creates a cone shaped object, which can be displayed in the Viewer SoExaminerViewer.","content":"Example 1: Open Inventor Objects \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example we like to construct an Open Inventor scene in which we display three 3D objects of different color and shape.\nSteps to do Generating Open Inventor Objects First, add the modules SoExaminerViewer and SoCone to the workspace and connect both modules as shown. The module SoCone creates a cone shaped object, which can be displayed in the Viewer SoExaminerViewer.\nSoExaminerViewer We like to change the color of the cone. In order to do so, add the module SoMaterial to the workspace and connect the module as shown below. When creating an Open Inventor scene (by creating networks of Open Inventor modules), the sequence of module connections, in this case the sequence of the inputs to the module SoExaminerViewer determines the functionality of the network.\nOpen Inventor modules are executed like scene graphs. This means, modules are executed from top to bottom and from left to right. Here, it is important to connect the module SoMaterial to an input on the left side of the connection between SoCone and SoExaminerViewer. With this, we first select features like a color and these features are then assigned to all objects, which were executed afterwards. Now, open the panel of the module SoMaterial and select any Diffuse Color you like. Here, we choose green.\nColors and Material in Open Inventor We like to add a second object to the scene.\nIn order to do that, add the module SoSphere to the workspace. Connect this module to SoExaminerViewer. When connecting SoSphere to an input on the right side of the connection between the viewer and the module SoMaterial, the sphere is also colored in green. One problem now is, that currently both objects are displayed at the same position.\nAdding a SoSphere They display both objects at different positions, add the modules SoSeparator and SoTransform to the scene and connect both modules shown on the following picture. Open the panel of SoTransform and implement a translation in x-direction to shift the object. Now you can examine two things:\nThe sphere loses its green color The cone is shifted to the side Transformation The module SoTransform is responsible for shifting objects, in this case the cone, to the side. The module SoSeparator ensures that only the cone is shifted and also only the cone is colored in green. It separates this features from the rest of the scene.\nWe like to add a third object, a cube, and shift it to the other side of the sphere. Add the modules SoCube and SoTransform to the workspace and connect both modules as shown below. To shift the cube to the other side of the sphere, open the panel of SoTransform and adjust the Translation in x direction. The sphere is not affected by the translation, as the connection from SoTransform1 to SoExaminerViewer is established on the right side of the connection between SoSphere and SoExaminerViewer.\nAdding a SoCube Again, we use the module SoMaterial to select a color for the cone and the sphere.\nMultiple Materials For easier handling we group an object together with its features by using the module SoGroup. This does not separate features, which is the reason for the cube to be colorized. All modules that are derived from SoGroup offer a basically infinite number of input connectors (a new connector is added for every new connection).\nSoGroup If we do not want to colorize the cube, we have to exchange the module SoGroup by another SoSeparator module.\nSoSeparator The implementation of all objects can be grouped together.\nGrouping In addition to the objects, a background can be added to the scene using the module SoBackground.\nSoBackground Summary Scene objects are represented by nodes. Size and position is defined by transformation nodes. A rendering node represents the root of the scene graph. Nodes are rendered in the order of traversal. Nodes on the same level are traversed from left to right. All modules that are derived from SoGroup offer a basically infinite number of input connectors (a new connector is added for every new connection). \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Open Inventor","3D"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/visualization/visualizationexample1/","title":"Example 1: Synchronous view of two images","summary":"Example 1: Synchronous view of two images Introduction In this example we like to use the module SynchroView2D to be able to inspect two different images simultaneously.\nThe module SynchroView2D provides two 2D viewers that are synchronized.\nAs in Tutorial Chapter 1 - Basic Mechanics of MeVisLab, the processed and the unprocessed image can be displayed simultaneously. Scrolling through one image automatically changes the slices of both viewers, so slices with the same slice number are shown in both images.","content":"Example 1: Synchronous view of two images Introduction In this example we like to use the module SynchroView2D to be able to inspect two different images simultaneously.\nThe module SynchroView2D provides two 2D viewers that are synchronized.\nAs in Tutorial Chapter 1 - Basic Mechanics of MeVisLab, the processed and the unprocessed image can be displayed simultaneously. Scrolling through one image automatically changes the slices of both viewers, so slices with the same slice number are shown in both images.\nThe difference is that we are now using an already existing Module named SynchroView2D.\nExtra Infos:\u0026nbsp; The SynchroView2D module is explained here Steps to do Develop your network Start the example by adding the module LocalImage to your workspace to load the example image Tumor1_Head_t1.small.tif. Next, add and connect the following modules as shown.\nSynchroView2D Viewer Summary Multiple images can be synchronized by the SynchroView2D module \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Visualization","2D"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/thirdparty/opencv/thirdpartyexample1/","title":"Example 1: WebCam access with OpenCV","summary":"Example 1: WebCam access with OpenCV Introduction In this example, we are using the PythonImage module and access your WebCam to show the video in a View2D.\nSteps to do Creating the network to be used for testing Add the modules to your workspace and connect them as seen below.\nExample Network The viewer is empty because the image needs to be set via Python scripting.\nInfo:\u0026nbsp; More information about the PythonImage module can be found here Create a Macro Module Now you need to create a Macro Module from your network.","content":"Example 1: WebCam access with OpenCV Introduction In this example, we are using the PythonImage module and access your WebCam to show the video in a View2D.\nSteps to do Creating the network to be used for testing Add the modules to your workspace and connect them as seen below.\nExample Network The viewer is empty because the image needs to be set via Python scripting.\nInfo:\u0026nbsp; More information about the PythonImage module can be found here Create a Macro Module Now you need to create a Macro Module from your network. You can either group your modules, create a local Macro and convert it to a global Macro Module, or you use the Project Wizard and load your *.mlab file.\nInfo:\u0026nbsp; A tutorial how to create your own Macro Modules can be found in Example 2.2: Global Macro Modules. Make sure to add a Python file to your Macro Module. Add the View2D to your UI Next, we need to add the View2D to a Window of your Macro Module. Right click on your module , open the context menu and select [ Related Files \u0026rarr; \u0026lt;YOUR_MODULE_NAME\u0026gt;.script ]. The text editor MATE opens. You can see the *.script file of your module.\nAdd the following to your file: \u0026lt;YOUR_MODULE_NAME\u0026gt;.script\nInterface { Inputs {} Outputs {} Parameters {} } Commands { source = $(LOCAL)/\u0026lt;YOUR_MODULE_NAME\u0026gt;.py } Window { h = 500 w = 500 initCommand = setupInterface destroyedCommand = releaseCamera Vertical { Horizontal { Button { title = Start command = startCapture } Button { title = Pause command = stopCapture } } Horizontal { expandX = True expandY = True Viewer View2D.self { type = SoRenderArea } } } } Now open the Python file of your module and define the commands to be called from the *.script file: \u0026lt;YOUR_MODULE_NAME\u0026gt;.py\n# from mevis import * # Setup the interface for PythonImage module def setupInterface(): pass # Release camera in the end def releaseCamera(_): pass # Start capturing WebCam def startCapture(): pass # Stop capturing WebCam def stopCapture(): pass Use OpenCV Your View2D is still empty, lets get access to the WebCam and show the video in your module. Open the Python file of your network again and enter the following code: \u0026lt;YOUR_MODULE_NAME\u0026gt;.py\n# from mevis import * import cv2 import OpenCVUtils _interfaces = [] camera = None # Setup the interface for PythonImage module def setupInterface(): global _interfaces _interfaces = [] interface = ctx.module(\u0026#34;PythonImage\u0026#34;).call(\u0026#34;getInterface\u0026#34;) _interfaces.append(interface) # Release camera in the end def releaseCamera(_): pass # Start capturing WebCam def startCapture(): pass # Stop capturing WebCam def stopCapture(): pass We now imported cv2 and OpenCVUtils so that we can use them in Python. Additionally we defined a list of _interfaces and a camera. The import of mevis is not necessary for this example.\nThe setupInterfaces function is called whenever the Window of your module is opened. Here we are getting the interface of the PythonImage module and append it to our global list.\nAccess the WebCam Now we want to start capturing the camera. \u0026lt;YOUR_MODULE_NAME\u0026gt;.py\n# Start capturing WebCam def startCapture(): global camera if not camera: camera = cv2.VideoCapture(0) ctx.callWithInterval(0.1, grabImage) # Grab image from camera and update def grabImage(): _, img = camera.read() updateImage(img) # Update image in interface def updateImage(image): _interfaces[0].setImage(OpenCVUtils.convertImageToML(image), minMaxValues = [0,255]) The startCapture function gets the camera from the cv2 object if not already available. Then it calls the current MeVisLab network context and creates a timer which calls a grabImage function every 0.1 seconds.\nThe grabImage function reads an image from the camera and calls updateImage. The interface from the PythonImage module is used to set the image from the WebCam. The MeVisLab OpenCVUtils convert the OpenCV image to the MeVisLab image format MLImage.\nNext, we define what happens if you click the Pause button. \u0026lt;YOUR_MODULE_NAME\u0026gt;.py\n... # Stop capturing WebCam def stopCapture(): ctx.removeTimers() ... As we started a timer in our network context which updates the image every 0.1 seconds, we just stop this timer and the camera is paused.\nIn the end, we need to release the camera whenever you close the Window of your Macro Module. \u0026lt;YOUR_MODULE_NAME\u0026gt;.py\n... # Release camera in the end def releaseCamera(_): global camera, _interfaces ctx.removeTimers() _interfaces = [] if camera: camera.release() camera = None ... Again, the timers are removed, all interfaces are reset and the camera is released. The light indicating WebCam usage should turn off.\nOpening your Macro Module via double-click should now allow to start and pause your WebCam video in MeVisLab. You can modify your internal network using a Convolution filter module or any other module available in MeVisLab for modifying the stream on the fly.\nSummary The PythonImage module allows to use Python for defining the image output OpenCV can be used in MeVisLab via Python scripting Images and videos from OpenCV can be used in MeVisLab networks Info:\u0026nbsp; You can download the Python file here ","tags":["Advanced","Tutorial","OpenCV","Python","WebCam","Macro","Macro Modules","Global Macro"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/testing/testingexample1/","title":"Example 1: Writing a simple test case in MeVisLab","summary":"Example 1: Writing a simple test case in MeVisLab \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, you will learn how to write an automated test for a simple network using the DicomImport, MinMaxScan and View3D modules. You can write test cases for any other module and network yourself.\nSteps to do Creating the network to be used for testing Add the following modules to your workspace and connect them as seen below:","content":"Example 1: Writing a simple test case in MeVisLab \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, you will learn how to write an automated test for a simple network using the DicomImport, MinMaxScan and View3D modules. You can write test cases for any other module and network yourself.\nSteps to do Creating the network to be used for testing Add the following modules to your workspace and connect them as seen below:\nTestcase network Save your network as NetworkTestCase.mlab.\nTest creation Open MeVisLab TestCaseManager via menu [ File \u0026rarr; Run TestCaseManager ]. The following window will appear.\nTestCaseManager window On Test Creation tab, enter the details of your test case as seen below. Make sure to have a package available already. For details about packages, see (Example 2.1: Package creation). Select the just saved network NetworkTestCase.mlab.\nTest Creation window Click Create. The MeVisLab text editor MATE opens automatically showing the Python file of your test. Create your first test function in Python:\nNetworkTestCase.py\nfrom mevis import * from TestSupport import Base, Fields, Logging from TestSupport.Macros import * filePath=\u0026#34;C:/Program Files/MeVisLab3.6.0/Packages/MeVisLab/Resources/DemoData/BrainT1Dicom\u0026#34; def OpenFiles(): ctx.field(\u0026#34;DicomImport.inputMode\u0026#34;).value = \u0026#34;Directory\u0026#34; ctx.field(\u0026#34;DicomImport.source\u0026#34;).value = filePath ctx.field(\u0026#34;DicomImport.triggerImport\u0026#34;).touch() MLAB.processEvents() while not ctx.field(\u0026#34;DicomImport.ready\u0026#34;).value: MLAB.sleep(1) Base.ignoreWarningAndError(MLAB.processEvents) ctx.field(\u0026#34;DicomImport.selectNextItem\u0026#34;).touch() MLAB.log(\u0026#34;Files imported from: \u0026#34;+ctx.field(\u0026#34;DicomImport.source\u0026#34;).value) def TEST_DicomImport(): expectedValue=1.0 OpenFiles() currentValue=ctx.field(\u0026#34;DicomImport.progress\u0026#34;).value ASSERT_FLOAT_EQ(expectedValue,currentValue) The filePath defines the DICOM files to load by using the DicomImport module. When calling the function TEST_DicomImport, an expected value of 1.0 is defined. Then, the DICOM files are opened.\nThe OpenFiles function defines the DicomImport field inputMode to be a Directory. In case you want to open single files, set this field value to Files. Then the source field is set to your previously defined filePath. After clicking triggerImport, the DicomImport module needs some time to load all images in the directory and process the DICOM tree. We have to wait until the field ready is TRUE. While the import is not ready, we wait for 1 millisecond and check again.\nMLAB.processEvents() lets MeVisLab continue execution while waiting for the DicomImportto be ready.\nIn case you get error messages in MeVisLab console about invalid DICOM tags, you can ignore these errors by calling Base.ignoreWarningAndError(MLAB.processEvents) instead of MLAB.processEvents().\nAfter the field ready is true, the test touches the selectNextItem trigger, so that the first images of the patient are selected and shown. The additional log message only writes the source directory for information purposes into the MeVisLab console.\nBack to the TEST_DicomImport() function, we get the current value of the field progress from the DicomImport. This field shows the progress as number between 0 and 1.\nIn the end, we check if currentValue and expectedValue of the progress are equal.\nRun your test case After finishing the code, open the TestCase Manager und run your test.\nRun Test Case After the test finished execution, the ReportViewer opens automatically showing the results of your test.\nReportViewer Writing a test for global macro modules Writing automated tests for global macro modules works a little different. If you create a global macro module from your above network (for details, see Example 2.2: Global Macro Modules), the Python script remains the same, just the module access differs. You always need the name of your macro module as a prefix.\nNetworkTestCase.py\n... # Testing a network file ctx.field(\u0026#34;DicomImport.inputMode\u0026#34;).value = \u0026#34;Directory\u0026#34; # Testing a macro module ctx.field(\u0026#34;\u0026lt;MACRO_MODULE_NAME\u0026gt;.DicomImport.inputMode\u0026#34;).value = \u0026#34;Directory\u0026#34; Exercise Create a global macro module and implement the following test objectives for both (network and macro module)\ncheck, if the file exists. check, if the max value of file is greater than zero. check, if the View3D-Input and DicomImport-output have the same data. Summary MeVisLab provides a TestCenter for writing automated tests in Python Tests can be executed on networks and macro modules The test results are shown in a ReportViewer Info:\u0026nbsp; You can download the Python files here ","tags":["Beginner","Tutorial","Testing","Python","Automated Tests"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/visualization/visualizationexample2/","title":"Example 2: Creating a magnifier","summary":"Example 2: Creating a magnifier \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction Medical images are typically displayed in three different viewing directions (see image): coronal, axial and sagittal.\nUsing the Viewer OrthoView2D you are able to decide, which viewing direction you like to use. In addition to that, you have the opportunity to display all three orthogonal viewing directions simultaneously. Here, we like to display an image of the head in all three viewing directions and mark positions in the image.","content":"Example 2: Creating a magnifier \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction Medical images are typically displayed in three different viewing directions (see image): coronal, axial and sagittal.\nUsing the Viewer OrthoView2D you are able to decide, which viewing direction you like to use. In addition to that, you have the opportunity to display all three orthogonal viewing directions simultaneously. Here, we like to display an image of the head in all three viewing directions and mark positions in the image.\nBody Planes Steps to do Develop your network In this example, use the module LocalImage to load the example image MRI_Head.tif. Now, connect the module OrthoView2D with the loaded image. The image is displayed in three orthogonal viewing directions. The yellow marker displays the same voxel in all three images. You can scroll through the slices in all three viewing directions.\nExtra Infos:\u0026nbsp; In case your image is black, change the Window and Center values by moving the mouse with right mouse button\npressed.\nOrthoView2D SoView2DPosition Next, we add the module SoView2DPosition (an Open Inventor module).\nThe module enables the selection of an image position via mouse-click . The last-clicked location in the Viewer is marked in white. If you now scroll through the slices, both, the last-clicked location and the current image location are shown.\nSoView2DPosition SoView2DRectangle Instead of points, we like to mark areas. In order to do that, replace the module SoView2DPosition with the module SoView2DRectangle. The module allows to add a rectangle to the image. Left-click on the image and draw a rectangle. In the OthoView2D, the rectangle is displayed in every viewing direction.\nSoView2DRectangle Using a rectangle to build a magnifier We like to use the module SoView2DRectangle to create a magnifier. In order to do that add the following modules to your workspace and connect them as shown below. We need to connect the module SoView2DRectangle to a hidden input connector of the module SynchroView2D. To be able to do this, click on your workspace and afterwards press SPACE . You can see, that SynchroView2D possesses Open Inventor input connectors. You can connect your module SoView2DRectangle to one of these connectors.\nHidden Inputs of SynchroView2D Connect Hidden Inputs of SynchroView2D In addition to that, add two types of the module DecomposeVector3 to your network. In MeVisLab exist different data types, for example vectors, or single variable, which contain the data type float or integer. This module can be used to convert field values of type vector (in this case a vector consisting of three entries) into three single coordinates. You will see in the next step, why this module can be useful.\nDecomposeVector3 We like to use the module SubImage to select a section of a slice, which is then displayed in the Viewer. The idea is to display a magnified section of one slice next to the whole slice in the module SynchroView2D. In order to do that, we need to tell the module SubImage which section to display in the Viewer. The section is selected using the module SoView2DRectangle. As a last step, we need to transmit the coordinates of the chosen rectangle to the module SubImage. To do that, we will build some parameter connections.\nSubImage Now, open the panels of the modules SoView2DRectangle and DecomposeVector3 and DecomposeVector31.\nWe here rename the DecomposeVector3 modules (press F2 to do that), for a better overview.\nIn the panel of the module Rectangle in the box Position you can see the position of the rectangle given in two 3D vectors.\nWe like to use the modules DecomposeVector3 to extract the single x, y and z values of the vector. For that, create a parameter connection from the field Start Wold Pos to the vector of the module we named StartWorldPos_Rectangle and create a connection from the field End World Pos to the vector of module EndWorldPos_Rectangle. The decomposed coordinates can be now used for further parameter connections.\nParameter Connections Open the panel of the module SubImage. Select the Mode World Start \u0026amp; End (Image Axis Aligned). Enable the function Auto apply.\nExtra Infos:\u0026nbsp; Make sure to also check Auto-correct for negative subimage extents so that you can draw rectangles from left to right and from right to left. World Coordinates Now, create parameter connections from the fields X, Y, Z of the module StartWorldPos_Rectangle to the field Start X, Start Y, Start Z in the panel of the module SubImage. Similarly, connect the parameter fields X, Y, Z of the module EndWorldPos_Rectangle to the field End X, End Y, End Z in the panel of the module SubImage.\nAnother Parameter Connection With this, you finished your magnifier. Open the Viewer and draw a rectangle on one slice, to see the result.\nFinal Magnifier with SubImage Exercises Invert the image inside your magnified SubImage without changing the original image. You can use Arithmetic* modules for inverting.\nSummary The module OrthoView2D provides coronal, axial and sagittal views of an image. The SubImage module allows to define a region of an input image to be treated as a separate image. Single x, y and z coordinates can be transferred to a 3-dimensional vector and vice versa by using ComposeVector3 and DecomposeVector3 Some modules provide hidden in- and outputs which can be shown via SPACE \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Visualization","2D","Magnifier"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/thirdparty/opencv/thirdpartyexample2/","title":"Example 2: Face Detection with OpenCV","summary":"Example 2: Face Detection with OpenCV Introduction This example uses the OpenCV WebCam Python script and adds a basic face detection.\nInfo:\u0026nbsp; The Python code used in this example has been taken from Towards Data Science. Steps to do Open Example 1 Add the Macro Module developed in Example 1 to your workspace.\nDownload trained classifier XML file Initially you need to download the trained classifier XML file. It is available in the OpenCV GitHub repository.","content":"Example 2: Face Detection with OpenCV Introduction This example uses the OpenCV WebCam Python script and adds a basic face detection.\nInfo:\u0026nbsp; The Python code used in this example has been taken from Towards Data Science. Steps to do Open Example 1 Add the Macro Module developed in Example 1 to your workspace.\nDownload trained classifier XML file Initially you need to download the trained classifier XML file. It is available in the OpenCV GitHub repository. Save the file somewhere and remember the path for later usage in Python.\nExtend Python file Right click on your module , open the context menu and select [ Related Files \u0026rarr; \u0026lt;YOUR_MODULE_NAME\u0026gt;.py ]. The text editor MATE opens. You can see the Python file of your module.\nYou have to load the previously downloaded XML file first. \u0026lt;YOUR_MODULE_NAME\u0026gt;.py\n# from mevis import * import cv2 import OpenCVUtils _interfaces = [] camera = None face_cascade = cv2.CascadeClassifier(\u0026#39;\u0026lt;YOUR_PATH\u0026gt;/haarcascade_frontalface_default.xml\u0026#39;) After loading the file, go to the previously implemented grabImage function and extend it as follows: \u0026lt;YOUR_MODULE_NAME\u0026gt;.py\ndef grabImage(): _, img = camera.read() updateImage(img) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) faces = face_cascade.detectMultiScale(gray, 1.1, 4) for (x, y, w, h) in faces: cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) # Display the output cv2.imshow(\u0026#39;img\u0026#39;, img) In the end, destroy all OpenCV windows in releaseCamera function. \u0026lt;YOUR_MODULE_NAME\u0026gt;.py\ndef releaseCamera(_): global camera, _interfaces ctx.removeTimers() _interfaces = [] if camera: camera.release() camera = None cv2.destroyAllWindows() Opening your Macro Module and pressing Start should now open your WebCam stream and an additional OpenCV window which shows a blue rectangle around a detected face.\nFace Detection in MeVisLab using OpenCV Summary This is just one example for using OpenCV in MeVisLab. You will find lots of other examples and tutorials online, we just wanted to show one possibility.\nInfo:\u0026nbsp; You can download the Python file here ","tags":["Advanced","Tutorial","OpenCV","Python","WebCam","Face Detection"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/image_processing/image_processing2/","title":"Example 2: Masking images","summary":"Example 2: Masking images Introduction The background of medical images is black for most cases. In case an image is inverted or window/level values are adapted, these black pixels outside clinical relevant pixels might become very bright or even white.\nBeing in a dark room using a large screen, the user might be blended by these large white regions.\nImage masking is a very good way to select a defined region where image processing shall be applied.","content":"Example 2: Masking images Introduction The background of medical images is black for most cases. In case an image is inverted or window/level values are adapted, these black pixels outside clinical relevant pixels might become very bright or even white.\nBeing in a dark room using a large screen, the user might be blended by these large white regions.\nImage masking is a very good way to select a defined region where image processing shall be applied. A mask allows to define a region (the masked region) to allow image modifications whereas pixels outside the mask remain unchanged.\nSteps to do Develop your network Add a LocalImage and a SynchroView2D module to your network and connect the modules as seen below.\nExample Network Open the Automatic Panel of the SynchroView2D module via context menu and selecting [ Show Window \u0026rarr; Automatic Panel ]. Set the field synchLUTs to TRUE.\nSynchronize LUTs in SynchroView2D Double-click the SynchroView2D and change window/level values via right mouse button . You can see that the background of your images gets very bright and changes on the LUT are applied to all pixels of your input image - even on the background. Hovering your mouse over the image(s) shows the current gray value under your cursor in Hounsfield Unit (HU).\nWithout masking the image Hovering the mouse over black background pixels shows a value between 0 and about 60. This means we want to create a mask which only allows modifications on pixels having a grey value larger than 60.\nAdd a Mask and a Threshold module to your workspace and connect them as seen below.\nExample Network Changing the window/level values in your viewer still also changes background pixels. The Thereshold module still leaves the pixels as is because the threshold value is configured as larger than 0. Open the Automatic Panel of the modules Threshold and Mask via double-click and set the values as seen below.\nThreshold Mask Now all pixels having a HU value lower or equal 60 are set to 0, all others are set to 1. The resulting image from the Threshold module is a bit image which can now be used as a mask by the Mask module.\nOutput of the Threshold module The Mask module is configured to use the Masked Original image. Changing the window/level values in your images now, you can see that the background pixels are not affected anymore (at least as long as you do not reach a very large value).\nAfter masking the image Summary The module Threshold applies a relative or an absolute threshold to a voxel image. It can be defined what should be written to those voxels which pass or which fail the adjustable comparison. The module Mask masks the image of input one with the mask at input two. A mask can be used to filter pixels inside images \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Image Processing","Mask"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/openinventor/mouseinteractions/","title":"Example 2: Mouse interactions in Open Inventor","summary":"Example 2: Mouse interactions in Open Inventor \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, we implement some image or object interactions. We will create a 3D scene, in which we display a cube and change its size using the mouse. We also get to know another viewer, the module SoExaminerViewer. This viewer is important. It enables the rendering of Open Inventor scenes and allows interactions with the Open Inventor scenes.","content":"Example 2: Mouse interactions in Open Inventor \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, we implement some image or object interactions. We will create a 3D scene, in which we display a cube and change its size using the mouse. We also get to know another viewer, the module SoExaminerViewer. This viewer is important. It enables the rendering of Open Inventor scenes and allows interactions with the Open Inventor scenes.\nSteps to do Develop your network For implementing the example, build the following network. We already know the module SoCube, which builds a 3D scene object forming a cube. In addition to that, add the module SoMouseGrabber. Connect the modules as shown below.\nExtra Infos:\u0026nbsp; Additional information about the SoMouseGrabber can be found here: SoMouseGrabber SoMouseGrabber Configure mouse interactions Now, open the panels of the module SoMouseGrabber and the module SoExaminerViewer, which displays a cube. In the Viewer, press the right key of your mouse and move the mouse around. This action can be seen in the panel of the module SoMouseGrabber.\nAttention:\u0026nbsp; Make sure to configure SoMouseGrabber fields as seen below. SoMouseGrabber You can see:\nButton 3, the right mouse button , is tagged as being pressed Changes of the mouse coordinates are displayed in the box Output. Mouse Interactions Resize cube via mouse interactions We like to use the detected mouse-movements to change the size of our cube. In order to that, open the panel of SoCube. Build parameter connections from the mouse coordinates to the width and depth of the cube.\nChange Cube size by Mouse Events If you now press the right mouse key inside the Viewer and move the mouse around, the size of the cube changes.\nExercises Change location of the cube via Mouse Interactions by using the Module SoTransform Add more objects to the scene and interact with them Summary The module SoExaminerViewer enables the rendering of Open Inventor scenes and allows interactions with the Open Inventor scenes. Mouse interactions can be applied to the objects in the scene. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Open Inventor","3D","Mouse Interactions"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/testing/testingexample2/","title":"Example 2: Profiling in MeVisLab","summary":"Example 2: Profiling in MeVisLab \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, we are using the MeVisLab Profiler to inspect the memory and CPU consumption of the modules in an example network.\nSteps to do Creating the network to be used for profiling You can open any network you like, here we are using the example network of the module MinMaxScan for profiling. Add the module MinMaxScan to your workspace and open the example network via right-click and selecting [ Help \u0026rarr; Show Example Network ].","content":"Example 2: Profiling in MeVisLab \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, we are using the MeVisLab Profiler to inspect the memory and CPU consumption of the modules in an example network.\nSteps to do Creating the network to be used for profiling You can open any network you like, here we are using the example network of the module MinMaxScan for profiling. Add the module MinMaxScan to your workspace and open the example network via right-click and selecting [ Help \u0026rarr; Show Example Network ].\nMinMaxScan Example Network Enable Profiling Next, enable the MeVisLab Profiler via menu item [ View \u0026rarr; Views \u0026rarr; Profiling ]. The Profiler is opened in your Views Area but can be detached and dragged over the workspace via left mouse button .\nMeVisLab Profiling Enable profiling by checking Enable in the top left corner.\nInspect your network Now open the View2D via double-click and scroll through the slices. Inspect the Profiler.\nMeVisLab Profiling Network The Profiler shows very detailed information about each module in your network.\nInfo:\u0026nbsp; By default, used macro modules are not shown in the Profiler. You need to check Show macros first, in order to see the profiling of the View2D and the LocalImage module. You can filter by module name in case of large networks so that you only get the information you need.\nThe Fields tab shows any changes of field values in your network.\nMeVisLab Profiling Fields In addition to the Profiler view, your modules also provide a tiny bar showing the current memory and time consumption of the module.\nMeVisLab Profiling Module Info:\u0026nbsp; More information about profiling in MeVisLab can be found here Attention:\u0026nbsp; You need to uncheck the Enable checkbox in the top left corner to stop profiling. Closing the window will not automatically end the profiling. Summary Profiling allows you to inspect the behavior of modules and networks including CPU and memory consumption. Field value changes in the entire network are also shown. ","tags":["Beginner","Tutorial","Profiling"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/openinventor/camerainteraction/","title":"Example 3: Camera Interactions in Open Inventor","summary":"Example 3: Camera Interactions in Open Inventor Introduction ","content":"Example 3: Camera Interactions in Open Inventor Introduction ","tags":["Beginner","Tutorial","Open Inventor","3D","Camera"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/visualization/visualizationexample3/","title":"Example 3: Image Overlays","summary":"Example 3: How to blend images over each other \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example we will show you how to blend a 2D image over another one. With the help of the module SoView2DOverlay we will create an overlay, which allows us to highlight all bones in the scan.\nSteps to do Develop your network Start this example by adding the shown modules, connecting the modules to form a network and loading the example image Bone.","content":"Example 3: How to blend images over each other \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example we will show you how to blend a 2D image over another one. With the help of the module SoView2DOverlay we will create an overlay, which allows us to highlight all bones in the scan.\nSteps to do Develop your network Start this example by adding the shown modules, connecting the modules to form a network and loading the example image Bone.tiff.\nOpen the panel of the module Threshold and configure the module as shown below.\nExtra Infos:\u0026nbsp; The Threshold module is explained here The module Threshold compares the contrast of each voxel of the image with a customized threshold. In this case: If the contrast of the chosen voxel is lower than the threshold, the voxel contrast is replaced by the minimum contrast of the image. If the contrast of the chosen voxel is higher than the threshold, the voxel contrast is replaced by the maximum contrast of the image. With this, we can construct a binary image, which divides the image into bone (white) and no bone (black).\nSelect output of the Threshold module to see the binary image in Output Inspector.\nImage Threshold Overlays The module SoView2DOverlay blends a 2D image over another one in a 2D viewer. In this case, all voxels with contrast above the Threshold are colored and therefore highlighted. The colored voxels are then blended over the original image. Using the panel of SoView2DOverlay, you can select the color of the overlay.\nSoView2DOverlay Extra Infos:\u0026nbsp; The SoView2DOverlay module is explained here Exercises Play around with different Threshold values and SoView2DOverlay colors. Visualize your generated threshold mask in 3D by using the View3D module Summary The module Threshold applies a relative or an absolute threshold to a voxel image. The module SoView2DOverlay blends an 2D image over another one in a 2D viewer. You can also use a 3D SoRenderArea for the same visualizations. An example can be seen in the next Example 4 Warning:\u0026nbsp; The SoView2DOverlay module is not intended to work with OrthoView2D; in this case, use a GVROrthoOverlay. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Visualization","2D","Overlays","Masks"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/testing/testingexample3/","title":"Example 3: Iterative tests in MeVisLab with Screenshots","summary":"Example 3: Iterative tests in MeVisLab \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, you are writing an iterative test. Iterative test functions run a function for every specified input. They return a tuple consisting of the function object called and the inputs iterated over. The iterative test functions are useful if the same function should be applied to different input data. These could be input values, names of input images, etc.","content":"Example 3: Iterative tests in MeVisLab \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example, you are writing an iterative test. Iterative test functions run a function for every specified input. They return a tuple consisting of the function object called and the inputs iterated over. The iterative test functions are useful if the same function should be applied to different input data. These could be input values, names of input images, etc.\nSteps to do Creating the network to be used for testing Add a LocalImage and a DicomTagViewer module to your workspace and connect them.\nExample Network Test case creation Open the panel of the DicomTagViewer and set Tag Name to WindowCenter. The value of the DICOM tag from the current input image is automatically set as value.\nSave the network.\nStart MeVisLab TestCaseManager and create a new test case called IterativeTestCase as seen in Example 1: Writing a simple testcase in MeVisLab.\nDicomTagViewer Defining the test data In TestCaseManager open the test case Python file via Edit File.\nAdd a list for test data to be used as input and a prefix for the path of the test data as seen below.\nIterativeTestCase.py\nfrom mevis import * from TestSupport import Base, Fields, ScreenShot from TestSupport.Macros import * patientPathPrefix = \u0026#34;$(DemoDataPath)/BrainMultiModal/\u0026#34; testData = { \u0026#34;ProbandT1\u0026#34;:(\u0026#34;ProbandT1.dcm\u0026#34;, \u0026#34;439.9624938965\u0026#34;), \u0026#34;ProbandT2\u0026#34;:(\u0026#34;ProbandT2.dcm\u0026#34;, \u0026#34;234.91\u0026#34;)} The above list contains an identifier for the test case (ProbandT1/2), the file names and a number value. The number value is the value of the DICOM tag (0028,1050) WindowCenter for each file.\nCreate your iterative test function Add the python function to your script file: IterativeTestCase.py\ndef ITERATIVETEST_TestWindowCenter(): return testData, testPatient This function defines that testPatient shall be called for each entry available in the defined list testData. Define the function testPatient: IterativeTestCase.py\ndef testPatient(path, windowCenter): ctx.field(\u0026#34;LocalImage.name\u0026#34;).value = patientPathPrefix + path tree = ctx.field(\u0026#34;LocalImage.outImage\u0026#34;).getDicomTree() importValue = str(tree.getTag(\u0026#34;WindowCenter\u0026#34;).value()) dicomValue = str(ctx.field(\u0026#34;DicomTagViewer.tagValue0\u0026#34;).value) ASSERT_EQ(windowCenter, importValue, \u0026#34;Checking expected WindowCenter value against DICOM tree value.\u0026#34;) ASSERT_EQ(windowCenter, dicomValue, \u0026#34;Checking expected WindowCenter value against DicomTagViewer value.\u0026#34;) Initially, the path and filename for the module LocalImage are set. The data is loaded automatically, because the module has the AutoLoad flag enabled by default. LocalImage Then, the DICOM tree of the loaded file is used to get the WindowCenter value (importValue). The previously defined value of the DicomTagViewer is set as dicomValue. The final test functions ASSERT_EQ evaluate if the given values are equal. Info:\u0026nbsp; You can use many other ASSERT* possibilities, just try using the MATE auto completion and play around with them. Run your iterative test Open MeVisLab TestCase Manager and select your package and test case. You will see 2 test functions on the right side.\nIterative Test The identifiers of your test functions are shown as defined in the list (ProbandT1/2). The TestWindowCenter now runs for each entry in the list and calls the function testPatient for each entry using the given values.\nAdding screenshots to your TestReport Now, extend your network by adding a View2D module and connect it with the LocalImage module. Add the following lines to the end of your function testPatient: IterativeTestCase.py\ndef testPatient(path, windowCenter): ... Fields.setValue(\u0026#34;View2D.startSlice\u0026#34;, 0) result = ScreenShot.createOffscreenScreenShot(\u0026#34;View2D.self\u0026#34;, \u0026#34;screentest.png\u0026#34;) Logging.showImage(\u0026#34;My screenshot\u0026#34;, result) Logging.showFile(\u0026#34;Link to screenshot file\u0026#34;, result) Your ReportViewer now shows a screenshot of the image in the View2D.\nScreenshot in ReportViewer Summary Iterative tests allow you to run the same test function on multiple input entries. It is possible to add screenshots to test cases ","tags":["Advanced","Tutorial","Testing","Python","Automated Tests","Iterative Test","Screenshot"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/image_processing/image_processing3/","title":"Example 3: Region Growing","summary":"Example 3: Region Growing Introduction A very simple approach to segment parts of an image is the region growing method. A general explanation can be found here.\nIn this example, you will segment the brain of an image and show the segmentation results as an overlay on the original image.\nSteps to do Develop your network Add a LocalImage module to your workspace and select load $(DemoDataPath)/BrainMultiModal/ProbandT1.dcm. Add a View2D module and connect both as seen below.","content":"Example 3: Region Growing Introduction A very simple approach to segment parts of an image is the region growing method. A general explanation can be found here.\nIn this example, you will segment the brain of an image and show the segmentation results as an overlay on the original image.\nSteps to do Develop your network Add a LocalImage module to your workspace and select load $(DemoDataPath)/BrainMultiModal/ProbandT1.dcm. Add a View2D module and connect both as seen below.\nExample Network Add the RegionGrowing module Add the RegionGrowing module and connect the input with the LocalImage module. You will see a message results invalid. The reason is, that a region growing always needs a starting point for getting similar pixels. The output of the module does not show a result in Output Inspector.\nResults Invalid Add a SoView2DMarkerEditor to your network and connect it with your RegionGrowing and with the View2D. Clicking into your viewer now creates markers which can be used for the region growing.\nSoView2DMarkerEditor The region growing starts on manually clicking Update or automatically if Update Mode is set to Auto-Update. We recommend to set update mode to automatic update. Additionally you should set the Neighborhood Relation to 3D-6-Neighborhood (x,y,z), because then your segmentation will also affect the z-axis.\nSet Threshold Computation to Automatic and define Interval Size as 1.600 % for relative, automatic threshold generation.\nExtra Infos:\u0026nbsp; For more information, see MeVisLab Module Reference Auto-Update for RegionGrowing Clicking into your image in the View2D now already generates a mask containing your segmentation. As you did not connect the output of the RegionGrowing, you need to select the output of the module and use the Output Inspector to visualize your results.\nOutput Inspector Preview In order to visualize your segmentation mask as an overlay in the View2D, you need to add the SoView2DOverlay module. Connect it as seen below.\nSoView2DOverlay Your segmentation is now shown in the View2D. You can change the color and transparency of the overlay via SoView2DOverlay.\nClose gaps Scrolling through the slices, you will see that your segmentation is not closed. There are lots of gaps where the grey value of your image differs more than your threshold. You can simply add a CloseGap module to resolve this issue. Configure Filter Mode as Binary Dilatation, Border Handling as Pad Src Fill and set KernelZ to 3.\nThe difference before and after closing the gaps can be seen in the Output Inspector.\nOutput_Before Output_After You can play around with the different settings of the RegionGrowing and CloseGap modules to get a better result.\nVisualize 2D and 3D You can now also add a View3D to show your segmentation in 3D. Your final result should look similar to this.\nFinal Result Summary The module RegionGrowing allows a very simple segmentation of similar grey values. Gaps in a segmentation mask can be closed by using the CloseGap module. Segmentation results can be visualized in 2D and 3D. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Image Processing","Segmentation","Region Growing"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/visualization/visualizationexample4/","title":"Example 4: Display 2D images in Open Inventor SoRenderArea","summary":"Example 4: Display images converted to Open Inventor scene objects Introduction In the previous example you learned how to use the module SoView2DOverlay together with a View2D. MeVisLab provides a whole family of SoView2D* modules (SoView2DOverlay, SoView2DRectangle, SoView2DGrid, \u0026hellip;). All these modules create or interact with scene objects and are based on the module SoView2D, which can convert a voxel-image into a scene object. In this example, you will get to know some members of the SoView2D-family.","content":"Example 4: Display images converted to Open Inventor scene objects Introduction In the previous example you learned how to use the module SoView2DOverlay together with a View2D. MeVisLab provides a whole family of SoView2D* modules (SoView2DOverlay, SoView2DRectangle, SoView2DGrid, \u0026hellip;). All these modules create or interact with scene objects and are based on the module SoView2D, which can convert a voxel-image into a scene object. In this example, you will get to know some members of the SoView2D-family.\nExtra Infos:\u0026nbsp; More information about the SoView2D-family can be found here\nand in the SoView2D Reference\nSteps to do Develop your network We will start the example by creating an overlay again. Add the following modules and connect them as shown. Select a Threshold and a Comparison Operator for the module Threshold as in the previous example. The module SoView2D converts the image into a scene-object. The image as well as the overlay is rendered and displayed by the module SoRenderArea.\nSoRenderArea Add Extension You may have noticed, that you are not able to scroll through the slices. This functionality is not yet implemented in the viewer SoRenderArea. To add a set of functionalities and viewer extensions, which are commonly used in conjunction with a 2D viewer, add the module View2DExtensions to the workspace and connect it as shown below. Now, additional information of the image can be displayed in the viewer and you can navigate and scroll through the slices.\nView2DExtensions Add Screenshot Gallery to Viewing Area With the help of the module SoRenderArea you can record screenshots and movies. Before we do that, open [ View \u0026rarr; Views \u0026rarr; Screenshot Gallery ], to add the Screenshot Gallery to your viewing area.\nScreenshot Gallery Create screenshots and movies If you now select your favorite slice of the bone in the Viewer SoRenderArea and press F11 , a screenshot is taken and displayed in the Screenshot Gallery. For recording a movie, press F9 to start the movie and F10 to stop recording. You can find the movie in the Screenshot Gallery.\nRecord Movies and Snapshots Exercises Create movies of a 3D Scene Summary Modules of the SoView2D-family create or interact with scene objects and are based on the module SoView2D, which can convert a voxel-image into a scene object The SoRenderArea module provides functionalities for screenshots and movie generation \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Visualization","2D","3D","Open Inventor"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/image_processing/image_processing4/","title":"Example 4: Subtract 3D objects","summary":"Example 4: Subtract 3D objects Introduction In this example, we load an image and render it as WEMIsoSurface. Then we create a 3-dimensional SoSphere and subtract the sphere from the initial WEM.\nSteps to do Develop your network Add a LocalImage module to your workspace and select load $(DemoDataPath)/BrainMultiModal/ProbandT1.dcm. Add a WEMIsoSurface, a SoWEMRenderer, a SoBackground and a SoExaminerViewer module and connect them as seen below. Make sure to configure the WEMIsoSurface to use a Iso Min.","content":"Example 4: Subtract 3D objects Introduction In this example, we load an image and render it as WEMIsoSurface. Then we create a 3-dimensional SoSphere and subtract the sphere from the initial WEM.\nSteps to do Develop your network Add a LocalImage module to your workspace and select load $(DemoDataPath)/BrainMultiModal/ProbandT1.dcm. Add a WEMIsoSurface, a SoWEMRenderer, a SoBackground and a SoExaminerViewer module and connect them as seen below. Make sure to configure the WEMIsoSurface to use a Iso Min. Value of 420 and a Voxel Sampling 1.\nExample Network The SoExaminerViewer now shows the head as a 3-dimensional rendering.\nSoExaminerViewer Add a 3D sphere to your scene We now want to add a 3-dimensional sphere to our scene. Add a SoMaterial and a SoSphere to your network, connect them to a SoSeparator and then to the SoExaminerViewer. Set your material to use a Diffuse Color red and adapt the size of the sphere to Radius 50.\nExample Network The SoExaminerViewer now shows the head and the red sphere inside.\nSoExaminerViewer Set location of your sphere In order to define the best possible location of the sphere, we additionally add a SoTranslation Module and connect it to the SoSeparator between the material and the sphere. Define a translation of x=0, y=20 and z=80.\nExample Network Subtract the sphere from the head We now want to subtract the sphere from the head to get a hole. Add another SoWEMRenderer, a WEMLevelSetBoolean and a SoWEMConvertInventor to the network and connect them to a SoSwitch as seen below. The SoSwitch also needs to be connected to the SoWEMRenderer of the head. Set your WEMLevelSetBoolean to use the Mode Difference.\nExample Network What happens in your network now?\nThe SoSphere is converted to a WEM. The WEMs from the head and from the sphere are subtracted by using a WEMLevelSetBoolean. The result of the subtraction is used for a SoWEMRenderer Both SoWEMRenderer (the head on the left side and the subtraction on the right side) are inputs for a SoSwitch. The SoSwitch toggles through its inputs and you can show the original WEM of the head or the subtraction. SoExaminerViewer_1 SoExaminerViewer_2 You can now toggle the hole to be shown or not, depending on your setting for the SoSwitch.\nSummary The module WEMLevelSetBoolean allows to subtract or add 3-dimensional WEM objects. The SoSwitch can toggle multiple inventor scenes as input \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Image Processing","3D","Subtraction"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/image_processing/image_processing5/","title":"Example 5: Clip Planes","summary":"Example 4: Subtract 3D objects Introduction In this example, we are using the SoGVRDrawOnPlane module to define the currently visible slice from a 2D view as a clip plane in 3D.\nSteps to do Develop your network First we need to develop the network to scroll through the slices. Add a LocalImage module to your workspace and select the file ProbandT1 from MeVisLab demo data.\nAdd the modules OrthoReformat3, Switch, SoView2D, View2DExtensions and SoRenderArea and connect them as seen below.","content":"Example 4: Subtract 3D objects Introduction In this example, we are using the SoGVRDrawOnPlane module to define the currently visible slice from a 2D view as a clip plane in 3D.\nSteps to do Develop your network First we need to develop the network to scroll through the slices. Add a LocalImage module to your workspace and select the file ProbandT1 from MeVisLab demo data.\nAdd the modules OrthoReformat3, Switch, SoView2D, View2DExtensions and SoRenderArea and connect them as seen below.\nExample Network In previous tutorials, we already learned that it is possible to show 2D slices in a SoRenderArea. For scrolling through the slices, a View3DExtensions module is necessary. In this network, we also have a OrthoReformat3 module. It allows us to transform the input image (by rotating and/or flipping) into the three main views commonly used:\nAxial Coronal Sagittal The Switch takes multiple input images and you can toggle between them to show one of the orthogonal transformations to be used as output.\nThe SoRenderArea now shows the 2D images in a view defined by the Switch.\nView0 View1 View2 Current 2D slice in 3D We now want to visualize the slice visible in the 2D images as a 3D plane. Add a SoGVRDrawOnPlane and a SoExaminerViewer to your workspace and connect them. We should also add a SoBackground and a SoLUTEditor. The viewer remains empty because no source image is selected to display. Add a SoGVRVolumeRenderer and connect it to your viewer and the LocalImage.\nExample Network A 3-dimensional plane of the image is shown. Adapt the LUT as seen below.\nSoLUTEditor We now have a single slice of the image in 3D, but the slice is static and cannot be changed. In order to use the currently visible slice from the 2D viewer, we need to create a parameter connection from the SoView2D Position Slice as plane to the SoGVRDrawOnPlane Plane vector.\nSoView2D Position SoGVRDrawOnPlane Plane Now the plane representation of the visible slice is synchronized to the plane of the 3D view. Scrolling through your 2D slices changes the plane in 3D.\nVisible slice in 3D Current 2D slice as clip plane in 3D This slice shall now be used as a clip plane in 3D. In order to achieve this, you need another SoExaminerViewer and a SoClipPlane. Add them to your workspace and connect them as seen below. You can also use the same SoLUTEditor and SoBackground for the 3D view. Also use the same SoGVRVolumeRenderer, the 3D volume does not change.\nExample Network Now your 3D scene shows a 3-dimensional volume cut by a plane in the middle. Once again, the clipping is not the same slice as your 2D view shows.\nClip plane in 3D Again create a parameter connection from the SoView2D Position Slice as plane, but this time to the SoClipPlane.\nSoClipPlane Plane If you now open all 3 viewers and scroll through the slices in 2D, the 3D viewers are both synchronized with the current slice. You can even toggle the view in the Switch and the plane is adapted automatically.\nFinal 3 views Summary The module OthoReformat3 transforms input images to the three viewing directions: coronal, axial and sagittal A Switch can be used to toggle through multiple input images The SoGVRDrawOnPlane module renders a single slice as a 3-dimensional plane 3-dimensional clip planes on volumes can be created by using a SoClipPlane module \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Image Processing","3D","Clip Planes"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/visualization/visualizationexample5/","title":"Example 5: Volume rendering and interactions","summary":"Example 5: Volume rendering and interactions \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example we like to convert a scan of a head into a 3D scene-object. The scene-object allows to add some textures, interactions and animations.\nSteps to do Develop your network Implement the following network and open the image $(DemoDataPath)/BrainMultiModal/ProbandT1.tif.\nSoGVRVolumeRenderer The module SoGVRVolumeRenderer allows volume rendering of 3D and 4D images.\nExtra Infos:\u0026nbsp; Additional information about Volume Rendering can be found here: Giga Voxel Renderer Change LUT We like to add a surface color to the head.","content":"Example 5: Volume rendering and interactions \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Introduction In this example we like to convert a scan of a head into a 3D scene-object. The scene-object allows to add some textures, interactions and animations.\nSteps to do Develop your network Implement the following network and open the image $(DemoDataPath)/BrainMultiModal/ProbandT1.tif.\nSoGVRVolumeRenderer The module SoGVRVolumeRenderer allows volume rendering of 3D and 4D images.\nExtra Infos:\u0026nbsp; Additional information about Volume Rendering can be found here: Giga Voxel Renderer Change LUT We like to add a surface color to the head. In order to do that, we add the module SoLUTEditor, which adds an RGBA Look up table (LUT) to the scene. Connecting this module to SoExaminerViewer left to the connection between SoGVRRenderer and SoExaminerViewer (remember the order in which Open Inventor modules are executed) allows you to set the surface color of the head.\nSoLUTEditor To change the color, open the panel of SoLUTEditor. In this editor we can change color and transparency interactively (for more information take a look at the help page ). Here, we have a range from black to white and from complete transparency to full opacity.\nSoLUTEditor change colors We now like to add color. New color-points can be added by clicking on the color bar at the bottom side of the graph and existing points can be moved by dragging. You can change the color of each point under Color.\nSoLUTEditor add colors Interactions As a next step, we add some dynamics to the 3D scene: We like to rotate the head. In Order to do this, add the modules SoRotationXYZ and SoElapsedTime to the workspace and connect the modules as shown.\nSoRotationXYZ Open the panels of both modules and select the axis the image should rotate around. In this case the z-axis was selected. Now, build a parameter connection from the parameter Time out of the module SoElapsedTime to the parameter Angle of the module SoRotationXYZ. The angle changes with time and the head starts turning.\nTime and Angle Exercises Change rotation speed change rotation angle Pause rotation on pressing SPACE Summary The module SoGVRVolumeRenderer renders paged images like DICOM files in a GVR. Lookup Tables (LUT) allow you to modify the color of your renderings \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Visualization","3D","Volume Rendering","GVR","LUT"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/visualization/visualizationexample6/","title":"Example 6: MeVis Path Tracer","summary":"Example 6: MeVis Path Tracer Introduction The MeVis Path Tracer offers a Monte Carlo Path Tracing framework running on CUDA GPUs. It offers photorealistic rendering of volumes and meshes, physically based lightning with area lights and soft shadows and fully integrates into MeVisLab Open Inventor (camera, depth buffer, clipping planes, etc.).\nExtra Infos:\u0026nbsp; CUDA is a parallel computing platform and programming model created by NVIDIA. For further information, see NVIDIA website.","content":"Example 6: MeVis Path Tracer Introduction The MeVis Path Tracer offers a Monte Carlo Path Tracing framework running on CUDA GPUs. It offers photorealistic rendering of volumes and meshes, physically based lightning with area lights and soft shadows and fully integrates into MeVisLab Open Inventor (camera, depth buffer, clipping planes, etc.).\nExtra Infos:\u0026nbsp; CUDA is a parallel computing platform and programming model created by NVIDIA. For further information, see NVIDIA website. The SoPathTracer module implements the main renderer (like the SoGVRVolumeRenderer). It collects all SoPathTracer* extensions (on its left side) in the scene and renders them. Picking is also supported, but currently only the first hit position. It supports an arbitrary number of objects with different orientation and bounding boxes.\nPath Tracing Path Tracing allows interactive, photorealistic 3D environments with dynamic light and shadow, reflections and refractions.\nIn the beginning, 3D images have been generated as seen from a single viewpoint. A mapping has been done from scene geometry in 3D to a pixel on the screen. The color of each pixel on screen has been assigned by a pixel shader. A pixel shader is able to take into account physical effects such as light position. Computation is very fast but the results do not include effects such as shadows, illumination and indirect lightning.\nTodays rendering is based on tracing light paths. Objects in a 3D scene contribute illumination to every other object. The illumination can be emitted from a light source or reflected by a surface. Illumination coming from surfaces must scatter in a particular direction that is some function of the incoming direction of the arriving illumination, and the outgoing direction being sampled (Wikipedia - Path Tracing).\nExtra Infos:\u0026nbsp; For more information about Path Tracing, see the NVIDIA website. Modules The SoPathTracer is the main renderer of the framework and should always appear on the right in your scene. It collects the current Open Inventor camera and clipping planes and uses them when rendering.\nThere are various extensions that can be used.\nVolumes SoPathTracerVolume loads and renders a volume, multiple volumes with arbitrary world coordinates are supported\nVolumes support: Diffuse/emissive/material LUT Shading options Subvolume mixing Additional transformation matrix Material selection SoPathTracerMaskVolume can be used to mask voxels in SoPathTracerVolume volumes\nAllows to load a 8bit mask volume THe mask volume can be used by any volume or instance It allows to: Change the alpha and color of inside/outside voxels Change the tag value (see SoPathTracerVolume) Very useful in combination with SoVolumeCutting SoPathTracerTagVolume can be used to tag voxels in SoPathTracerVolume volumes\nAllows to load a 8bit tag volume The tags are used to select a per-object LUT and/or material A 2D LUT can be provided using LUTConcat or SoLUTEditor2D Per-tag materials can be provided by adding multiple materials to the inMaterial scene Useful to render segmented objects SoPathTracerVolumeInstance can be used to render a SoPathTracerVolume with differnt transformation, subvolume, LUT, material, \u0026hellip;\nAllows to instantiate an existing volume Supports all options of a normal volume, but only references the volume itself This allows to: Use a different LUT Change shading options Change subvolume Change transformation matrix Different material selection SoPathTracerSlice renders a slice at the given plane, showing the volume data of the given volume\nAllows to render a cut slice through a volume Allows to set an arbitrary plane and works on volumes and instances Has its own LUT and can be opaque or transparent SoPathTracerIsoSurface renders an iso surface (with first hit refinement) on the given base volume\nAllows to render an ISO surface of a volume Works on volumes and instances Supports opaque and transparent surfaces ISO surface is rendered on-the-fly Hit refinement is used to provide high-quality surfaces Arbitrary material can be specified Geometry SoPathTracerMesh scans the input scene for triangle meshes and ray traces them Allows to render arbitrary triangle meshes Scans the input scene for triangle meshes and converts them to a bounding volume hierarchy (BVH) Supports different materials by adding SoPathTracerMaterials Objects can be turned on/off via material nodes (without BVH rebuilding) Supports opaque and transparent meshes SoPathTracerLines scans the input scene for line sets and ray traces them as cylinders with round caps Allows to render thick lines (capsules) Scans the input scene for SoLineSet/SoIndexedLineSet and converts them to a BVH Different materials are supported by adding SoPathTracerMaterial nodes Supports opaque and transparent lines Useful to render fibers or stream lines SoPathTracerSpheres renders a marker list as ray traced spheres Allows to render markers as spheres Converts marker list to spheres and creates a BVH Currently only supports single material Lights SoPathTracerAreaLight provides a realistic area light with attenuation, area and distance Provides an area light Multiple area lights are supported Lights can be placed: Around the scene bounding box using polar coordinates At absolute camera or world position (as head or local light) Light intensity is automatically adapted to the scene size Otherwise it would be hard to select an intensity that works on different scales SoPathTracerBackgroundLight provides a background light, using image based lighting from a sphere or cube map Provides environmental lighting It supports: Specifying environment light colors Image based lighting using a cube map or sphere map Only one background light can be added to a scene Material SoPathTracerMaterial allows to specify which material should be used for a given object. Provides material settings for other nodes Offers to select the used material and its parameters Is connected to the inMaterial of other nodes Multiple materials may be placed into the input scene of SoPathTracerMesh and SoPathTracerLines Allows to override volume shader settings as well The following examples shall help you to learn how to use them.\nExample images MeVis Path Tracer Image 1 MeVis Path Tracer Image 2 MeVis Path Tracer Image 3 MeVis Path Tracer Image 4 MeVis Path Tracer Image 5 MeVis Path Tracer Image 6 MeVis Path Tracer Image 7 MeVis Path Tracer Image 8 MeVis Path Tracer Image 9 MeVis Path Tracer Image 10 ","tags":["Beginner","Tutorial","Visualization","3D","Volume Rendering","Path Tracer"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/visualization/pathtracer/pathtracerexample1/","title":"Example 6.1: Loading a SoPathTracerVolume","summary":"Example 6.1: Loading a SoPathTracerVolume Introduction In this example we are having a closer look at the example network of the SoPathTracer module. This network uses the SoPathTracerVolume module to render a dataset downloaded from our website.\nExtra Infos:\u0026nbsp; The engine dataset is a downscaled version of a 1024x1024 CT scan. The dataset was provided by: Varex Industrial CT Services \u0026amp; Engineering 425 Barclay Boulevard Lincolnshire, Illinois 60069\nIndustrial.CTServices@vareximaging.com\nSteps to do Add the SoPathTracer module to your workspace and open the example network via right mouse button [ Help \u0026rarr; Show Example Network ].","content":"Example 6.1: Loading a SoPathTracerVolume Introduction In this example we are having a closer look at the example network of the SoPathTracer module. This network uses the SoPathTracerVolume module to render a dataset downloaded from our website.\nExtra Infos:\u0026nbsp; The engine dataset is a downscaled version of a 1024x1024 CT scan. The dataset was provided by: Varex Industrial CT Services \u0026amp; Engineering 425 Barclay Boulevard Lincolnshire, Illinois 60069\nIndustrial.CTServices@vareximaging.com\nSteps to do Add the SoPathTracer module to your workspace and open the example network via right mouse button [ Help \u0026rarr; Show Example Network ].\nSoPathTracer Example Network The SoExaminerViewer is empty. You need to load the dataset first. Click LoadDataFromWeb and inspect the viewer module. A 3-dimensional engine is shown.\n3D engine with SoPathTracer Opening the same file in a SoGVRVolumeRenderer looks completely different.\n3D engine with SoGVRVolumeRenderer Open the panel of the SoPathTracer. You have lots of different settings for your rendering. We will try to explain some of them so that you understand what\u0026rsquo;s the difference.\nSoPathTracer Render Mode The most important field for MeVis Path Tracer is the render mode.\n","tags":["Beginner","Tutorial","Visualization","3D","Volume Rendering","Path Tracer"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/thirdparty/example2/","title":"Face detection in OpenCV","summary":"ThirdParty Example 2: Face detection in OpenCV This Python file shows how to access the webcam and detect faces in the video stream via OpenCV.\nDownload You can download the Python files here","content":"ThirdParty Example 2: Face detection in OpenCV This Python file shows how to access the webcam and detect faces in the video stream via OpenCV.\nDownload You can download the Python files here\n","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/howto/","title":"How to use examples","summary":"How to use the available examples: The examples provided on this site are (normally) either *.mlab files or *.zip archives. Sometimes there are also Python (*.py) or Script (*.script) files. This page shall explain how to use them in your local MeVisLab installation.\nMeVisLab (*.mlab) files MeVisLab files are networks stored as *.mlab file. They can be opened in MeVisLab via double-click or via [ File \u0026rarr; Open ].\nArchives (*.","content":"How to use the available examples: The examples provided on this site are (normally) either *.mlab files or *.zip archives. Sometimes there are also Python (*.py) or Script (*.script) files. This page shall explain how to use them in your local MeVisLab installation.\nMeVisLab (*.mlab) files MeVisLab files are networks stored as *.mlab file. They can be opened in MeVisLab via double-click or via [ File \u0026rarr; Open ].\nArchives (*.zip files) Archives are mostly Macro Modules. They require a user package. See Example 2.1: Package creation for more information about MeVisLab packages.\nHaving a package, the examples can be extracted into the directory of your package. Make sure to keep the directory structure inside the package so that the examples are loaded correctly.\nThe directory structure of a MeVisLab package looks like this: Package directory structure In this example, we have the package TutorialSummary in the package group MeVis. A package normally at least contains a Projects directory. This directory should include your Macro Modules. If you extract a *.zip file of a Macro Module, the Projects folder of your package should be the target directory.\nIn some cases we also provide test cases. Extract them into a directory TestCases. Package directory structure In case the directories do not exist, for example in an empty package, you can create them. Make sure to use the same names for the Projects and TestCases directories.\nBack in MeVisLab, you might need to reload the module cache after extracting the example. Open [ Extras \u0026rarr; Reload Module Database (Clear Cache) ].\nPython (*.py) or Script (*.script) files Sometimes we provide Python or Script files. Make sure to follow the steps of the tutorial and then paste the content of the provided files into your file. Python and Script files without having a Macro Module or test case do not make sense in MeVisLab, therefore the tutorial needs to be done first.\n","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/image_processing/","title":"Image Processing","summary":"Image Processing Examples: The following examples are available:\n[1] Arithmetic operations on two images [2] Clip Planes [3] Masking images [4] Region Growing (Segmentation) [5] Subtract 3D objects ","content":"Image Processing Examples: The following examples are available:\n[1] Arithmetic operations on two images [2] Clip Planes [3] Masking images [4] Region Growing (Segmentation) [5] Subtract 3D objects ","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/introduction/","title":"Introduction","summary":"MeVisLab Tutorial Introduction Welcome to MeVisLab!\nMeVisLab is a development environment for rapid prototyping and product development of medical and industrial imaging applications. It includes a Software Development Kit (SDK) and an ApplicationBuilder for deploying your applications to end-customers.\nThe MeVisLab SDK consists of an Integrated Development Environment (IDE) for visual programming and the advanced text editor MATE for Python scripting including code completion, debugging, profiling and automated test development or execution.","content":"MeVisLab Tutorial Introduction Welcome to MeVisLab!\nMeVisLab is a development environment for rapid prototyping and product development of medical and industrial imaging applications. It includes a Software Development Kit (SDK) and an ApplicationBuilder for deploying your applications to end-customers.\nThe MeVisLab SDK consists of an Integrated Development Environment (IDE) for visual programming and the advanced text editor MATE for Python scripting including code completion, debugging, profiling and automated test development or execution.\nYou can re-use thousands of pre-defined Modules for image processing (2D up to 6D images) and visualization. You will get a quick introduction into the available modules and example networks in the following tutorials.\nMore than 20 years of experience and development made MeVisLab one of the most powerful development platforms for medical image processing. Several prototypes and applications have been realized on the basis of MeVisLab, including software assistants for neuro-imaging, dynamic image analysis, surgery planning, and cardiovascular analysis.\nHow to read this tutorial: This tutorial is a hands-on training. You will learn basic mechanics and features of MeVisLab. We will start by explaining the user interface and end building our own web-applications. While reading the tutorial, open the MeVisLab SDK and try to implement each step yourself. You will learn new mechanics and possibilities in MeVisLab step-by-step. Additional information and links are provided in colored boxes.\nThe tutorials are divided into chapters for a specific topic. Each chapter contains one or more example(s).\nGlossary Term Description MeVisLab MeVisLab consists of the MeVisLab SDK and the MeVisLab ApplicationBuilder. MeVisLab SDK The MeVisLab Software Development Kit (SDK) is the MeVisLab IDE including the text editor MATE and any tools integrated for debugging, testing and profiling. MeVisLab ApplicationBuilder The MeVisLab ApplicationBuilder allows you to generate installable executables from your developed networks and applications. These executables can be delivered to customers. MeVisLab IDE The MeVisLab Integrated Development Environment (IDE) is your starting point whenever you are working with MeVisLab. It provides a programming interface and an advanced text editor. MeVisLab MATE The Advanced Text Editor (MATE) is an integrated text editor for Python and MDL development in MeVisLab. It provides auto-completion and syntax highlighting, as well as debugging functionalities. MDL The MeVisLab Definition Language (MDL) is the language for developing basic User Interfaces for Networks and Modules in MeVisLab. Module A Module is a single instance providing encapsulated functionalities for a specific purpose. MeVisLab provides thousands of such pre-defined Modules and you can develop your own Modules for extending functionalities. Modules provide inputs and outputs for connections in a Network and/or one or more Panels for interacting. Panel A Panel is a User Interface providing possibilities to interact with MeVisLab. Field Parameters of Modules are called fields. Several different types of fields are available such as numbers, text, trigger buttons, etc. Publicly accessible fields can be modified in the Module Inspector or Panel of the selected Module. Macro Module Macro Modules encapsulate Networks including input and output into a single Module. In order to see whats inside a Macro Module, you can open the Context Menu via Right-Click and select [ Show Internal Network ]. You can choose to create Local Macros and Global Macros. Local Macro Local Macros are only available in your currently opened Network. You cannot use the Module Search in MeVisLab to find Local Macros. Global Macro Global Macros are integrated into MeVisLab and can be used in any future Networks. They are available in Module search. Network A Network defines at least two connected Modules. Example Network Each Module provides an Example Network to see how it can be used. Right-Click on the Module and select Help \u0026gt; Show Example Network Output Inspector The Output Inspector is a quick preview of the output of a specific Module. The output can be an image or any other user defined output format. For images, a 2D and 3D view including basic interactions is already available. Module Inspector The Module Inspector shows publicly available properties of the selected module and their current values. Changes in Module Inspector are applied on the fly. Workspace The Workspace is the area where you can add and connect Modules. Multiple Networks are organized in separate Tabs. Views Area The right side of the MeVisLab IDE provides a space to add several predefined panels like Output- and Module inspectors. Debug Output The Debug Output shows debugging messages of your Modules and the MeVisLab IDE. Open Inventor Open Inventor Modules process and render 3D scene objects and enable image interactions. Scene Objects CSO Contour Segmentation Objects (CSOs) WEM Winged Edge Meshes (WEMs) GVR Giga Voxel Renderer (GVR) Lookup Table (LUT) Package Installation and first start Right after installation of MeVisLab, you will find some new icons on your Desktop (if selected during setup).\nMeVisLab Desktop Icons (Windows) Use the top middle icon to start the MeVisLab IDE. You can also start the integrated text editor MATE or the ToolRunner. For this tutorial, you will generally require the IDE.\nYou can also use the QuickStart icons but any packages developed yourself during these tutorials will not be loaded, so you should not use this for now.\nMeVisLab IDE User Interface First, start MeVisLab IDE. After the Welcome Screen, the standard user interface opens.\nMeVisLab IDE User Interface Workspace By default, MeVisLab starts with an empty workspace. The workspace is the place for developing and editing Networks via visual programming. Networks of Modules form the basis for all processing and visualization pipelines.\nViews Area The standard Views Area contains the Output Inspector and the Module Inspector. With the help of the Output Inspector, you can visualize the Module output.\nFurther information of each module, like information about Module parameters, can be found using the Module Inspector.\nDebug Output In the Debug Output, you can find any debugging information about your MeVisLab installation.\nThe MeVisLab IDE and the layout is completely configurable. You can rearrange the items and add new views via [ Main Menu \u0026rarr; View \u0026rarr; Views ].\nFiletypes in MeVisLab Here a list of the most important file types: Extension Description .mlab Network file, includes all information about the network's modules, their settings, their connections, and module groups. Networks developed by using the MeVisLab SDK are stored as .mlab file and can only be opened having a valid SDK license. .def Module definition file, necessary for a module to be added to the common MeVisLab module database. May also include all MDL script parts (if they are not sourced out to the .script file). .script MDL script file, typically includes the user interface definition for panels. See Chapter GUI Development for an example on GUI programming. .mlimage MeVisLab internal image format for 6D images saved with all DICOM tags, lossless compression, and in all data types. .mhelp File with descriptions of all fields and the use of a module, edit- and creatable by using MATE. See Help files for details. .py Python file, used for scripting in macro modules. See Python scripting for an example on macro programming. .dcm DCM part of the imported DICOM file, see Importing DICOM Data. Types of Modules Within the concept of MeVisLab the basic entities we are working with a graphical representation of modules having their specific functions for image processing, image visualization, and image interaction.\nThe three basic module types (ML, Open Inventor and Macro Module) are distinguished by their colors:\nType Look Characteristics ML Module (blue) ML Module Page-based, demand-driven processing of voxels Open Inventor Module (green) Open Inventor Module Visual scene graphs (3D); naming convention: all modules starting with So (for scene object) Macro Module (brown) Macro Module Combination of other module types, allowing implementing hierarchies and scripted interaction If a module is invalid, it is displayed in bright red. This might happen if the module itself is not available on your system.\nInvalid Modules Appearance Explanation Invalid Module Invalid module Macro State Invalid Macro containing an invalid module The number of warning and error messages that are being printed to the debug console are listed in the upper right corner of the module. Once the debug console is cleared, the warning and error indicators at the module are also cleared. If the module produces information messages, their number is printed in gray at this position. This enables a network or module developer to find the modules in a network that produce messages quickly.\nModule context menu Each module provides a context menu to get additional information.\nContext Menu of a module Show Internal Network: Macro Modules provide an entry to open the internal network. You can see what happens inside a Macro Module. This network may also contain other Macro Modules. Show Window: In case a module does not provide an own User Interface, you will see the Automatic Panel of the module showing the name. Modules may additionally have one or more Windows to be opened. You can also open the Scripting Console of a module to use Python. Instance Name: You can also edit or copy the instance name. Editing is useful if you have the same module multiple times in one network. You should give the modules a useful name to access and distinguish them in Python. Copying the name is useful if you want to access the module in Python. You will have the correct name in your clipboard for usage in Python. Help: The menu entry Help provides access to the Module Help pages and to an Example Network where the module is used. This example network often helps to understand which additional modules are necessary for usage. Extras: Automated tests written for the specific module can be executed here. You can also run this Module in a separate process. Reload Definition: In case you are currently working on a Module, you may need to reload the definition so that your changes are applied on the Module (for example attached Python scripts). Related Files: Related files allows a quick access to the modules *.script or *.py files. The files are automatically opened in MATE for editing. Show Enclosing Folder: This entry opens the directory where your Module has been stored. Grouping: Multiple Modules can be Grouped and the groups can be named. This makes sense to structure your network for a better overview. In addition to that, grouped Modules can be converted to local- or global Macro Modules easily. Module Connectors Most modules have connectors which are displayed on the module. These represent the inputs (bottom) and outputs (top) of modules.\nIn MeVisLab, three types of connectors are defined.\nLook Appearance Definition Triangle - ML Image triangle ML images Circle - Inventor Scene half-circle Inventor scene Square - Base Object square Base objects: pointers to data structures By connecting these connectors and therefore establishing a so-called data connection, image data, or Open Inventor information is transported from one module to one or more others.\nBesides connecting connectors, basically any field of modules can be connected to other compatible fields of modules with a parameter connection.\nSome modules contain hidden connectors in addition to the ones you can see when adding a module to the workspace. Click on the workspace and press SPACE to see the hidden connectors as well as the internal networks of each module. You can now use the hidden connectors for building connections.\nExtra Infos:\u0026nbsp; For more information about connector and connection types click here\nFor more information about connecting, disconnecting, moving, and replacing connections click here\nMacro Modules More Information:\u0026nbsp; More information about creating Macro Modules is available in Tutorial Chapter I - Example 2.2 Searching and Adding Modules There are several ways to add a module to the current network, for example:\nvia the menu bar, entry [ Modules ]. via the menu bar, [ Quick Search ]. via the View Module Search. via the View Module Browser. via copy and paste from another network. by scripting, see the Scripting Reference Both the [ Modules ] menu and the Module Browser display all available modules. The modules are sorted hierarchically by topics and by module name, as given in the file Genre.def.\nTherefore, both places are a good starting point when in need of a specific function, like an image load module.\nModules Menu and Module Browser The advantage of the Module Browser is that you can right-click the entries, open the context menu and, for example, open the help (in your default Internet browser) or the module files (in MATE, the in-built text editor).\nNote:\u0026nbsp; For a module to get listed, it has to be available in the SDK distribution or in your user-defined packages. If in doubt or missing something, check out the loaded packages in the Preferences.\nFor details on packages, see Package Creation.\nUsually the quickest way to add modules to a network is the quick search in the menu bar. It offers you the possibility to search for modules by module name. By default, the search will also be extended to keywords and substrings and is case-insensitive. To change these settings, click the magnifier button for the search options.\nTip:\u0026nbsp; The quick search field does not need to have the focus. Any time you enter something in the MeVisLab GUI while not being in a dialog window, this will be entered into the quick search automatically. Quick Search Options To search for a module to load an image, you could either type load or image. Let us go with the second option this time. While typing image, the possible results appear. Use the \u0026uarr; ArrowUp or \u0026darr; ArrowDown keys on your keyboard to move to one of the listed modules. The module\u0026rsquo;s About information will appear next to it, allowing you to decide if this is the right module for you.\nQuick Search Results Tip:\u0026nbsp; For a more complex search, use the Module Search View. ","tags":["Tutorial","Introduction","Glossary","Modules","ML Module","Filetypes","UI","Workspace","Search"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/testing/example3/","title":"Iterative tests in MeVisLab with Screenshots","summary":"Testing Example 3: Iterative tests in MeVisLab with Screenshots In this example you will learn how to write iterative tests in MeVisLab. In addition to that, we create a screenshot of a viewer and add the image to the test report.\nDownload n.a.","content":"Testing Example 3: Iterative tests in MeVisLab with Screenshots In this example you will learn how to write iterative tests in MeVisLab. In addition to that, we create a screenshot of a viewer and add the image to the test report.\nDownload n.a.\n","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/markerobjects/","title":"Marker Objects","summary":"Markers in MeVisLab Introduction In MeVisLab you can equip images and other data objects with markers. In this example you will see how to create, process and use markers.\nMarker Creation and Rendering To create markers, you can use a marker editor, for example the SoView2DMarkerEditor. Connect this editor to a viewer as shown below. Now you can interactively create new markers. Connect the module XMarkerListContainer to your marker editor to store markers in a list.","content":"Markers in MeVisLab Introduction In MeVisLab you can equip images and other data objects with markers. In this example you will see how to create, process and use markers.\nMarker Creation and Rendering To create markers, you can use a marker editor, for example the SoView2DMarkerEditor. Connect this editor to a viewer as shown below. Now you can interactively create new markers. Connect the module XMarkerListContainer to your marker editor to store markers in a list.\nCreate Markers Using the module StylePalette you can define the style of your markers. In order to set different styles for different markers, change the field Color Mode in the Panel of SoView2DMarkerEditor to Index.\nStyle of Markers With the help of the module So3DMarkerRenderer markers of an XMarkerList can be rendered.\nRendering of Markers Working with Markers It is possible to convert other data objects into markers and also to convert markers into other data objects. An example for that is given here. With the help of the module MaskToMarkers you can create markers from an image. Using the module MaskToSurface you can generate a surface object from a list of markers. There are more modules, which can be used for marker conversion. For more converter modules, check out [ Modules \u0026rarr; Geometry \u0026rarr; Markers ] in MeVisLab.\nBuild the following network. Press the Reload buttons of the modules MaskToMarkers and MarkersToSurface to enable the conversion. Now you can see both, the markers and the created surface in the module SoExaminerViewer. Use the toggle options of SoToggle and SoWEMRenderer to enable/disable the visualization of markers and surface.\nConvert Markers Exercises Get the HU value of the image at your markers location.\nSummary Markers are single point objects located at a defined location in your image Markers can be converted to be rendered in 3D ","tags":["Beginner","Tutorial","Data Objects","2D","Marker"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/open_inventor/","title":"Open Inventor","summary":"Open Inventor Examples: The following examples are available:\n[1] Camera interaction with collision detection [2] Mouse interactions in an Open Inventor scene [3] Open Inventor objects ","content":"Open Inventor Examples: The following examples are available:\n[1] Camera interaction with collision detection [2] Mouse interactions in an Open Inventor scene [3] Open Inventor objects ","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/thirdparty/opencv/","title":"OpenCV","summary":"Open Source Computer Vision Library (OpenCV) Introduction OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library.\nThis chapter provides some examples how to use OpenCV in MeVisLab.\nOther resources You can find a lot of OpenCV examples and tutorials on their website.","content":"Open Source Computer Vision Library (OpenCV) Introduction OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library.\nThis chapter provides some examples how to use OpenCV in MeVisLab.\nOther resources You can find a lot of OpenCV examples and tutorials on their website.\n","tags":["Advanced","Tutorial","OpenCV","Python"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/thirdparty/example1/","title":"OpenCV Webcam access","summary":"ThirdParty Example 1: OpenCV Webcam access This Python file shows how to access the webcam via OpenCV and use the video via PythonImage module in MeVisLab.\nDownload You can download the Python files here","content":"ThirdParty Example 1: OpenCV Webcam access This Python file shows how to access the webcam via OpenCV and use the video via PythonImage module in MeVisLab.\nDownload You can download the Python files here\n","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/testing/example2/","title":"Profiling in MeVisLab","summary":"Testing Example 2: Profiling in MeVisLab This example shows how to use the Profiling View in MeVisLab.\nDownload n.a.","content":"Testing Example 2: Profiling in MeVisLab This example shows how to use the Profiling View in MeVisLab.\nDownload n.a.\n","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/surfaces/surfaceexample1/","title":"Surface Example 1: Creation of WEMs","summary":"Surface Example 1: Create Winged Edge Mesh out of voxel-images and CSOs Introduction In this example you will learn how to create a Winged Edge Mesh (WEM). There are several ways how to create WEMs, a few of them are shown in this example. Instead of creating WEMs, it is also possible to load existing WEMs. This was already shown in Surface Objects (WEM) chapter.\nSteps to do From image to surface: Generating WEMs out of voxel images At first, we will create a WEM out of a voxel image using the module WEMIsoSurface.","content":"Surface Example 1: Create Winged Edge Mesh out of voxel-images and CSOs Introduction In this example you will learn how to create a Winged Edge Mesh (WEM). There are several ways how to create WEMs, a few of them are shown in this example. Instead of creating WEMs, it is also possible to load existing WEMs. This was already shown in Surface Objects (WEM) chapter.\nSteps to do From image to surface: Generating WEMs out of voxel images At first, we will create a WEM out of a voxel image using the module WEMIsoSurface. Add and connect the shown modules. Load the image $(DemoDataPath)/Bone.tiff and set the Iso Min. Value in the panel of WEMIsoSurface to 1200. Tick the box Use image max. value. The module WEMIsoSurface creates surface objects out of all voxels with an Iso value equal or above 1200 (and smaller than the image max value). The module SoWEMRenderer can now be used to generate an Open Inventor scene, which can be displayed by the module SoExaminerViewer.\nWEM From surface to image: Generating voxel images out of WEM It is not only possible to create WEMs out of voxel images. You can also transform WEMs into voxel images: Add and connect the modules VoxelizeWEM and View2D as shown and press the Update button of the module VoxelizeWEM.\nWEM From Contour to Surface: Generating WEMs out of CSOs Now we like to create WEMs out of CSOs. To create CSOs load the network from Contour Example 2 and create some CSOs.\nNext, add and connect the module CSOToSurface to convert CSOs into a surface object. To visualize the created WEM, add and connect the modules SoWEMRenderer and SoExaminerViewer.\nWEM It is also possible to display the WEM in 2D in addition to the original image. In order to do that, add and connect the modules SoRenderSurfaceIntersection and SoView2DScene. The module SoRenderSurfaceIntersection allows to display the voxel image and the created WEM in one viewer using the same coordinates. In its panel, you can choose the color used for visualizing the WEM. The module SoView2DScene renders an Open Inventor scene graph into 2D slices.\nWEM If you like to transform WEMs back into CSOs, take a look at the module WEMClipPlaneToCSO.\nSummary Voxel images can be transformed into WEMs using WEMIsoSurface WEMs can be transformed into voxel images using VoxelizeWEM CSOs can be transformed into WEMS using CSOToSurface WEMs can be transformed into voxel images using WEMClipPlaneToCSO Warning:\u0026nbsp; Whenever converting voxel data to pixel data, keep the so called Partial Volume Effect in mind, see wikipedia for details. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","3D","Surfaces","Meshes","WEM"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/surfaces/surfaceexample2/","title":"Surface Example 2: Processing and Modification of WEM","summary":"Surface Example 2: Processing and Modification of WEM Introduction In this example, you will learn how to modify and process WEMs.\nSteps to do Develop your network Modification of WEMs Use the module WEMLoad to load the file venus.off. Then add and connect the shown modules. We like to display the WEM venus two times, one time this WEM is modified. You can use the module WEMModify to apply modifications. In its panel, change the scale and the size of the WEM.","content":"Surface Example 2: Processing and Modification of WEM Introduction In this example, you will learn how to modify and process WEMs.\nSteps to do Develop your network Modification of WEMs Use the module WEMLoad to load the file venus.off. Then add and connect the shown modules. We like to display the WEM venus two times, one time this WEM is modified. You can use the module WEMModify to apply modifications. In its panel, change the scale and the size of the WEM. Now you see two times the venus next to each other.\nWEMModify Smoothing of WEMs It is possible to smooth the WEM using the module WEMSmooth. Add this module to your network as shown. You can see the difference of the smoothed and the unsmoothed WEM in your viewer. There are more modules, which can modify WEMs, for example WEMExtrude. You can find them via search or in [ Modules \u0026rarr; Visualization \u0026rarr; Surface Meshes (WEM) ].\nWEMSmooth Calculate distance between WEMs Now, we like to calculate the distance between our two WEMs. In order to do this, add and connect the module WEMSurfaceDistance as shown.\nCalculate surface distance Annotations in 3D As a last step, we like to draw the calculated distances as annotations into the image. This is a little bit tricky as we need the module SoView2DAnnotation to create annotations in a 3D viewer. Add and connect the following modules as shown. What is done here? We use the module SoView2D to display a 2D image in the SoExaminerViewer, in addition to the WEMs we already see in the viewer. We do not see an additional image in the viewer, as we chose no proper input image to the module SoView2D using the module ConstantImage with value 0. Thus, we pretend to have a 2D image, which we can annotate. Now, we use the module SoView2DAnnotation to annotate the pretended-2D-image, displayed in the viewer of SoExaminerViewer. We already used the module SoView2DAnnotation in Contour Example 4.\nAnnotation modules Now, change the Annotation Mode to User, as we like to insert custom annotations. In addition, disable to Show vertical ruler.\nSelect annotation mode Next, open the tab Input and draw parameter connections from the results of the distance calculations, which can be found in the panel of WEMSufaceDistance, to the input fields in the panel of SoView2DAnnotation.\nDefine annotation parameters You can design the annotation overlay as you like in the tab User. We decided to only display the minimum and maximum distance between both WEMs.\nAnnotation design As we use a 2D annotation module to annotate a 3D viewer, it is important to get rid of all 2D orientation annotations, which you can edit in the tab Orientation.\nDisable 2D orientation annotations Now, you can see the result in the viewer. If the annotations are not visible, press a a few times to change the annotation mode. Display surface distance in viewer Summary There are several modules to modify and process WEMs, e.g. WEMModify, WEMSmooth. To calculate the minimal and maximal surface distance between two WEMs, use the module WEMSurfaceDistance. To create annotations in 3D, the module SoView2DAnnotation can be used, when adapted to be used in combination with a 3D viewer. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","3D","Surfaces","Meshes","WEM"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/surfaces/surfaceexample3/","title":"Surface Example 3: Interactions with WEM","summary":"Surface Example 3: Interactions with WEM Introduction In this example, we like to create networks, which enable interactive manipulations of WEMs inside a viewer. We will build a network to draw on WEMs and use this network to enable to cut WEMs.\nSteps to do Interactively drawing on WEMs Interactively cutting WEMs Summary ","content":"Surface Example 3: Interactions with WEM Introduction In this example, we like to create networks, which enable interactive manipulations of WEMs inside a viewer. We will build a network to draw on WEMs and use this network to enable to cut WEMs.\nSteps to do Interactively drawing on WEMs Interactively cutting WEMs Summary ","tags":["Beginner","Tutorial","Data Objects","3D","Surfaces","Meshes","WEM"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/surfaces/surfaceexample4/","title":"Surface Example 4: Interactively moving WEM","summary":"Surface Example 4: Interactively moving WEM Introduction In this example, we like to interactively move WEMs using SoDragger modules insight a viewer.\nDevelop your network Interactively translating objects in 3D using SoDragger modules Add and connect the following modules as shown. In the panel of the module WEMInitialize select the Model Octasphere. After that, open the viewer SoExaminerViewer and make sure to select the Interaction Mode. Now, you are able to click on the presented Octaspehere and move it alongside one axis.","content":"Surface Example 4: Interactively moving WEM Introduction In this example, we like to interactively move WEMs using SoDragger modules insight a viewer.\nDevelop your network Interactively translating objects in 3D using SoDragger modules Add and connect the following modules as shown. In the panel of the module WEMInitialize select the Model Octasphere. After that, open the viewer SoExaminerViewer and make sure to select the Interaction Mode. Now, you are able to click on the presented Octaspehere and move it alongside one axis. The following modules are involved in the interactions:\nSoMITranslate1Dragger: This module allows interactive translation of the object alongside one axis. You can select the axis for translation in the panel of the module. SoMIDraggerContainer: This module is responsible for actually changing the translation values of the object. Interactive dragging of objects Interactively translating a WEM alongside three axis We like to be able to interactively move a WEM alongside all three axis. In MeVisLab exists the module SoMITranslate2Dragger which allows translations alongside two axis, but there is no module which allows object translation in all three directions. Therefore, we will create a network, which solves this task. The next steps will show you, how you create three planes intersecting the objects. Dragging one plane, will drag the object alongside one axis. In addition, these planes will only be visible when hovering over them.\nCreation of planes intersecting an object We start creating a plane, which will allow dragging in x direction. In order to do that, modify your network as shown: Add the modules WEMModify, and SoBackground and connect the module SoCube to the dragger modules. You can select the translation direction in the panel of SoMITranslate1Dragger.\nInteractive dragging of objects We will modify the cube to be able to use it as a dragger plane. In order to do this, open the panel of SoCube and reduce the Width to be 0. This sets a plane in Y and Z direction.\nInteractive dragging of objects We like to move the object, when dragging the plane. Thus, we need to modify the translation of our object, when moving the plane. Open the panels of the modules WEMModify and SoMIDraggerContainer and draw a parameter connection from one Translation vector to the other.\nInteractive dragging of objects As a next step, we like to adapt the size of the plane, to the size of the object we have. Add the modules WEMInfo and DecomposeVector3 to your workspace and open their panels. The module WEMInfo presents information about the given WEM, for example its position and size. The module DecomposeVector3 splits a 3D vector into its components. Now, draw a parameter connection from Size of WEMInfo to the vector in DecomposeVector3. As a next step, open the panel of SoCube and draw parameter connections from the fields Y and Z of DecomposeVector3 to Height and Depth of SoCube. Now, the size of the plane adapts to the size of the object.\nInteractive dragging of objects The result can be seen in the next image. You can now select the plane in the Interaction Mode of the module SoExaminerViewer and move the plane together with the object alongside the x-axis.\nInteractive dragging of objects Modifying the appearance of the plane For changing the visualization of the dragger plane add the modules SoGroup, SoSwitch and SoMaterial to your network and connect them as shown. In addition, group together all the modules, which are responsible for the translation in X direction.\nInteractive dragging of objects We like to switch the visualization of the plane, in dependence of the mouse position in the viewer. In other words, when hovering over the plane, the plane should be visible, when the mouse is in another position and the possibility to drag the object is not given, the plane should be invisible. We use the module SoMaterial to edit the appearance of the plane. Open the panel of the module SoMITranslate1Dragger. The box of the field Highlighted is ticked, when the mouse hovers over the plane. Thus, we can use the field\u0026rsquo;s status to switch between different presentations of the plane. In order to do this, open the panel of SoSwitch and draw a parameter connection from Highlighted of SoMITranslate1Dragger to Which Child of SoSwitch.\nInteractive dragging of objects Open the panels of the modules SoMaterial. Change the Transparency of the first SoMaterial module to make the plane invisible, when not hovering over the plane. Furthermore, we changed the Diffuse Color of the module SoMaterial1 to red, so that the plane appears in red, when hovering over it.\nInteractive dragging of objects When hovering over the plane, the plane becomes visible and the option to move the object alongside the x-axis is given. When you do not hover over the plane, the plane is invisible.\nInteractive dragging of objects Interactive object translation in three dimensions We do not only want to move the object in one direction, we like to be able to do interactive object translations in all three dimensions. For this, copy the modules responsible for the translation in one direction and change the properties to enable translations in other directions.\nWe need to change the size of SoCube1 and SoCube2 to form planes, which cover surfaces in X and Z as well as X and Y directions. To do that, draw the respective parameter connections from DecomposeVector3 to the fields of the modules SoCube. In addition, we need to adapt the field Direction in the panels of the modules SoMITranslate1Dragger.\nInteractive dragging of objects As a next step, we like to make sure, that all planes always intersect the object, even though the object is moved. To to this, we need to synchronize the field Translation of all SoMIDraggerContainer modules and the module WEMModify. Draw parameter connections from one Translation field to the next, as shown below.\nInteractive dragging of objects We like to close the loop, so that a change in one field Translation causes a change in all the other Translation fields. To do this, we need to include the module SyncVector. The module SyncVector avoids an infinite processing loop causing a permanent update of all fields Translation.\nAdd the module SyncVector to your workspace and open its panel. Draw a parameter connection from the field Translation of the module SoMIDraggerContainer2 to Vector1 of SyncVector. The field Vector1 is automatically synchronized to the field Vector2. Now, connect the field Vector2 to the field Translate of the module WEMModify. Your synchronization network is now established.\nInteractive dragging of objects To enable transformations in all directions, we need to connect the modules SoMIDraggerContainer to the viewer. First, connect the modules to SoGroup, after that connect SoGroup to SoExaminerViewr.\nInteractive dragging of objects As a next step, we like to enlarge the planes, to make them exceed the object. For that, add the module CalculateVectorFromVectors to your network. Open its panel and connect the field Size of WEMInfo to Vector 1. We like to enlarge the size by one, so we add the vector (1,1,1), by editing the field Vector 2. Now, connect the Result to the field V of the module DecomposeVector3.\nInteractive dragging of objects At last, we can condense all the modules enabling the transformation into one local macro module. For that, group all the modules together and convert the group into a macro module as shown in Chapter I: Basic Mechanisms.\nInteractive dragging of objects The result can be seen in the next image. This module can now be used for interactive 3D transformations for all kind of WEMs.\nInteractive dragging of objects Summary A family of SoDragger modules is available, which can be used to interactively modify Open Inventor objects. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Data Objects","3D","Surfaces","Meshes","WEM"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/surfaces/surfaceexample5/","title":"Surface Example 5: WEM - Primitive Value Lists","summary":"Surface Example 5: WEM - Primitive Value Lists Introduction WEMs do not only contain the coordinates of nodes and surfaces, they can also contain additional information. These information are stored in so called Primitive Value Lists (PVLs). Every node, every surface and every edge can contains such a list. In these lists, you can for example store the color of the node or specific patient information. These information can be used for visualization or for further statistical analysis.","content":"Surface Example 5: WEM - Primitive Value Lists Introduction WEMs do not only contain the coordinates of nodes and surfaces, they can also contain additional information. These information are stored in so called Primitive Value Lists (PVLs). Every node, every surface and every edge can contains such a list. In these lists, you can for example store the color of the node or specific patient information. These information can be used for visualization or for further statistical analysis.\nIn this example, we like to use PVLs to color-code and visualize the distance between two WEMs.\nSteps to do Develop your network We start our network by initializing two WEMs using WEMInitialize. We chose an Octasphere and a resized Cube. Use the modules SoWEMRenderer, SoExaminerViewer and SoBackground to visualize the WEMs.\nWEMInitialize Subdividing WEM edges As a next step, add and connect two modules WEMSubdivide to further divide edges and surfaces. With this step we increase the node density to have an accurate distance measurement.\nWEMSubdivide The difference when selecting different maximum edge lengths can be seen in the following images.\nEdgeLength1 EdgeLength01 Distances between WEMs are stored in PVLs Now, add the modules WEMSurfaceDistance and WEMInfo to your workspace and connect them as shown. WEMSurfaceDistance calculates the minimum distance between the nodes of both WEM. The distances are stored in the nodes\u0026rsquo; PVLs as LUT values.\nDistances between surfaces Open the panels of the modules WEMSurfaceDistance and WEMInfo. In the panel of WEMInfo select the tab Statistics. You can see, the statistics of the stored PVLs. The Minimum Value and the Maximum Value are similar to the calculated Min Dist. and Max. Dist. of WEMSurfaceDistance.\nWEM information Color-coding the distance between WEMs What can we do with these information? We can use the calculated distances, stored in LUT values, to color-code the distance between the WEMs. For this, add and connect the module SoLUTEditor. Each LUT value from the PVLs will in the next step be translated into a color. But first, open the panel of SoWEMRenderer to select the Color Mode LUT Values. Now, the module SoLUTEditor defines the coloring of the WEM.\nSoWEMRenderer To translate the LUT values from the PVLs into color, open the panel of SoLUTEditor and select the tab Range. We need to define the value range, we like to work with. As the distance and thus the PVL-value is expected to be 0 when the surfaces of both WEMs meet, we set the New Range Min to 0. As the size of the WEMs does not exceed 3, we set the New Range Max to 3. After that, press Apply new Range.\nSoLUTEditor Our goal is to colorize faces of the Octasphere in red, if they are close to or even intersect the cubic WEM. And we like to colorize faces of the Octasphere in green, if these faces are far away from the cubic WEM.\nOpen the tab Editor of the panel of SoLUTEditor. This tab allows to interactively select a color for each PVL-value. Select the color point on the left side. Its Position value is supposed to be 0, so we like to select the Color red in order to color-code small distances between the WEMs in red. In addition to that, increase the Opacity of this color point. Next, select the right color point. Its Position is supposed to be 3 and thus equals the value of the field New Range Max. As these color points colorize large distances between WEMs, select the Color green. You can add new color points by clicking on the colorized bar in the panel. Select for example the Color yellow for a color point in the middle. Select and shift the color points to get the desired visualization.\nChanging the LUT Add the module WEMModify to your workspace and connect the module as shown. If you now shift the WEM using WEMModify, you can see that the colorization adapts.\nWEMModify Interactive shift of WEMs As a next step, we like to implement the interactive shift of the WEM. Add the modules SoTranslateDragger1 and SyncVector. Connect all translation vectors: Draw connections from the field Translate of SoTranslateDragger1 to Vector1 of SyncVector, from Vector2 of SyncVector to Translate of WEMModify, and at last from Translate of WEMModify to Translate of SoTranslateDragger1.\nYou can now interactively drag the WEM insight the viewer.\nDragging the WEM At last, exchange the module WEMInitialize with WEMLoad and load venus.off. You can decrease the Face Alpha in the panel of SoWEMRenderer1 to make that WEM transparent.\nWEM transparency The result can be seen in the next image.\nYour final result Summary Additional information of WEMs can be stored in Primitive Value Lists (PVL), attached to nodes, edges or faces. The module WEMSurfaceDistance stores the minimum distance between nodes of different WEMs in PVLs, as LUT values. PVLs containing LUT values can be used to color-code additional information on the WEM surface. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Advanced","Tutorial","Data Objects","3D","Surfaces","Meshes","WEM","PVM","Primitive Value Lists","LUT"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/tutorials/dataobjects/surfaceobjects/","title":"Surface Objects (WEM)","summary":"Surface Objects (WEMs) Introduction In MeVisLab it is possible to create, visualize, process and manipulate surface objects, also known as polygon meshes. Here, we call surface objects Winged Edge Mesh, in short WEM. In this chapter you will get an introduction into WEMs. In addition, you will find examples on how to work with WEMs. For more information on WEMs take a look at the MeVislab Toolbox Reference . If you like to know which WEM formats can be imported into MeVisLab, take a look at the assimp documentation here.","content":"Surface Objects (WEMs) Introduction In MeVisLab it is possible to create, visualize, process and manipulate surface objects, also known as polygon meshes. Here, we call surface objects Winged Edge Mesh, in short WEM. In this chapter you will get an introduction into WEMs. In addition, you will find examples on how to work with WEMs. For more information on WEMs take a look at the MeVislab Toolbox Reference . If you like to know which WEM formats can be imported into MeVisLab, take a look at the assimp documentation here.\nWEM explained with MeVisLab To explain WEMs in MeVisLab we will build a network, which shows the structure and the characteristics of WEMs. We will start the example by generating a WEM forming a cube. With this, we will explain structures of WEMs called Edges, Nodes, Surfaces, and Normals.\nInitialize a WEM Add the module WEMInitialize to your workspace, open its panel and select a Cube. In general, a WEM is made up of surfaces. Here all surfaces are squares. In MeVisLab it is common to build WEMs out of triangles.\nWEM initializing Rendering of WEMs For rendering WEMs, you can use the module SoWEMRenderer in combination with the viewer SoExaminerViewer. Add both modules to your network and connect them as shown. A background is always a nice feature to have. WEM rendering Geometry of WEMs The geometry of WEMs is given by different structures. Using specialized WEM-Renderer modules, all structures can be visualized.\nEdges Add and connect the module SoWEMRendererEdges to your workspace to enable the rendering of WEM Edges. Here, we manipulated the line thickness, to make the lines of the edges thicker. WEM Edges Nodes Nodes mark the corner points of each surface. Therefore, nodes define the geometric properties of every WEM. To visualize the nodes, add and connect the module SoWEMRendererNodes as shown. Per default, the nodes are visualized with an offset to the position they are located in. We reduced the offset to be zero, increased the point size and changed the color. WEM Nodes Faces Between the nodes and alongside the edges surfaces are created. The rendering of these surfaces can be enabled and disabled using the panel of SoWEMRenderer. WEM Faces Normals Normals display the orthogonal vector either to the faces (Face Normals) or to the nodes (Nodes Normals). With the help of the module SoWEMRendererNormals these structures can be visualized.\nWEM normal editor WEMNodeNormals WEMFaceNormals WEMs in MeVisLab In MeVisLab WEMs can consist of triangles, squares or other polygons. Most common in MeVisLab are surfaces composed of triangles, as shown in the following example. With the help of the module WEMLoad existing WEMs can be loaded into the network.\nWEMTriangles WEMNetwork WEMSurface Summary WEMs are polygon meshes, in most cases composed of triangles WEM\u0026rsquo;s geometry is determined by nodes, edges, faces and normals, which can be visualized using renderer modules ","tags":["Beginner","Tutorial","Data Objects","3D","Surfaces","Meshes","WEM"],"section":"tutorials"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/testing/","title":"Testing Examples","summary":"Testing Examples: The following examples are available:\n[1] Iterative tests in MeVisLab with Screenshots [2] Profiling in MeVisLab [3] Writing a simple test case in MeVisLab ","content":"Testing Examples: The following examples are available:\n[1] Iterative tests in MeVisLab with Screenshots [2] Profiling in MeVisLab [3] Writing a simple test case in MeVisLab ","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/thirdparty/","title":"ThirdParty Examples","summary":"ThirdParty Examples: The following examples are available:\n[1] Face detection in OpenCV [2] OpenCV Webcam access ","content":"ThirdParty Examples: The following examples are available:\n[1] Face detection in OpenCV [2] OpenCV Webcam access ","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/visualization/example1/","title":"Visualization Example 1: Synchronous view of two images","summary":"Visualization Example 1: Synchronous view of two images This very simple example shows how to load an image and apply a basic Convolution filter to the image. The image with and without filter is shown in a Viewer and scrolling is synchronized so that the same slice is shown for both images.\nDownload You can download the example network here","content":"Visualization Example 1: Synchronous view of two images This very simple example shows how to load an image and apply a basic Convolution filter to the image. The image with and without filter is shown in a Viewer and scrolling is synchronized so that the same slice is shown for both images.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/visualization/","title":"Visualization Examples","summary":"Visualization Examples: The following examples are available:\n[1] Display images converted to Open Inventor scene objects [2] Image overlays [3] Volume rendering and interactions ","content":"Visualization Examples: The following examples are available:\n[1] Display images converted to Open Inventor scene objects [2] Image overlays [3] Volume rendering and interactions ","tags":[],"section":"examples"},{"date":"1655276193","url":"https://mevislab.github.io/examples/examples/testing/example1/","title":"Writing a simple test case in MeVisLab","summary":"Testing Example 1: Writing a simple test case in MeVisLab This example shows how to write and execute test cases in MeVisLab. The Python files can be downloaded below.\nDownload You can download the Python files here","content":"Testing Example 1: Writing a simple test case in MeVisLab This example shows how to write and execute test cases in MeVisLab. The Python files can be downloaded below.\nDownload You can download the Python files here\n","tags":[],"section":"examples"},{"date":"1655276093","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/","title":"Chapter I: Basic Mechanisms of MeVisLab","summary":"MeVisLab Tutorial Chapter I \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Basic Mechanics of MeVisLab (Example: Building a Contour Filter) In this chapter you will learn the basic mechanics of the MeVisLab IDE. You will learn how to re-use existing Modules to load and view data, and you will build your first processing pipeline.\nExtra Infos:\u0026nbsp; Additional information about the basics of MeVisLab are explained here Loading Data First, we need to load the data we like to work on.","content":"MeVisLab Tutorial Chapter I \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Basic Mechanics of MeVisLab (Example: Building a Contour Filter) In this chapter you will learn the basic mechanics of the MeVisLab IDE. You will learn how to re-use existing Modules to load and view data, and you will build your first processing pipeline.\nExtra Infos:\u0026nbsp; Additional information about the basics of MeVisLab are explained here Loading Data First, we need to load the data we like to work on. In MeVisLab, you usually use modules to perform specific tasks. Modules are the basic entities you will be working with. Each module has a specific functionality for processing, visualization and interaction. Connecting these modules enables the development of complex processing pipelines. You will get to know different types of modules throughout the course of this tutorial.\nBy now, we will load our data by using the module ImageLoad. You can find this module via search and add it to your Workspace.\nSearch for ImageLoad As a next step, we like to select and load the data we like to process. Double-click the Module ImageLoad to open its Panel. Now, you can browse through your folders to select the data you like to open. You can find example data in the MeVisLab DemoData directory $(InstallDir)/Packages/MeVisLab/Resources/DemoData located in the MeVisLab installation path. Select a file, for example an MRI scan of a shoulder Shoulder_Fracture.tif. The image is loaded immediately and basic information of the loaded image can be seen in the Panel.\nExtra Infos:\u0026nbsp; Multiple additional Modules for loading data are available such as:\nDicomImport for loading DICOM Images LocalImage for loading any image format For details about loading DICOM images, see here\nThe Output-Inspector and the Module Inspector For a first inspection and visualization of the loaded data, we can use the Output Inspector located in the Views area. You can already interact with the image via Mouse-Wheel and Mouse Buttons / . To preview the image, click on the triangle on the top side of the module ImageLoad, which offers the module output. All module outputs can be found at the top side of the respective module.\nYou can now inspect your image in 2D.\nOutput Inspector Your image does not look like this? One reason might be that the slice of the image you are looking at has no information. Click on the Output Inspector and scroll through the slices (slicing) by using the mouse wheel . Still not seeing anything? Then try to adjust the contrast of the given image by keeping the right mouse button pressed while moving the mouse.\nYou are not restricted to only see your image in 2D. The Output Inspector offers a 3D View of the selected data. For this, click on the tab 3D of the Output Inspector. The 3D view of the image can be rotated by left-clicking on the image and moving the courser around. The little cube in the lower right corner of the viewer shows the orientation of the image.\nNotation:\u0026nbsp; A = anterior, front P = posterior, back R = right side L = left side H = head F = feet Below the Output Inspector, you can find the Module Inspector. The Module Inspector displays properties and parameters of the selected module. Parameters are stored in so called Fields. Using the Module Inspector you can examine different fields of the module ImageLoad. The module has for example the fields filename (the path, the loaded image is stored in) and sizeX, sizeY, sizeZ (the size of the loaded image).\nModule Inspector Viewer Instead of using the Output Inspector to inspect images, it is sensible to add a viewer to the network. Search for the module View2D and add it to your workspace. Most modules have different connectors. Data were transmitted via output connectors on the top side of a module and can be received by other modules via input connectors on the bottom side of the module.\nThe module View2D has one input connector for the voxel-images on the bottom side (triangle) and three other possible inputs (half-circles), which will be explained later on. In general, module outputs can be connected to module inputs with the same symbol and thus transmit information and data between modules.\n2D Viewer You can now add the loaded image to the viewer by connecting the image output of the module ImageLoad with the image input of the module View2D. This is done as follows:\nClick the output connector of ImageLoad.\nKeep the left mouse button pressed while dragging the connection to the input connector of View2D (white line).\nCheck that the connection is well-defined (green line).\nAt the input connector of View2D, release the mouse button and establish the connection (blue line).\nEstablish connection Although the connection is established, no image rendering has started yet. To initialize rendering, open the View2D panel by double-clicking the module View2D in your network. Similar to the Output Inspector, you can scroll through the slices and change the contrast. By pressing the A you can switch the annotation mode.\nView2D Panel You can also disconnect the Modules by dragging the connection away from the input or output connector of the Modules.\nConnections between compatible outputs and inputs are established automatically in case 2 Modules are moved close enough to each other.\nExtra Infos:\u0026nbsp; Connecting, Disconnecting, Moving and Replacing Connections is explained here Image Processing Next, we like to add a processing step to our network. We like to smooth the image using an average kernel. In order to do that, search for the module Convolution and add it to the workspace. Delete the established connection from the module ImageLoad to the module View2D by clicking on the connection and pressing DEL . Now, you can build new connections from the module ImageLoad to the module Convolution and from this module to View2D.\nConvolution Module Double-click the module Convolution to open its panel. The panel allows configurations of the module. You can adjust parameters or in this case select a kernel, for example the 3x3 Avarage Kernel.\nSelect a Kernel The module View2D is now displaying the smoothed image.\nTo see the difference between the processed and the unprocessed image, click on the output of the module ImageLoad to view the original image in the Output Inspector. The great thing about the Output Inspector is that it can display the output of any connector in the process chain (as long as a format is used, the inspector can interpret). Simply click the connector or connection to find out more about the module output.\nThere is another way of inspecting the difference between the processed and the unprocessed image. Add a second viewer module View2D to your workspace. The new module gets a different name: View2D1. It is possible to establish numerous connections from one module output to different other module inputs, but a module input can only receive one connection. Connect the module ImageLoad to the second viewer to display two images at the same time. You can scroll through the slices of both viewers and inspect the images.\nMultiple Viewer Parameter Connection for Synchronization In our example you can scroll through the slices of both viewers independently. To inspect the effect of the filter, it would be helpful to synchronize both viewers in a way, that both show the same slices.\nWe already know data connections between module inputs and outputs. Besides module connections, it is also possible to connect module fields via a parameter connection. The values of connected fields are synchronized, that means when changing the value of one field, all fields connected to this field will be adapted to the same value.\nIn this chapter we like to establish parameter connections to allow the synchronized use of both image viewers. In order to do that, search for the module SyncFloat and add it to your workspace.\nSyncFloat Module We like to synchronize the field startSlice of both viewers, to be able to show the same slice in both viewers simultaneously.\nFirst, right-click the viewer View2D to open its context menu and select [ Show Window \u0026rarr; Automatic Panel ].\nAutomatic Panel View2D This option shows all parameter fields of the module View2D.\nSearch for the field startSlice. The field indicates which slice is currently shown in the Viewer. If you scroll through the slices of an image the value of startSlice changes.\nNow, double-click the module SyncFloat to open its panel.\nClick on the label startSlice in the automatic panel of the module View2D, keep the button pressed and drag the connection to the label Float1 in the panel of the module SyncFloat.\nSynchronize StartSlice The connection is drawn as a thin grey arrow between both modules with the arrowhead pointing to the module that receives the field value as input. The value of the field starSlice is now transmitted to the field Float1. Changing StartSlice automatically changes Float1, but not the other way round.\nParameter Connection StartSlice We now like to establish a connection from the module SyncFloat to the second viewer, Viewer2D1. In order to do that, open the automatic panel View2D1. Draw a connection from the label Float2 of the panel of the module SyncFloat to the label startSlice in the automatic panel of the module View2D1. At last, implement a connection between the parameter fields startSlice of both viewers. Draw the connection from View2D1 to View2D.\nSynchronize both directions As a result, scrolling through the slices with the mouse wheel in one of the viewers synchronizes the rendered slice in the second viewer. In this case, you can inspect the differences between smoothed and unsmoothed data on every single slice.\nYour final Network You can also use the pre-defined Module SynchroView2D to reach the same goal (shown in this chapter ).\nGrouping Modules In this chapter we like to create a contour filter. To finalize the filter, add the modules Arithmetic2 and Morphology to your workspace and connect the modules as shown below. Double-click the module Arithmetic2 to open its panel. Change the field Function of the module Arithmetic2 to use the function subtract in the panel of the module. With this, we finished our contour filter. You can inspect each processing step using the Output Inspector by clicking on the input and output connectors of the respective modules. The final results can be inspected using the viewers. If necessary, adjust the contrast by pressing the right-key and moving the cursor.\nGrouping Modules If you like to know more information about each module, search for help. You can do this by right-clicking the module and select help, which offers an example network and further information about this module.\nModule Help To distinguish the image processing pipeline, you can create a group for it. For that: Select the three modules, for example by dragging a selection rectangle around them. Right-click the selection to open the context menu and select [ Add to New Group ].\nAdd to new Group Enter a name for the new group, for example Filter. The new group is created and displayed as a green rectangle. The group allows for quick interactions with all its modules together.\nYour Filter Group Your network gets very complex and you lost track? No problem. Let MeVisLab arrange your modules automatically via [ Mein Menu \u0026rarr; Edit \u0026rarr; Auto Arrange Selection ] (or via keyboard shortcut CTRL + 1 ).\nNow, it is time to save your first network. Open the tab [ File \u0026rarr; Save ] to save the network in an .mlab file.\nExtra Infos:\u0026nbsp; More information on module groups can be found here Macro-Modules We now like to condense our filter into one single module. You have probably already noticed, that the modules have different colors. Each color represents a special type of modules. The blue modules are called ML-Modules and are responsible for the processing of voxel-images. The brown modules are called macro modules. Macro modules encapsulate a whole network in a single module. You can right-click on one macro-module to open the context menu and select Show Internal Network to see the internal network structure. In addition, macro modules enable the implementation of custom functionalities via python scripting.\nWe now like to condense the modules forming the contour filter into one single macro module. To do that, right-click on the group-title and select Convert To Local Macro. Now, you need to select a name for your macro module and finish the creation of the module. With this you create a local macro module. Local macro modules can only be used in your current network.\nConvert to Local Macro Your first Local Macro Right-click the macro module and select Show Internal Network to inspect and change the internal network. You can change the properties of the new macro module by changing the properties in the internal network. As before, you can for example right-click the module Convolution and change the Kernel. These changes will be preserved.\nInternal Network of your Local Macro \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;This example is also available on YouTube. Extra Infos:\u0026nbsp; Module handling is explained here\nMore information about Marco Modules can be found here\nSummary MeVisLab provides pre-defined Modules you can re-use and connect for building more or less complex networks. Each Module output can be previewed by using the Output Inspector. Each Module provides Example Networks to explain their usage. Parameters of each Module can be changed in the Module Inspector or Automatic Panel of the Module. Parameter connections can be established to synchronize the values of these parameters. Modules can be grouped. Grouped Modules can be encapsulated to Macro Modules. Macro Modules encapsulate networks. Internal networks can be shown and modified. Any changes of the internal network are applied to the Macro Module. \u0026nbsp;\u0026nbsp;\u0026nbsp;Download .mlab file here. ","tags":["Beginner","Tutorial","Macro","Macro Modules","Local Macro"],"section":"tutorials"},{"date":"1655276093","url":"https://mevislab.github.io/examples/tutorials/basicmechanisms/dataimport/","title":"Example 1: Data import in MeVisLab","summary":"Example 1: Data Import in MeVisLab MeVisLab provides several pre-defined modules to import data for processing in your networks.\nThis chapter explains the basic data formats and modules to use in your network:\nImages DICOM Data Segmentations / 2D Contours 3D Data / Meshes Extra Infos:\u0026nbsp; More detailed explanations for loading images in MeVisLab can be found here Images A very simple module for loading images is the ImageLoad module. ImageLoad Module The ImageLoad module can import the following formats:","content":"Example 1: Data Import in MeVisLab MeVisLab provides several pre-defined modules to import data for processing in your networks.\nThis chapter explains the basic data formats and modules to use in your network:\nImages DICOM Data Segmentations / 2D Contours 3D Data / Meshes Extra Infos:\u0026nbsp; More detailed explanations for loading images in MeVisLab can be found here Images A very simple module for loading images is the ImageLoad module. ImageLoad Module The ImageLoad module can import the following formats:\nDICOM TIFF DICOM/TIFF RAW LUMISYS PNM Analyze PNG JPEG MLImageFileFormat Basic information of the imported images are available on the Panel which opens via double-click.\nDICOM data Extra Infos:\u0026nbsp; Additional information about Digital Imaging and Communications in Medicine (DICOM) can be found at Wikipedia Even if the above explained ImageLoad is able to import DICOM data, a much better way is to use one of the specialized modules for DICOM images such as DicomImport.\nThe DicomImport module allows to define a directory containing DICOM files to import as well as a list of files which can be dropped to the UI and imported. After import, the volumes are shown in a patient tree providing the following patient, study, series and volume information (depending on the availability in the DICOM file(s)):\nPATIENT LEVEL Patient Name (0010,0010) - Patient Birthdate (0010,0030) STUDY LEVEL Study Date (0008,0020) - Study Description (0008,1030) SERIES/VOLUME LEVEL Modality (0008,0060) - Series Description (0008,103e) - Rows (0028,0010) - Columns (0028,0011) - number of slices in volume - number of time points in volume DicomImport Module Configuration The DicomImport module generates volumes based on the Dicom Processor Library (DPL) which allows to define sorting and partitioning options.\nDicomImport Sort Part Configuration DicomTree information In order to get all DICOM tags from your currently imported and selected volume, you can connect the DicomImport module to a DicomTagBrowser.\nDicomTagBrowser Module Segmentations / 2D Contours 2-dimensional contours in MeVisLab are handled via CSOs (Contour Segmentation Objects).\nExtra Infos:\u0026nbsp; Tutorials for CSOs are available here\nDetailed explanations about CSOs can be found here\nThe CSO library provides data structures and modules for an interactive or automatic generation of contours in voxel images. Furthermore, these contours can be analyzed, maintained, grouped, and converted into a voxel image or a set of markers.\nCSOs can be created by the existing SoCSO*Editor modules. The following modules are available:\nSoCSOPointEditor SoCSOAngleEditor SoCSOArrowEditor SoCSODistanceLineEditor SoCSODistancePolylineEditor SoCSOEllipseEditor SoCSORectangleEditor SoCSOIsoEditor SoCSOSplineEditor SoCSOPolygonEditor SoCSOLiveWireEditor For saving and loading existing CSOs, the modules CSOSave and CSOLoad can be used.\n3D data / meshes Winged Edge Mesh (WEM) 3-dimensional meshes in MeVisLab are handled via WEMs (Winged Edge Mesh).\nThe module WEMLoad loads different 3D mesh file formats like:\nObject File Format (*.off *.geom) Wavefront (*.obj) Polygon File Format (*.ply) Standard Tessellation Language (*.stl) VRML (*.wrl) Winged Edge Mesh (*.wem) WEMLoad Module WEMs can be rendered via Open Inventor by using the modules SoExaminerViewer or SoRenderArea and SoCameraInteraction.\nBefore visualizing a WEM, it needs to be converted to a Scene Object via SoWEMRenderer.\nSoWEMRenderer Module Extra Infos:\u0026nbsp; Tutorials for WEMs are available here. Loading arbitrary 3D files The SoSceneLoader module is able to load external 3D formats. MeVisLab uses the integrated assimp ThirdParty library which is able to import most common 3D file types. The currently integrated assimp version can be found here Extra Infos:\u0026nbsp; Supported file formats of the assimp library are documented on their website. SoSceneLoader Module The SoSceneLoader module generates a 3D scene from your loaded files which can be rendered via SoExaminerViewer or SoRenderArea and SoCameraInteraction Extra Infos:\u0026nbsp; Example usage is explained in the tutorials for Open Inventor. ","tags":["Beginner","Tutorial","Data Import","DICOM"],"section":"tutorials"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/contours/example3/","title":"2D and 3D visualization of contours","summary":"Contour Example 3: 2D and 3D visualization of contours This example shows how to display CSOs in 2D as an overlay. In addition, the CSOs are displayed in 3D.\nSummary Images are loaded by using a LocalImage module and visualized in a 2D viewer. A SoCSOLiveWireEditor is added to draw contours on the images. The CSOSliceInterpolator generates additional contours between the manual CSOs by using a linear interpolation.\nThe module VoxelizeCSO is used to create a 3-dimensional voxel mask of the contours which can be used as overlay on the images in a View2D.","content":"Contour Example 3: 2D and 3D visualization of contours This example shows how to display CSOs in 2D as an overlay. In addition, the CSOs are displayed in 3D.\nSummary Images are loaded by using a LocalImage module and visualized in a 2D viewer. A SoCSOLiveWireEditor is added to draw contours on the images. The CSOSliceInterpolator generates additional contours between the manual CSOs by using a linear interpolation.\nThe module VoxelizeCSO is used to create a 3-dimensional voxel mask of the contours which can be used as overlay on the images in a View2D. The SoView2DOverlay module defines the color and transparency of the overlay.\nIn the end, a View3D is used to visualize the voxel mask in 3D.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/contours/example4/","title":"Annotation of images","summary":"Contour Example 4: Annotation of images This example shows how to add annotations to an image.\nSummary In this example, the network of Contour Example 3 is extended so that the volume of the 3D mask generated by the VoxelizeCSO module is calculated. The CalculateVolume module counts the number of voxels in the given mask and returns the correct volume in ml. This volume is used for a custom SoView2DAnnotation displayed in the View2D.","content":"Contour Example 4: Annotation of images This example shows how to add annotations to an image.\nSummary In this example, the network of Contour Example 3 is extended so that the volume of the 3D mask generated by the VoxelizeCSO module is calculated. The CalculateVolume module counts the number of voxels in the given mask and returns the correct volume in ml. This volume is used for a custom SoView2DAnnotation displayed in the View2D.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/image_processing/example1/","title":"Arithmetic operations on two images","summary":"Image Processing Example 1: Arithmetic operations on two images In this example, we apply scalar functions on two images like Add, Multiply, Subtract, etc.\nSummary We are loading two images by using the LocalImage module and show them in a SynchroView2D. In addition to that, both images are used for arithmetic processing in the module Arithmetic2.\nDownload You can download the example network here","content":"Image Processing Example 1: Arithmetic operations on two images In this example, we apply scalar functions on two images like Add, Multiply, Subtract, etc.\nSummary We are loading two images by using the LocalImage module and show them in a SynchroView2D. In addition to that, both images are used for arithmetic processing in the module Arithmetic2.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/open_inventor/example4/","title":"Camera interaction with collision detection","summary":"Open Inventor Example 4: Camera interaction with collision detection This example shows how to implement a camera flight using keyboard shortcuts. Collisions with anatomical structures are detected and the flight stops. In addition to that, the camera object and direction is rendered in another viewer.\nThis example has been taken from the MeVisLab Forum.\nSummary A local macro flightControl allows you to navigate with the camera through the scene.\nDownload You can download the example network here","content":"Open Inventor Example 4: Camera interaction with collision detection This example shows how to implement a camera flight using keyboard shortcuts. Collisions with anatomical structures are detected and the flight stops. In addition to that, the camera object and direction is rendered in another viewer.\nThis example has been taken from the MeVisLab Forum.\nSummary A local macro flightControl allows you to navigate with the camera through the scene.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/image_processing/example5/","title":"Clip Planes","summary":"Image Processing Example 5: Clip Planes In this example, we are using the currently visible slice from a 2D view as a clip plane in 3D.\nSummary We are loading images by using the LocalImage module and render them as a 2-dimensional image stack SoRenderArea. The displayed slice is used to create a 3D plane/clip plane in a SoExaminerViewer.\nDownload You can download the example network here","content":"Image Processing Example 5: Clip Planes In this example, we are using the currently visible slice from a 2D view as a clip plane in 3D.\nSummary We are loading images by using the LocalImage module and render them as a 2-dimensional image stack SoRenderArea. The displayed slice is used to create a 3D plane/clip plane in a SoExaminerViewer.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/basic_mechanisms/contour_filter/","title":"Contour Filter","summary":"Example 1: Contour Filter This example shows how to create a contour filter.\nSummary Images are loaded via ImageLoad module and visualized unchanged in a View2D module View2D1. Additionally the images are modified by a local macro module Filter and shown in another View2D viewer View2D.\nIn order to display the same slice (unchanged and changed), the module SyncFloat is used to synchronize the field value startSlice in both viewers. The SyncFloat module duplicates the value Float1 to the field Float2.","content":"Example 1: Contour Filter This example shows how to create a contour filter.\nSummary Images are loaded via ImageLoad module and visualized unchanged in a View2D module View2D1. Additionally the images are modified by a local macro module Filter and shown in another View2D viewer View2D.\nIn order to display the same slice (unchanged and changed), the module SyncFloat is used to synchronize the field value startSlice in both viewers. The SyncFloat module duplicates the value Float1 to the field Float2.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/contours/example2/","title":"Contour interpolation","summary":"Contour Example 2: Contour interpolation This example shows how to interpolate CSOs over slices.\nSummary In this example, semi-automatic countours are created by using a SoCSOLiveWireEditor. The created contours are managed by a CSOManager. Visualization of the contours is customized by using a SoCSOVisualizationSettings module.\nIn the end, additional contours between the manual contours are generated by the CSOSliceInterpolator and added to the CSOManager. Different groups of contours are created for left and right lung lobe and colored separately.","content":"Contour Example 2: Contour interpolation This example shows how to interpolate CSOs over slices.\nSummary In this example, semi-automatic countours are created by using a SoCSOLiveWireEditor. The created contours are managed by a CSOManager. Visualization of the contours is customized by using a SoCSOVisualizationSettings module.\nIn the end, additional contours between the manual contours are generated by the CSOSliceInterpolator and added to the CSOManager. Different groups of contours are created for left and right lung lobe and colored separately.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/contours/example5/","title":"Contours and ghosting","summary":"Contour Example 5: Contours and ghosting This image shows how to automatically create CSOs based on an iso value. In addition the visualization of CSOs of previous and subsequent slices is shown.\nSummary In this example, the CSOIsoGenerator is used to generate contours based on a given iso value of the image. Contours are generated in the image where the given iso value is close to the one configured. These contours are stored in a CSOManager and ghosting is activated in the SoCSOVisualizationSettings.","content":"Contour Example 5: Contours and ghosting This image shows how to automatically create CSOs based on an iso value. In addition the visualization of CSOs of previous and subsequent slices is shown.\nSummary In this example, the CSOIsoGenerator is used to generate contours based on a given iso value of the image. Contours are generated in the image where the given iso value is close to the one configured. These contours are stored in a CSOManager and ghosting is activated in the SoCSOVisualizationSettings.\nGhosting means not only showing contours available on the currently visible slice but also contours of the neighbouring slices with increasing transparency.\nThe contours are also displayed in a 3-dimensionsl SoExaminerViewer by using a SoCSO3DRenderer.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/basic_mechanisms/viewer_application/","title":"Creating a simple application","summary":"Example 3: Creating a simple application In this example, you will learn how to create a simple Prototype application in MeVisLab including a User Interface with 2D and 3D viewer. Download You can download the example network here","content":"Example 3: Creating a simple application In this example, you will learn how to create a simple Prototype application in MeVisLab including a User Interface with 2D and 3D viewer. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/contours/example1/","title":"Creation of Contours","summary":"Contour Example 1: Creation of Contours This example shows how to create CSOs using SoCSOEditor modules.\nSummary Contours (in MeVisLab CSO\u0026rsquo;s) can be created by many modules, such as:\nSoCSOPointEditor SoCSOAngleEditor SoCSOArrowEditor SoCSODistanceLineEditor SoCSODistancePolylineEditor SoCSOEllipseEditor SoCSORectangleEditor SoCSOSplineEditor SoCSOPolygonEditor SoCSOIsoEditor SoCSOLiveWireEditor Whenever creating contours, they are managed and temporarily stored by a CSOManager. In this example, contours are created and colors and styles of these CSOs are customized by using a SoCSOVisualizationSettings module.","content":"Contour Example 1: Creation of Contours This example shows how to create CSOs using SoCSOEditor modules.\nSummary Contours (in MeVisLab CSO\u0026rsquo;s) can be created by many modules, such as:\nSoCSOPointEditor SoCSOAngleEditor SoCSOArrowEditor SoCSODistanceLineEditor SoCSODistancePolylineEditor SoCSOEllipseEditor SoCSORectangleEditor SoCSOSplineEditor SoCSOPolygonEditor SoCSOIsoEditor SoCSOLiveWireEditor Whenever creating contours, they are managed and temporarily stored by a CSOManager. In this example, contours are created and colors and styles of these CSOs are customized by using a SoCSOVisualizationSettings module.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/surface_objects/example1/","title":"Creation of WEMs","summary":"Surface Example 1: Creation of WEMs This example shows how to create WEMs out of voxel images and CSOs. Download You can download the example network here","content":"Surface Example 1: Creation of WEMs This example shows how to create WEMs out of voxel images and CSOs. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/visualization/example4/","title":"Display images converted to Open Inventor scene objects","summary":"Visualization Example 4: Display images converted to Open Inventor scene objects This example shows how to convert images to Open Inventor scene objects using the module SoView2D and modules based on SoView2D. Download You can download the example network here","content":"Visualization Example 4: Display images converted to Open Inventor scene objects This example shows how to convert images to Open Inventor scene objects using the module SoView2D and modules based on SoView2D. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/markers/example1/","title":"Distance between markers","summary":"Marker Example 1: Distance between markers This examples shows how to create markers in a viewer and measure their distance. Download You can download the example network here","content":"Marker Example 1: Distance between markers This examples shows how to create markers in a viewer and measure their distance. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/curves/example1/","title":"Drawing curves","summary":"Marker Example 1: Distance between markers This examples shows how to create and render curves. Download You can download the example network here","content":"Marker Example 1: Distance between markers This examples shows how to create and render curves. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/visualization/example3/","title":"Image overlays","summary":"Visualization Example 3: Image overlays This example shows the creation of an overlay. Using the module SoView2DOverlay, an overlay can be blended over a 2D image. Download You can download the example network here","content":"Visualization Example 3: Image overlays This example shows the creation of an overlay. Using the module SoView2DOverlay, an overlay can be blended over a 2D image. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/surface_objects/example4/","title":"Interactively moving WEM","summary":"Surface Example 4: Interactively moving WEM This example shows how to use dragger modules, to modify objects in a 3D viewer. Download You can download the example network here","content":"Surface Example 4: Interactively moving WEM This example shows how to use dragger modules, to modify objects in a 3D viewer. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/image_processing/example2/","title":"Masking images","summary":"Image Processing Example 2: Masking images In this example, we create a simple mask on an image, so that background pixels are not affected by changes of the window/level values.\nSummary We are loading images by using the LocalImage module and show them in a SynchroView2D. The same image is shown in the right viewer of the SynchroView2D but with a Threshold based Mask.\nDownload You can download the example network here","content":"Image Processing Example 2: Masking images In this example, we create a simple mask on an image, so that background pixels are not affected by changes of the window/level values.\nSummary We are loading images by using the LocalImage module and show them in a SynchroView2D. The same image is shown in the right viewer of the SynchroView2D but with a Threshold based Mask.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/open_inventor/example2/","title":"Mouse interactions in an Open Inventor scene","summary":"Open Inventor Example 2: Mouse interactions in an Open Inventor scene This example shows how to implement object interactions.\nSummary A SoExaminerViewer is used to render a SoCube object. The SoMouseGrabber is used to identify mouse interactions in the viewer and to resize the cube.\nDownload You can download the example network here","content":"Open Inventor Example 2: Mouse interactions in an Open Inventor scene This example shows how to implement object interactions.\nSummary A SoExaminerViewer is used to render a SoCube object. The SoMouseGrabber is used to identify mouse interactions in the viewer and to resize the cube.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/open_inventor/example1/","title":"Open Inventor objects","summary":"Open Inventor Example 1: Open Inventor objects In this example a simple Open Inventor scene is created. The Open Inventor scene shows three objects of different color and shape.\nSummary A SoExaminerViewer is used to render open inventor scenes in 3D. The SoBackground module defines the background of the whole scene.\nThree 3D objects are created (SoCone, SoSphere and SoCube) having a defined SoMaterial module for setting the DiffuseColor of the object.","content":"Open Inventor Example 1: Open Inventor objects In this example a simple Open Inventor scene is created. The Open Inventor scene shows three objects of different color and shape.\nSummary A SoExaminerViewer is used to render open inventor scenes in 3D. The SoBackground module defines the background of the whole scene.\nThree 3D objects are created (SoCone, SoSphere and SoCube) having a defined SoMaterial module for setting the DiffuseColor of the object. The cube and the cone are also transformed by a SoTransform module so that they are located next to the centered sphere.\nIn the end, all three objects including their materials and transformations are added to the SoExaminerViewer by a SoGroup.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/basic_mechanisms/macro_modules_and_module_interaction/example1/","title":"Panel for the contour filter","summary":"Example 1: Panel for the contour filter This example contains a whole package structure. Inside you can find the example contour filter for which a panel was created.\nSummary A new Macro Module Filter has been created. Initially Macro Modules do not provide an own Panel containing user interface elements such as Buttons. The Automatic Panel is shown on double-clicking the module providing the name of the module.\nIn this example we update the *.","content":"Example 1: Panel for the contour filter This example contains a whole package structure. Inside you can find the example contour filter for which a panel was created.\nSummary A new Macro Module Filter has been created. Initially Macro Modules do not provide an own Panel containing user interface elements such as Buttons. The Automatic Panel is shown on double-clicking the module providing the name of the module.\nIn this example we update the *.script file of the module Filter and add the kernel selection field from the internal networks Convolution module to our own module UI. Changes of the kernel are automatically applied to our internal network.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/surface_objects/example2/","title":"Processing and modification of WEMs","summary":"Surface Example 2: Processing and modification of WEMs This example shows how to process and modify WEMs using the modules WEMModify, WEMSmooth and WEMSurfaceDistance. Download You can download the example network here","content":"Surface Example 2: Processing and modification of WEMs This example shows how to process and modify WEMs using the modules WEMModify, WEMSmooth and WEMSurfaceDistance. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/basic_mechanisms/macro_modules_and_module_interaction/example2/","title":"Python scripting","summary":"Example 2: Python scripting This example shows how to create module interactions via Python scripting.\nSummary A new Macro Module IsoCSOs is created providing 2 viewers in the internal network. One View2D and one SoExaminerViewer. Both viewers are added to the custom user interface of the module.\nAdditional Buttons for Browsing directories and creating contours (CSOIsoGenerator) are added calling Python functions to explain how Python can be used in MeVisLab. In the end, a field listener is implemented calling a Python function whenever a field of the internal network changes.","content":"Example 2: Python scripting This example shows how to create module interactions via Python scripting.\nSummary A new Macro Module IsoCSOs is created providing 2 viewers in the internal network. One View2D and one SoExaminerViewer. Both viewers are added to the custom user interface of the module.\nAdditional Buttons for Browsing directories and creating contours (CSOIsoGenerator) are added calling Python functions to explain how Python can be used in MeVisLab. In the end, a field listener is implemented calling a Python function whenever a field of the internal network changes. This is used to colorize the contours under the mouse.\nDownload The files need to be added to a package. You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/image_processing/example3/","title":"Region Growing (Segmentation)","summary":"Image Processing Example 3: Region Growing (Segmentation) In this example, we create a simple mask on an image by using the RegionGrowing module.\nSummary We are loading images by using the LocalImage module and show them in a SynchroView2D. The same image is used as input for the RegionGrowing module. The starting point for the algorithm is a list of markers created by the SoView2DMarkerEditor. As the RegionGrowing may leave gaps, an additional CloseGap module is added.","content":"Image Processing Example 3: Region Growing (Segmentation) In this example, we create a simple mask on an image by using the RegionGrowing module.\nSummary We are loading images by using the LocalImage module and show them in a SynchroView2D. The same image is used as input for the RegionGrowing module. The starting point for the algorithm is a list of markers created by the SoView2DMarkerEditor. As the RegionGrowing may leave gaps, an additional CloseGap module is added. The resulting segmentation mask is shown as an overlay on the original image via SoView2DOverlay.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/image_processing/example4/","title":"Subtract 3D objects","summary":"Image Processing Example 4: Subtract 3D objects In this example, we subtract a sphere from another WEM.\nSummary We are loading images by using the LocalImage module and render them as a 3D scene in a SoExaminerViewer. We also add a sphere which is then subtracted from the original image.\nDownload You can download the example network here","content":"Image Processing Example 4: Subtract 3D objects In this example, we subtract a sphere from another WEM.\nSummary We are loading images by using the LocalImage module and render them as a 3D scene in a SoExaminerViewer. We also add a sphere which is then subtracted from the original image.\nDownload You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/visualization/example2/","title":"Visualization Example 2: Creating a magnifier","summary":"Visualization Example 2: Creating a magnifier This example shows how to create a magnifier. Using the module SubImage a fraction of the original image can be extracted and enlarged. Download You can download the example network here","content":"Visualization Example 2: Creating a magnifier This example shows how to create a magnifier. Using the module SubImage a fraction of the original image can be extracted and enlarged. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/visualization/example5/","title":"Volume rendering and interactions","summary":"Visualization Example 5: Volume rendering and interactions This example shows the volume rendering of a scan. The texture of the volume is edited and animations are implemented. Download You can download the example network here","content":"Visualization Example 5: Volume rendering and interactions This example shows the volume rendering of a scan. The texture of the volume is edited and animations are implemented. Download You can download the example network here\n","tags":[],"section":"examples"},{"date":"-62135596800","url":"https://mevislab.github.io/examples/examples/data_objects/surface_objects/example5/","title":"WEM - Primitive Value Lists","summary":"Surface Example 5: WEM - Primitive Value Lists This example shows how to use Primitive Value Lists (PVLs). With the help of PVLs the distance between the surfaces of WEMs is color coded. Download You can download the example network here","content":"Surface Example 5: WEM - Primitive Value Lists This example shows how to use Primitive Value Lists (PVLs). With the help of PVLs the distance between the surfaces of WEMs is color coded. Download You can download the example network here\n","tags":[],"section":"examples"}]