<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LUT on MeVisLab Examples</title><link>https://mevislab.github.io/examples/pull/135/tags/lut/</link><description>Recent content in LUT on MeVisLab Examples</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 15 Jun 2022 08:56:33 +0200</lastBuildDate><atom:link href="https://mevislab.github.io/examples/pull/135/tags/lut/index.xml" rel="self" type="application/rss+xml"/><item><title>Example 5: Volume Rendering and Interactions</title><link>https://mevislab.github.io/examples/pull/135/tutorials/visualization/visualizationexample5/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/135/tutorials/visualization/visualizationexample5/</guid><description>&lt;h1 id="TutorialVisualizationExample6"&gt;Example 5: Volume Rendering and Interactions&lt;/h1&gt;
&lt;div class="alert alert-secondary d-flex align-items-center" role="alert"&gt;
 &lt;div&gt;
 &lt;img width="100px" src="images/youtube.svg" /&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://www.youtube.com/watch?v=QViPqXs2LHc" target="_blank"&gt;&lt;img width="100px" src="https://img.youtube.com/vi/QViPqXs2LHc/0.jpg" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on &lt;a href="https://www.youtube.com/watch?v=QViPqXs2LHc" target="_blank"&gt;YouTube&lt;/a&gt;.
 &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this example we like to convert a scan of a head into a 3D scene object. The scene object allows to add some textures, interactions, and animations.&lt;/p&gt;
&lt;h2 id="steps-to-do"&gt;Steps to Do&lt;/h2&gt;
&lt;h3 id="develop-your-network"&gt;Develop Your Network&lt;/h3&gt;
&lt;p&gt;Implement the following network and open the image &lt;em&gt;$(DemoDataPath)/BrainMultiModal/ProbandT1.tif&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;p class="page-image"&gt;
 &lt;a data-modal="bs-lightbox" href="images/tutorials/visualization/V6_01.png" title="SoGVRVolumeRenderer"&gt;&lt;img id="SoGVRVolumeRenderer" class="img-fluid rounded" src="images/tutorials/visualization/V6_01.png" alt="SoGVRVolumeRenderer" title="SoGVRVolumeRenderer" /&gt;&lt;/a&gt;
 &lt;figcaption class="figure-caption"&gt;SoGVRVolumeRenderer&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/p&gt;
&lt;p&gt;The module &lt;code&gt;SoGVRVolumeRenderer&lt;/code&gt; allows volume rendering of 3D and 4D images.&lt;/p&gt;</description></item><item><title>Surface Example 5: WEM - Primitive Value Lists</title><link>https://mevislab.github.io/examples/pull/135/tutorials/dataobjects/surfaces/surfaceexample5/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/135/tutorials/dataobjects/surfaces/surfaceexample5/</guid><description>&lt;h1 id="surface-example-5-wem---primitive-value-lists"&gt;Surface Example 5: WEM - Primitive Value Lists&lt;/h1&gt;
&lt;div class="alert alert-secondary d-flex align-items-center" role="alert"&gt;
 &lt;div&gt;
 &lt;img width="100px" src="images/youtube.svg" /&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://www.youtube.com/watch?v=Rap1RY6l5Cc" target="_blank"&gt;&lt;img width="100px" src="https://img.youtube.com/vi/Rap1RY6l5Cc/0.jpg" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on &lt;a href="https://www.youtube.com/watch?v=Rap1RY6l5Cc" target="_blank"&gt;YouTube&lt;/a&gt;.
 &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;WEMs do not only contain the coordinates of nodes and surfaces, they can also contain additional information. That information is stored in so-called &lt;em&gt;Primitive Value Lists&lt;/em&gt; (PVLs). Every node, every surface, and every edge can contain such a list. In these lists, you can, for example, store the color of the node or specific patient information. This information can be used for visualization or for further statistical analysis.&lt;/p&gt;</description></item></channel></rss>