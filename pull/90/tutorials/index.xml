<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tutorials on MeVisLab Examples</title><link>https://mevislab.github.io/examples/pull/90/tutorials/</link><description>Recent content in Tutorials on MeVisLab Examples</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 11 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://mevislab.github.io/examples/pull/90/tutorials/index.xml" rel="self" type="application/rss+xml"/><item><title>Chapter I: Basic Mechanisms of MeVisLab</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/</link><pubDate>Wed, 15 Jun 2022 08:54:53 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/</guid><description>Basic Mechanics of MeVisLab (Example: Building a Contour Filter) In this chapter you will learn the basic mechanisms of the MeVisLab IDE. You will learn how to re-use existing modules to load and view data and you will build your first processing pipeline.
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Extra Infos:&amp;nbsp; Additional information on the basics of MeVisLab are explained here Loading Data First, we need to load the data we would like to work on, e.</description></item><item><title>Example 1: Data import in MeVisLab</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/dataimport/</link><pubDate>Wed, 15 Jun 2022 08:54:53 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/dataimport/</guid><description>Example 1: Data Import in MeVisLab MeVisLab provides several pre-defined modules to import data for processing in your networks.
Extra Infos:&amp;nbsp; The easiest way to load data in MeVisLab is to drop the file onto the MeVisLab workspace. MeVisLab will try to find a module that is capable of loading your file automatically. These chapters explain the data formats and modules related to this example:
Images DICOM Data Segmentations / 2D Contours 3D Data / Meshes Extra Infos:&amp;nbsp; Detailed explanations on loading images onto your MeVisLab workspace can be found here Images A good option to load images is the ImageLoad module.</description></item><item><title>Example 1.1: MeVisLab Coordinate Systems</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/coordinatesystems/coordinatesystems/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/coordinatesystems/coordinatesystems/</guid><description>Example 1.1: MeVisLab Coordinate Systems Three coordinate systems exist next to each other:
World coordinates Voxel coordinates Device coordinates World coordinate systems in MeVisLab are always right handed.
The blue rectangle shows the same region in the three coordinate systems.
Coordinate Systems in MeVisLab World coordinates World coordinates are:
Global: Combine several objects in a view Isotropic: All directions are equivalent Orthogonal: Coordinate axes are orthogonal to each other The origin of the world coordinate system can be anywhere and is not clearly defined.</description></item><item><title>Example 1.2: DICOM Coordinate Systems</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/coordinatesystems/coordinatesystems2/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/coordinatesystems/coordinatesystems2/</guid><description>Example 1.2: DICOM Coordinate Systems General Coordinate systems in DICOM are basically the same as world coordinates in MeVisLab (except for the 0.5 voxel offset). World coordinates also refer to the patient axes. They are:
Based on the patient&amp;rsquo;s main body axes (transverse, coronal, sagittal) Measured as 1 coordinate unit = 1 millimeter Right-handed Not standardized regarding their origin World Coordinates in Context of the Human Body The DICOM (Digital Imaging and Communications in Medicine) standard defines a data format that groups information into data sets.</description></item><item><title>Example 2: Macro modules and Module Interaction</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/</guid><description>Example 2: Macro modules Macro modules and Module Interactions via User Interface and Python Scripting MeVisLab provides different types of modules, which can be distinguished by their color. The brown modules are called Macro modules. Macro modules condense a whole network into one module. You can open the internal network by pressing the middle mouse button or via right mouse click and select [ Help &amp;rarr; Show Internal Network ]. Macro modules provide the possibility to create customized user interfaces and Python interactions.</description></item><item><title>Example 2.1: Package Creation</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/package/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/package/</guid><description>Example 2.1: Package creation &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction Packages are the way MeVisLab organizes different development projects.
Macro modules and projects are stored in packages. If you like to create a global macro module, you need a package in which this macro module can be stored in. In this chapter, we will create our own package. We start our package creation by creating a package group, because every package needs to be stored in a package group.</description></item><item><title>Example 2.2: Creation of global macro modules</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/globalmacromodules/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/globalmacromodules/</guid><description>Example 2.2: Global macro modules &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this chapter you will learn how to create global macro modules. There are many ways to do this. You can convert local macros into global macro modules or you can directly create global macro modules using the Project Wizard. In contrast to local macro modules, global macro modules are commonly available throughout projects and can be found via module search and under [ Modules ].</description></item><item><title>Example 2.3: Creation of module help</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/helpfiles/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/helpfiles/</guid><description>Example 2.3: Creation of module help Generating help of a macro module is part of the video about macro modules from Example 2: Creation of global macro modules &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this chapter, you will learn how to create a help page and an example network. For hands-on training, we will use the macro module Filter, which was created in the previous chapter.
Depending on the way the macro module was created the default help page and example network might or might not exist.</description></item><item><title>Example 2.4: GUI development</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/guidesign/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/guidesign/</guid><description>Example 2.4: Building a Panel Layout: Interactions with macro modules &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction This chapter will give you an introduction into the creation of module panels and user interfaces. For the implementation you will need to use the MeVisLab Definition Language (MDL) .
Extra Infos:&amp;nbsp; More information about GUI design in MeVisLab can be found here Creating a panel for the macro module flilter Creation of a module panel In Example 2.</description></item><item><title>Example 2.5: Interactions via Python scripting</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/pythonscripting/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/pythonscripting/</guid><description>Example 2.5: Module Interactions Using Python Scripting Introduction This chapter will give you an overview over Python scripting in MeVisLab. Here, no introduction into Python will be given. However, basic knowledge in Python is helpful. Instead, we will show how to integrate and use Python in the MeVisLab SDK.
In fact, nearly everything in MeVisLab can be done via Python scripting: You can add modules to your network, or remove modules, you can dynamically establish and remove connections and so on.</description></item><item><title>Example 2.5.1: The module RunPythonScript</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/scriptingexample1/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/scriptingexample1/</guid><description>Example 2.5.1: The module RunPythonScript &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction The module RunPythonScript allows to execute Python scripts from within a MeVisLab network. You can draw parameter connection from modules to RunPythonScript and back, to process parameter fields using Python scripting.
Steps to do Develop your network In this example, we like to dynamically change the color of a cube in an Open Inventor scene. For that, add and connect the following modules as shown.</description></item><item><title>Example 2.5.2: Module interactions via Python scripting</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/scriptingexample2/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/scriptingexample2/</guid><description>Example 2.5.2: Module interactions via Python scripting &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, you will learn how to add Python scripting to your User Interface. The network used in Chapter V will be used for creating the macro module.
Steps to do Creating the macro module First, we condense the example network into a macro module and then we create a panel for that module. To create a macro module use the Project Wizard, which you find under [ File &amp;rarr; Run Project Wizard ].</description></item><item><title>Example 3: Creating a simple application</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/viewerexample/</link><pubDate>Wed, 15 Jun 2022 08:58:44 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/viewerexample/</guid><description>Example 3: Creating a simple application Introduction In the previous examples, you already learned how to create macro modules, user interfaces and how to interact with your UI via Python scripting.
In this example, you will learn how to create a simple Prototype application in MeVisLab including a User Interface with 2D and 3D viewer. You will learn how to implement field listeners and react on events.
Steps to do Create your network Start with an empty network and add the Module ImageLoad to your workspace.</description></item><item><title>Example 4: Installing additional Python packages using the PythonPip module</title><link>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/pythonpip/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/basicmechanisms/macromodules/pythonpip/</guid><description>Example 4: Installing additional Python packages using the PythonPip module Introduction MeVisLab already comes with a lot of integrated third party software tools ready to use. Nevertheless it might be necessary to install additional Python packages for your specific needs. This example will walk you through the process of adding packages through usage of/using the PythonPip module.
The PythonPip module allows to work with the Python package manager pip. It can be used to install Python packages into the site-packages of the MeVisLab Python installation.</description></item><item><title>Chapter II: Open Inventor</title><link>https://mevislab.github.io/examples/pull/90/tutorials/openinventor/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/openinventor/</guid><description>Open Inventor modules Introduction In total, there are three types of modules:
blue ML modules brown macro modules green Open Inventor modules The names of Open Inventor modules start with the prefix So\* (for Scene Objects). Open Inventor modules process and render 3D scene objects and enable image interactions. Scene objects are transmitted using the semi-circle shaped input and output connectors. With the help of these modules, Open Inventor scenes can be implemented.</description></item><item><title>Example 1: Open Inventor Objects</title><link>https://mevislab.github.io/examples/pull/90/tutorials/openinventor/openinventorobjects/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/openinventor/openinventorobjects/</guid><description>Example 1: Open Inventor Objects &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example we like to construct an Open Inventor scene in which we display three 3D objects of different color and shape.
Steps to do Generating Open Inventor Objects First, add the modules SoExaminerViewer and SoCone to the workspace and connect both modules as shown. The module SoCone creates a cone shaped object, which can be displayed in the Viewer SoExaminerViewer.</description></item><item><title>Example 2: Mouse interactions in Open Inventor</title><link>https://mevislab.github.io/examples/pull/90/tutorials/openinventor/mouseinteractions/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/openinventor/mouseinteractions/</guid><description>Example 2: Mouse interactions in Open Inventor &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we implement some image or object interactions. We will create a 3D scene, in which we display a cube and change its size using the mouse. We also get to know another viewer, the module SoExaminerViewer. This viewer is important. It enables the rendering of Open Inventor scenes and allows interactions with the Open Inventor scenes.</description></item><item><title>Example 3: Camera Interactions in Open Inventor</title><link>https://mevislab.github.io/examples/pull/90/tutorials/openinventor/camerainteraction/</link><pubDate>Wed, 22 Mar 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/openinventor/camerainteraction/</guid><description>Example 3: Camera Interactions in Open Inventor &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we are learning the basic principles of camera interactions in Open Inventor. We will show the difference between a SoRenderArea and a SoExaminerViewer and use different modules of the SoCamera* group.
The SoRenderArea module The module SoRenderArea is a simple renderer for Open Inventor scenes. It offers functionality to record movies and to create snapshots, but does not include an own camera or light.</description></item><item><title>Chapter III: Visualization</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/</guid><description>Visualization in MeVisLab Introduction Images and data objects can be rendered in 2D and 3D and interacted with in several ways using a set of tools available through MeVisLab. In this chapter in particular, we will focus on simple image interaction with two- and three-dimensional visualizations.
Info:&amp;nbsp; Not only pixel- and voxel-based data, but also scene objects and 3D scenes can be visualized. See our tutorial on OpenInventorModules for further information.</description></item><item><title>Example 1: Synchronous view of two images</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample1/</guid><description>Example 1: Synchronous view of two images Introduction In this example we like to use the module SynchroView2D to be able to inspect two different images simultaneously.
The module SynchroView2D provides two 2D viewers that are synchronized.
As in Tutorial Chapter 1 - Basic Mechanics of MeVisLab, the processed and the unprocessed image can be displayed simultaneously. Scrolling through one image automatically changes the slices of both viewers, so slices with the same slice number are shown in both images.</description></item><item><title>Example 2: Creating a magnifier</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample2/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample2/</guid><description>Example 2: Creating a magnifier &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction Medical images are typically displayed in three different viewing directions (see image): coronal, axial and sagittal.
Using the Viewer OrthoView2D you are able to decide, which viewing direction you like to use. In addition to that, you have the opportunity to display all three orthogonal viewing directions simultaneously. Here, we like to display an image of the head in all three viewing directions and mark positions in the image.</description></item><item><title>Example 3: Image Overlays</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample3/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample3/</guid><description>Example 3: How to blend images over each other &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example we will show you how to blend a 2D image over another one. With the help of the module SoView2DOverlay we will create an overlay, which allows us to highlight all bones in the scan.
Steps to do Develop your network Start this example by adding the shown modules, connecting the modules to form a network and loading the example image Bone.</description></item><item><title>Example 4: Display 2D images in Open Inventor SoRenderArea</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample4/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample4/</guid><description>Example 4: Display images converted to Open Inventor scene objects &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In the previous example you learned how to use the module SoView2DOverlay together with a View2D. MeVisLab provides a whole family of SoView2D* modules (SoView2DOverlay, SoView2DRectangle, SoView2DGrid, &amp;hellip;). All these modules create or interact with scene objects and are based on the module SoView2D, which can convert a voxel-image into a scene object.</description></item><item><title>Example 5: Volume rendering and interactions</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample5/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample5/</guid><description>Example 5: Volume rendering and interactions &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example we like to convert a scan of a head into a 3D scene-object. The scene-object allows to add some textures, interactions and animations.
Steps to do Develop your network Implement the following network and open the image $(DemoDataPath)/BrainMultiModal/ProbandT1.tif.
SoGVRVolumeRenderer The module SoGVRVolumeRenderer allows volume rendering of 3D and 4D images.
Extra Infos:&amp;nbsp; Additional information about Volume Rendering can be found here: Giga Voxel Renderer Change LUT We like to add a surface color to the head.</description></item><item><title>Example 6: MeVis Path Tracer</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample6/</link><pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample6/</guid><description>Example 6: MeVis Path Tracer &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;We have a Short video showing the possibilities of the MeVis Path Tracer on YouTube. Introduction The MeVis Path Tracer offers a Monte Carlo Path Tracing framework running on CUDA GPUs. It offers photorealistic rendering of volumes and meshes, physically based lightning with area lights and soft shadows and fully integrates into MeVisLab Open Inventor (camera, depth buffer, clipping planes, etc.).
Extra Infos:&amp;nbsp; CUDA is a parallel computing platform and programming model created by NVIDIA.</description></item><item><title>Example 6.1: Volume Rendering vs. Path Tracer</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/pathtracer/pathtracerexample1/</link><pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/pathtracer/pathtracerexample1/</guid><description>Example 6.1: Volume Rendering vs. Path Tracer Introduction In this example you develop a network to show some differences between volume rendering and the MeVisLab Path Tracer. You will visualize the same scene using both 3D rendering techniques and some of the modules for path tracing.
Attention:&amp;nbsp; The MeVis Path Tracer requires an NVIDIA graphics card with CUDA support. In order to check your hardware, open MeVisLab and add a SoPathTracer module to your workspace.</description></item><item><title>Example 6.2: Visualization using Path Tracer</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/pathtracer/pathtracerexample2/</link><pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/pathtracer/pathtracerexample2/</guid><description>Example 6.2: Visualization using SoPathTracer Introduction In this tutorial, we will explain the basics of using the SoPathTracer module in MeVisLab. You will learn how to create a scene, assign materials, add light sources, and configure the PathTracer to generate enhanced renderings.
Attention:&amp;nbsp; The MeVis Path Tracer requires an NVIDIA graphics card with CUDA support. In order to check your hardware, open MeVisLab and add a SoPathTracer module to your workspace.</description></item><item><title>Example 7: Add 3D viewer to OrthoView2D</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample7/</link><pubDate>Tue, 21 Nov 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample7/</guid><description>Example 7: Add 3D viewer to OrthoView2D Introduction In this example we will use the OrthoView2D module and add a 3D viewer to the layout Cube.
Steps to do Develop your network Add the modules LocalImage and OrthoView2D to your workspace and connect them.
Network The OrthoView2D module allows you to select multiple layouts. Select layout Cube Equal. The layout shows your image in three orthogonal viewing directions. The top left segment remains empty.</description></item><item><title>Example 8: Vessel Segmentation using SoVascularSystem</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample8/</link><pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample8/</guid><description>Example 8: Vessel Segmentation using SoVascularSystem Introduction In this tutorial, we are using an input mask to create a vessel centerline using the DtfSkeletonization module and visualize the vascular structures in 3D using the SoVascularSystem module. The second part uses the distance between centerline and surface of the vessel structures to color thin vessels red and thick vessels green.
Steps to do Develop your network Load the example tree mask by using the LocalImage module.</description></item><item><title>Example 9: Creating Dynamic 3D Animations using AnimationRecorder</title><link>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample9/</link><pubDate>Mon, 08 Jan 2024 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/visualization/visualizationexample9/</guid><description>Example 9: Creating Dynamic 3D Animations using AnimationRecorder Introduction In this tutorial, we are using the AnimationRecorder module to generate dynamic and visually appealing animations of our 3D scenes. We will be recording a video of the results of our previous project, particularly the detailed visualizations of the muscles, bones and blood vessels created using PathTracer.
Steps to do Open the network and files of Example 6.2, add a SoSeparator module and an AnimationRecorder module to your workspace and connect them as shown below.</description></item><item><title>Chapter IV: Image Processing</title><link>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/</guid><description>Image Processing in MeVisLab Digital image processing is the use of a digital computer to process digital images through an algorithm (see Wikipedia).
MeVisLab provides multiple modules for image processing tasks, such as:
Filters Masks Transformations Arithmetics Statistics For details about Image Processing in MeVisLab, see the MeVisLab Documentation In this chapter, you will find some examples for different types of image processing in MeVisLab.</description></item><item><title>Example 1: Arithmetic operations on two images</title><link>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing1/</guid><description>Example 1: Arithmetic operations on two images &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction We are using the Arithmetic2 module to apply basic scalar functions on two images. The module provides 2 inputs for images and 1 output image for the result.
Steps to do Develop your network Add two LocalImage modules to your workspace for the input images. Select $(DemoDataPath)/BrainMultiModal/ProbandT1.dcm and $(DemoDataPath)/BrainMultiModal/ProbandT2.dcm from MeVisLab demo data and add a SynchroView2D to your network.</description></item><item><title>Example 2: Masking images</title><link>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing2/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing2/</guid><description>Example 2: Masking images &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction The background of medical images is black for most cases. In case an image is inverted or window/level values are adapted, these black pixels outside clinical relevant pixels might become very bright or even white.
Being in a dark room using a large screen, the user might be blended by these large white regions.
Image masking is a very good way to select a defined region where image processing shall be applied.</description></item><item><title>Example 3: Region Growing</title><link>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing3/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing3/</guid><description>Example 3: Region Growing &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction A very simple approach to segment parts of an image is the region growing method. A general explanation can be found here.
In this example, you will segment the brain of an image and show the segmentation results as an overlay on the original image.
Steps to do Develop your network Add a LocalImage module to your workspace and select load $(DemoDataPath)/BrainMultiModal/ProbandT1.</description></item><item><title>Example 4: Subtract 3D objects</title><link>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing4/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing4/</guid><description>Example 4: Subtract 3D objects &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we load an image and render it as WEMIsoSurface. Then we create a 3-dimensional SoSphere and subtract the sphere from the initial WEM.
Steps to do Develop your network Add a LocalImage module to your workspace and select load $(DemoDataPath)/BrainMultiModal/ProbandT1.dcm. Add a WEMIsoSurface, a SoWEMRenderer, a SoBackground and a SoExaminerViewer module and connect them as seen below.</description></item><item><title>Example 5: Clip Planes</title><link>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing5/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/image_processing/image_processing5/</guid><description>Example 5: Clip Planes &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we are using the SoGVRDrawOnPlane module to define the currently visible slice from a 2D view as a clip plane in 3D.
Steps to do Develop your network First we need to develop the network to scroll through the slices. Add a LocalImage module to your workspace and select the file ProbandT1 from MeVisLab demo data.</description></item><item><title>Chapter V: Data Objects</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/</guid><description>Data Objects in MeVisLab MeVisLab provides pre-defined data objects, e. g.
Contour Segmented Objects (CSOs) which are three-dimensional objects encapsulating formerly defined contours within images. Surface Objects (Winged Edge Meshes or WEMs) represent the surface of geometrical figures and allow the user to manipulate them. Markers are used to mark specific locations or aspects of an image and allow to process those later on. Curves can print the results of a function as two-dimensional mathematical graphs into a diagram.</description></item><item><title>Contour Objects (CSO)</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contourobjects/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contourobjects/</guid><description>Contour Segmented Objects (CSOs) in MeVisLab Introduction Structure of CSOs MeVisLab provides modules to create contours in images. 3D objects which encapsulate these contours are called Contour Segmented Objects (CSOs).
In the next image, you can see a rectangular shaped CSO. The pink circles you can see are called Seed Points.
Seed Points define the shape of the CSO. In case of a rectangle, you need four Seed Points forming the corners, to define the whole rectangle.</description></item><item><title>Contour Example 1: Creation of Contours</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample1/</guid><description>Contour Example 1: Creation of Contours &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction We like to start with the creation of CSOs. To create CSOs, you need a SoCSO*-Editor. There are several different editors, which can be used to create CSOs (see here). Some of them are introduced in this example.
Steps to do Develop your network For this example, we need the following modules. Add the modules to your workspace, connect them as shown below and load the example image $(DemoDataPath)/BrainMultiModal/ProbandT1.</description></item><item><title>Contour Example 2: Contour Interpolation</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample2/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample2/</guid><description>Contour Example 2: Creating Contours using Live Wire and Interpolation &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we like to create CSOs using the Live Wire Algorithm, which allows semi-automatic CSO creation. The algorithm uses edge detection to support the user creating CSOs.
We also like to interpolate CSOs over slices. That means additional CSOs are generated between manual segmentations based on a linear interpolation.
As a last step, we will group together CSOs of the same anatomical unit.</description></item><item><title>Contour Example 3: 2D and 3D Visualization of Contours</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample3/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample3/</guid><description>Contour Example 3: Overlay Creation and 3D Visualization of Contours &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we&amp;rsquo;d like to use the created CSOs to display an overlay. This allows us to mark one of two lungs. In addition to that, we will display the whole segmented lobe of the lung in a 3D image.
Steps to do Develop your network Use the network from the contour example 2 and add the modules VoxelizeCSO, SoView2DOverlay and View2D to your workspace.</description></item><item><title>Contour Example 4: Annotation of Images</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample4/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample4/</guid><description>Contour Example 4: Annotation of Images &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example we like to calculate the volume of our object, in this case the part of the lung we have segmented.
Steps to do Develop your network and calculate the lung volume Add the module CalculateVolume and SoView2DAnnotation to your workspace and connect both modules as shown. Update the module CalculateVolume, which directly shows the volume of our object.</description></item><item><title>Contour Example 5: Contours and Ghosting</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample5/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample5/</guid><description>Contour Example 5: Visualizing Contours and Images &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we like to automatically create CSOs based on a predefined iso value.
Steps to do Develop your network Add the following modules to your workspace and connect them as shown. Load the example image Bone.tiff.
Automatic creation of CSOs based on the iso value Now, open the panel of CSOIsoGenerator to set the Iso Value to 1200.</description></item><item><title>Contour Example 6: Adding Labels to Contours</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample6/</link><pubDate>Mon, 11 Mar 2024 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/contours/contourexample6/</guid><description>Contour Example 6: Adding Labels to Contours Introduction In this example, we are adding a label to a contour. The label provides information about measurements and about the contour itself. The label remains connected to the contour and can be moved via mouse interactions.
Steps to do Develop your network Add a LocalImage and a View2D module to your workspace and connect them as shown below. Load the file ProbandT1.dcm from MeVisLab demo data.</description></item><item><title>Surface Objects (WEM)</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaceobjects/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaceobjects/</guid><description>Surface Objects (WEMs) Introduction In MeVisLab it is possible to create, visualize, process and manipulate surface objects, also known as polygon meshes. Here, we call surface objects Winged Edge Mesh, in short WEM. In this chapter you will get an introduction into WEMs. In addition, you will find examples on how to work with WEMs. For more information on WEMs take a look at the MeVislab Toolbox Reference . If you like to know which WEM formats can be imported into MeVisLab, take a look at the assimp documentation here.</description></item><item><title>Surface Example 1: Creation of WEMs</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample1/</guid><description>Surface Example 1: Create Winged Edge Mesh out of voxel images and CSOs &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example you will learn how to create a Winged Edge Mesh (WEM). There are several approaches on creating WEMs, a few of them are shown in this example. Instead of creating WEMs, they can also be imported, see chapter Surface Objects (WEM).
Steps to do From image to surface: Generating WEMs out of voxel images At first, we will create a WEM out of a voxel image using the module WEMIsoSurface.</description></item><item><title>Surface Example 2: Processing and Modification of WEM</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample2/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample2/</guid><description>Surface Example 2: Processing and Modification of WEM &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, you will learn how to modify and process WEMs.
Steps to do Develop your network Modification of WEMs Use the module WEMLoad to load the file venus.off. Then add and connect the shown modules. We like to display the WEM venus two times, one time this WEM is modified. You can use the module WEMModify to apply modifications.</description></item><item><title>Surface Example 3: Interactions with WEM</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample3/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample3/</guid><description>Surface Example 3: Interactions with WEM &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In these examples, we are showing 2 different possibilities to interact with a WEM:
Scale, rotate and move a WEM in a scene Modify a WEM in a scene Scale, rotate and move a WEM in a scene We are using a SoTransformerDragger module to apply transformations on a 3D WEM object via mouse interactions.
Add a SoCube and a SoBackground module and connect both to a SoExaminerViewer.</description></item><item><title>Surface Example 4: Interactively moving WEM</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample4/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample4/</guid><description>Surface Example 4: Interactively moving WEM &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we like to interactively move WEMs using SoDragger modules insight a viewer.
Develop your network Interactively translating objects in 3D using SoDragger modules Add and connect the following modules as shown. In the panel of the module WEMInitialize select the Model Octasphere. After that, open the viewer SoExaminerViewer and make sure to select the Interaction Mode.</description></item><item><title>Surface Example 5: WEM - Primitive Value Lists</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample5/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/surfaces/surfaceexample5/</guid><description>Surface Example 5: WEM - Primitive Value Lists &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction WEMs do not only contain the coordinates of nodes and surfaces, they can also contain additional information. These information are stored in so called Primitive Value Lists (PVLs). Every node, every surface and every edge can contains such a list. In these lists, you can for example store the color of the node or specific patient information.</description></item><item><title>Chapter VI: Testing</title><link>https://mevislab.github.io/examples/pull/90/tutorials/testing/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/testing/</guid><description>MeVisLab Tutorial Chapter VI Testing, Profiling and Debugging in MeVisLab The MeVisLab Integrated Development Environment (IDE) provides tools to write automated tests in Python, profile your network performance and to debug your Python code. All of these funtionalities will be addressed in this chapter.
Testing The MeVisLab TestCenter is the starting point of your tests. Select [ File &amp;rarr; Run TestCaseManager ] to open the user interface of the TestCaseManager.</description></item><item><title>Marker Objects</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/markerobjects/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/markerobjects/</guid><description>Markers in MeVisLab In MeVisLab you can equip images and other data objects with markers. In this example you will see how to create, process and use markers.
Creation and Rendering To create markers, you can use a marker editor, for example the SoView2DMarkerEditor. Connect this editor to a viewer as shown below. Now you can interactively create new markers. Connect the module XMarkerListContainer to your marker editor to store markers in a list.</description></item><item><title>Example 1: Distance between Markers</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/markers/markerexample1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/markers/markerexample1/</guid><description>Example 1: Calculating the distance between markers &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we will measure the distance between one position in an image to a list of markers.
Steps to do Develop your network Add the following modules and connect them as shown.
We changed the names of the modules SoView2DMarkerEditor and XMarkerLIstContainer, to distinguish these modules from two similar modules we will add later on.</description></item><item><title>Example 1: Writing a simple test case in MeVisLab</title><link>https://mevislab.github.io/examples/pull/90/tutorials/testing/testingexample1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/testing/testingexample1/</guid><description>Example 1: Writing a simple test case in MeVisLab &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, you will learn how to write an automated test for a simple network using the DicomImport, MinMaxScan and View3D modules. Afterwards, you will be able to write test cases for any other module and network yourself.
Steps to do Creating the network to be used for testing Add the following modules to your workspace and connect them as seen below:</description></item><item><title>Example 2: Profiling in MeVisLab</title><link>https://mevislab.github.io/examples/pull/90/tutorials/testing/testingexample2/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/testing/testingexample2/</guid><description>Example 2: Profiling in MeVisLab &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we are using the MeVisLab Profiler to inspect the memory and CPU consumption of the modules in an example network.
Steps to do Creating the network to be used for profiling You can open any network you like, here we are using the example network of the module MinMaxScan for profiling. Add the module MinMaxScan to your workspace, open the example network via right-click and select [ Help &amp;rarr; Show Example Network ].</description></item><item><title>Example 3: Iterative tests in MeVisLab with Screenshots</title><link>https://mevislab.github.io/examples/pull/90/tutorials/testing/testingexample3/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/testing/testingexample3/</guid><description>Example 3: Iterative tests in MeVisLab &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, you are writing an iterative test. Iterative test functions run a function for every specified input. They return a tuple consisting of the function object called and the inputs iterated over. The iterative test functions are useful if the same function should be applied to different input data. These could be input values, names of input images, etc.</description></item><item><title>Curves</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/curves/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/curves/</guid><description>Curves in MeVisLab Introduction Curves can be used in MeVisLab to print the results of a function as two-dimensional mathematical curves into a diagram.
Curves in MeVisLab In the given example, only modules available in commercial MeVisLab Professional SDK have been used. The non-commercial MeVisLab Standard SDK provides more modules for curves.</description></item><item><title>Example 1: Drawing curves</title><link>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/curves/curvesexample1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/dataobjects/curves/curvesexample1/</guid><description>Example 1: Drawing curves &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, you will draw one or more curves into a diagram and define different styles for the curves.
Steps to do Develop your network A curve requires x- and y-coordinates to be printed. You can use the CurveCreator module as input for these coordinates. The SoDiagram2D draws the curves into a SoRenderArea. You can also define the style of the curves by using the StylePalette module.</description></item><item><title>Chapter VII: Application Development</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/</guid><description>MeVisLab Tutorial Chapter VII Summary This chapter will summarize all previous chapters and you will develop a whole application in MeVisLab. The complete workflow from developing a prototype to delivering your final application to your customer is explained step-by-step.
Prototype to Product Licensing:&amp;nbsp; Some of the features described here will require a separate license. Building an installable executable requires the MeVisLab ApplicationBuilder license. It extends the MeVisLab SDK so that you can generate an installer of your developed macro module.</description></item><item><title>Step 1: Prototyping - Develop your Network</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary1/</link><pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary1/</guid><description>Step 1: Prototyping - Develop your Network &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we will develop a network which fulfills the requirements mentioned on the overview page. The network will be developed by re-using existing modules and defining basic field values.
Steps to do 2D viewer The 2D viewer shall visualize the loaded images. In addition to that, it shall be possible to click into the image to trigger a RegionGrowing algorithm to segment parts of the loaded image based on a threshold.</description></item><item><title>Step 2: Prototyping - Create a macro module</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary2/</link><pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary2/</guid><description>Step 2: Prototyping - Create a macro module &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this example, we encapsulate the previously developed prototype network into a macro module for future application development and automated testing.
Steps to do Make sure to have your *.mlab file from the previous tutorial available.
Package creation Packages are described in detail in Example 2.1: Package creation. If you already have your own package, you can skip this part and continue creating a macro module.</description></item><item><title>Step 3: Prototyping - User Interface and Python scripting</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary3/</link><pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary3/</guid><description>Step 3: Prototyping - User Interface and Python scripting &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In this step, we will develop a user interface and add Python scripting to the macro module you created in Step 2.
Steps to do Develop the User Interface A mockup of the user interface you are going to develop is available here. The interface provides the possibility to load files and shows a 2D and a 3D viewer.</description></item><item><title>Step 4: Review - Automated Tests</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary4/</link><pubDate>Wed, 18 Jan 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary4/</guid><description>Step 4: Review - Automated Tests &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In the previous chapters you developed a macro module with User Interface and Python scripting. In this step you will see how to implement an automated test to verify and validate the Requirements defined in Overview.
Steps to do Create a test network using your macro module Create a new and empty network and save it as *.</description></item><item><title>Step 5: Review - Installer creation</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary5/</link><pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary5/</guid><description>Step 5: Review - Installer creation &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction Your macro module has been tested manually and/or automatically? Then you should create your first installable executable and deliver it to your customer(s) for final evaluation.
Licensing:&amp;nbsp; This step requires a valid MeVisLab ApplicationBuilder license. It extends the MeVisLab SDK so that you can generate an installer of your developed macro module. Free evaluation licenses of the MeVisLab ApplicationBuilder, time-limited to 3 months, can be requested at sales(at)mevislab.</description></item><item><title>Step 6: Refine - Update Application</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary6/</link><pubDate>Fri, 20 Jan 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary6/</guid><description>Step 6: Refine - Update Application &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This example is also available on YouTube. Introduction In previous step you developed an application which can be installed on your customers systems for usage. In this step we are going to integrate simple feedback into our executable and re-create the installer.
We want to show you how easy it is to update your application using MeVisLab.
Your customer requests an additional requirement to define the transparency of your 2D overlay in addition to defining the color.</description></item><item><title>Step 7: Refine - Re-Build Installer</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary7/</link><pubDate>Sat, 21 Jan 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary7/</guid><description>Step 7: Refine - Re-Build Installer Introduction In this step you are re-creating your application installer after changing the UI in previous Step 6: Refine - Update Application.
Steps to do Update the *.mlinstall file You do not need to use the Project Wizard now, because you already have a valid *.mlinstall file. The location should be in your package, under .\Configuration\Installers\TutorialSummary. Open the file in any text editor and search for the $VERSION 0.</description></item><item><title>Extra: Run your application in Browser</title><link>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary8/</link><pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/summary/summary8/</guid><description>Extra: Run your application in Browser Introduction This step explains how to run your developed application in a browser. The MeVisLab network remains the same, only some adaptations are necessary for running any macro module in a browser window.
Licensing:&amp;nbsp; This step requires a valid MeVisLab Webtoolkit license. It extends the MeVisLab SDK so that you can develop web macro modules. Free evaluation licenses of the MeVisLab Webtoolkit, time-limited to 3 months, can be requested at sales(at)mevislab.</description></item><item><title>Chapter VIII: ThirdParty components</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/</guid><description>MeVisLab Tutorial Chapter VIII Using ThirdParty software integrated into MeVisLab MeVisLab is equipped with a lot of useful software right out of the box, like the Insight Segmentation and Registration Toolkit (ITK) or the Visualization Toolkit (VTK). This chapter works as a guide on how to use some of the third party components integrated in MeVisLab for your projects via Python scripting. Additional Information:&amp;nbsp; You will also find instructions to install and use any Python package (e.</description></item><item><title>OpenCV</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/opencv/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/opencv/</guid><description>Open Source Computer Vision Library (OpenCV) Introduction OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library.
This chapter provides some examples how to use OpenCV in MeVisLab.
Other resources You can find a lot of OpenCV examples and tutorials on their website.</description></item><item><title>Example 1: WebCam access with OpenCV</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/opencv/thirdpartyexample1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/opencv/thirdpartyexample1/</guid><description>Example 1: WebCam access with OpenCV Introduction In this example, we are using the PythonImage module and access your WebCam to show the video in a View2D.
Steps to do Creating the network to be used for testing Add the modules to your workspace and connect them as seen below.
Example Network The viewer is empty because the image needs to be set via Python scripting.
Info:&amp;nbsp; More information about the PythonImage module can be found here Create a macro module Now you need to create a macro module from your network.</description></item><item><title>Example 2: Face Detection with OpenCV</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/opencv/thirdpartyexample2/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/opencv/thirdpartyexample2/</guid><description>Example 2: Face Detection with OpenCV Introduction This example uses the OpenCV WebCam Python script and adds a basic face detection.
Info:&amp;nbsp; The Python code used in this example has been taken from Towards Data Science. Steps to do Open Example 1 Add the macro module developed in Example 1 to your workspace.
Download trained classifier XML file Initially you need to download the trained classifier XML file. It is available in the OpenCV GitHub repository.</description></item><item><title>assimp</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/assimp/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/assimp/</guid><description>Asset-Importer-Lib (assimp) Introduction Assimp (Asset-Importer-Lib) is a library to load and process geometric scenes from various 3D data formats.
This chapter provides some examples of how 3D formats can be imported into MeVisLab. In general you always need a SoSceneLoader module. The SoSceneLoader allows to load meshes as Open Inventor points/lines/triangles/faces using the Open Asset Import Library.
SoSceneLoader You can also use the SoSceneWriter module to export your 3D scenes from MeVisLab into any of the output formats listed below.</description></item><item><title>Example 1: 3D Printing in MeVisLab</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/assimp/assimpexample1/</link><pubDate>Wed, 15 Jun 2022 08:56:33 +0200</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/assimp/assimpexample1/</guid><description>Example 1: 3D Printing in MeVisLab Introduction This example uses the assimp library to load a 3D file and save the file as *.stl for 3D printing.
Steps to do Develop your network Add the modules SoSceneLoader, SoBackground and SoExaminerViewer to your workspace and connect them as seen below.
Example Network Open the 3D file Select the file vtkCow.obj from MeVisLab demo data directory. Open SoExaminerViewer and inspect the scene. You will see a 3D cow.</description></item><item><title>PyTorch</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/pytorch/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/pytorch/</guid><description>PyTorch Introduction PyTorch is a machine learning framework based on the Torch library, used for applications such as Computer Vision and Natural Language Processing, originally developed by Meta AI and now part of the Linux Foundation umbrella.
A lot of AI frameworks can be used within MeVisLab. We currently do not provide a preintegrated AI framework though as we try to avoid compatibility issues, and AI frameworks are very fast-moving by nature.</description></item><item><title>Example 1: Installing PyTorch using the PythonPip module</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/pytorch/pytorchexample1/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/pytorch/pytorchexample1/</guid><description>Example 1: Installing PyTorch using the PythonPip module Introduction The module PythonPip allows you to install additional Python packages to be used in MeVisLab.
Warning:&amp;nbsp; You should not use the general Python pip command from a locally installed Python, because MeVisLab will not know these packages and they cannot be used in MeVisLab directly. The module either allows to install packages into the global MeVisLab installation directory, or into your defined user package.</description></item><item><title>Example 2: Brain Parcellation using PyTorch</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/pytorch/pytorchexample2/</link><pubDate>Fri, 30 Jun 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/pytorch/pytorchexample2/</guid><description>Example 2: Brain Parcellation using PyTorch Introduction In this example, you are using a pre-trained PyTorch deep learning model (HighRes3DNet) to perform a full brain parcellation. HighRes3DNet is a 3D residual network presented by Li et al. in On the Compactness, Efficiency, and Representation of 3D Convolutional Networks: Brain Parcellation as a Pretext Task.
Steps to do Add a LocalImage module to your workspace and select the file MRI_Head.dcm. For PyTorch it is necessary to resample the data to a defined size.</description></item><item><title>Example 3: Segment persons in webcam videos</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/pytorch/pytorchexample3/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/pytorch/pytorchexample3/</guid><description>Example 3: Segment persons in webcam videos Introduction This tutorial is based on Example 2: Face Detection with OpenCV. You can re-use some of the scripts already developed in the other tutorial.
Steps to do Add the macro module developed in the previous example to your workspace.
WebCamTest module Open the internal network of the module via middle mouse button and right click on the tab of the workspace showing the internal network.</description></item><item><title>Matplotlib</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/</link><pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/</guid><description>Matplotlib Matplotlib, introduced by John Hunter in 2002 and initially released in 2003, is a comprehensive data visualization library in Python. It is widely used among the scientific world as it is easy to grasp for beginners and provides high quality plots and images, that are widely customizable.
Info:&amp;nbsp; The documentation on Matplotlib along with general examples, cheat sheets and a starting guide can be found here. As MeVisLab supports the integration of Python scripts e.</description></item><item><title>Example 1: Module Setup</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/modulesetup/</link><pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/modulesetup/</guid><description>Example 1: Module Setup Introduction To be able to access the data needed for our grayscale distribution plots, we need a network consisting of a module that imports DICOM data, a module that differentiates between slices and another that ouputs histogram data.
Steps to do Open up your MeVisLab workspace and add the modules LocalImage, SubImage and Histogram to it. Connect the output of LocalImage to the input of SubImage and the output of SubImage with the input of Histogram.</description></item><item><title>Example 2: 2D Plotting</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/2dplotting/</link><pubDate>Tue, 30 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/2dplotting/</guid><description>Example 2: 2D Plotting Introduction In this tutorial, we will equip the macro module we created in the previous tutorial with a responsive and interactable panel to plot grayscale distributions of single slices as well as defined sequences of slices in 2D.
Steps to do Open the module definition folder of your macro module and the related .script file in MATE. Then activate the Preview as shown below:
Drag the small Preview window to the bottom right corner of your window where it does not bother you.</description></item><item><title>Example 3: Slice Comparison</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/slicecomparison/</link><pubDate>Wed, 31 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/slicecomparison/</guid><description>Example 3: Slice Comparison Introduction We will adapt the previously created macro module to be able to overlay two defined slices to compare their grayscale distributions.
The module we are adapting has been set up in the Example 1: Module Setup tutorial. The panel and two dimensional plotting functionality has been added in Example 2: 2D Plotting. Steps to do At first, we will extend the panel: Open your BaseNetwork macro module within an empty MeVisLab workspace and select the .</description></item><item><title>Example 4: 3D Plotting</title><link>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/3dplotting/</link><pubDate>Wed, 31 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/thirdparty/matplotlib/3dplotting/</guid><description>Example 4: 3D Plotting Introduction In this tutorial, we will equip the macro module we created in the Example 1: Module Setup and later on adapted by enabling it to plot grayscale distributions of single slices and sequences in 2D in Example 2: 2D Plotting with a three dimensional plotting functionality.
Steps to do The fields and commands needed have already been prepared in the second tutorial. We will just have to modify our .</description></item><item><title>Tips and Tricks</title><link>https://mevislab.github.io/examples/pull/90/tutorials/shorts/</link><pubDate>Wed, 29 Nov 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/90/tutorials/shorts/</guid><description>MeVisLab Tips and Tricks This chapter shows some features and functionalities which are helpful but do not provide its own tutorial.
Keyboard Shortcuts Using Snippets Scripting Assistant User Scripts Show status of module in- and output Keyboard Shortcuts This is a collection of useful keyboard shortcuts in MeVisLab, hopefully it grows continuously.
Shortcut Functionality Ctrl+1 Automatically arrange selection of modules / in the current network Ctrl+2 Open most recent network file Ctrl+3 Run most recent test case (extremely useful for developers) Ctrl+A then Ctrl+1 Layout network Ctrl+A then Tab Layout .</description></item></channel></rss>