<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PyTorch on MeVisLab Examples</title><link>https://mevislab.github.io/examples/pull/132/tags/pytorch/</link><description>Recent content in PyTorch on MeVisLab Examples</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 30 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://mevislab.github.io/examples/pull/132/tags/pytorch/index.xml" rel="self" type="application/rss+xml"/><item><title>PyTorch</title><link>https://mevislab.github.io/examples/pull/132/tutorials/thirdparty/pytorch/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/132/tutorials/thirdparty/pytorch/</guid><description>&lt;h1 id="pytorch"&gt;PyTorch&lt;/h1&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.pytorch.org" title="pytorch" target="_blank" rel="noopener"&gt;PyTorch&lt;/a&gt; is a machine learning framework based on the Torch library, used for applications such as Computer Vision and Natural Language Processing, originally developed by Meta AI and now part of the Linux Foundation umbrella.&lt;/p&gt;
&lt;p&gt;A lot of AI frameworks can be used within MeVisLab. We currently do not provide a preintegrated AI framework though as we try to avoid compatibility issues, and AI frameworks are very fast-moving by nature.&lt;/p&gt;</description></item><item><title>Example 1: Installing PyTorch Using the PythonPip Module</title><link>https://mevislab.github.io/examples/pull/132/tutorials/thirdparty/pytorch/pytorchexample1/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/132/tutorials/thirdparty/pytorch/pytorchexample1/</guid><description>&lt;h1 id="example-1-installing-pytorch-using-the-pythonpip-module"&gt;Example 1: Installing PyTorch using the PythonPip module&lt;/h1&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The module &lt;code&gt;PythonPip&lt;/code&gt; allows you to install additional Python packages to be used in MeVisLab.&lt;/p&gt;

&lt;svg xmlns="http://www.w3.org/2000/svg" style="display: none;"&gt;
 &lt;symbol id="check-fill" fill="currentColor" viewBox="0 0 16 16"&gt;
 &lt;path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-3.97-3.03a.75.75 0 0 0-1.08.022L7.477 9.417 5.384 7.323a.75.75 0 0 0-1.06 1.06L6.97 11.03a.75.75 0 0 0 1.079-.02l3.992-4.99a.75.75 0 0 0-.01-1.05z"/&gt;
 &lt;/symbol&gt;
 &lt;symbol id="info-fill" fill="currentColor" viewBox="0 0 16 16"&gt;
 &lt;path d="M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16zm.93-9.412-1 4.705c-.07.34.029.533.304.533.194 0 .487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703 0-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381 2.29-.287zM8 5.5a1 1 0 1 1 0-2 1 1 0 0 1 0 2z"/&gt;
 &lt;/symbol&gt;
 &lt;symbol id="warning-fill" fill="currentColor" viewBox="0 0 16 16"&gt;
 &lt;path d="M8.982 1.566a1.13 1.13 0 0 0-1.96 0L.165 13.233c-.457.778.091 1.767.98 1.767h13.713c.889 0 1.438-.99.98-1.767L8.982 1.566zM8 5c.535 0 .954.462.9.995l-.35 3.507a.552.552 0 0 1-1.1 0L7.1 5.995A.905.905 0 0 1 8 5zm.002 6a1 1 0 1 1 0 2 1 1 0 0 1 0-2z"/&gt;
 &lt;/symbol&gt;
 &lt;symbol id="danger-fill" fill="currentColor" viewBox="0 0 16 16"&gt;
 &lt;path d="M8.982 1.566a1.13 1.13 0 0 0-1.96 0L.165 13.233c-.457.778.091 1.767.98 1.767h13.713c.889 0 1.438-.99.98-1.767L8.982 1.566zM8 5c.535 0 .954.462.9.995l-.35 3.507a.552.552 0 0 1-1.1 0L7.1 5.995A.905.905 0 0 1 8 5zm.002 6a1 1 0 1 1 0 2 1 1 0 0 1 0-2z"/&gt;
 &lt;/symbol&gt;
&lt;/svg&gt;

&lt;div class="alert alert-primary alert-warning d-flex align-items-center" role="alert"&gt;
 &lt;svg class="bi flex-shrink-0 me-2" width="24" height="24" role="img" aria-label="Warning:"&gt;&lt;use xlink:href="#warning-fill"/&gt;&lt;/svg&gt;
 &lt;div&gt;
 &lt;b&gt;Warning:&amp;nbsp;&lt;/b&gt;
 You should not use the general Python &lt;em&gt;pip&lt;/em&gt; command from a locally installed Python, because MeVisLab will not know these packages and they cannot be used in MeVisLab directly.
 &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The module either allows to install packages into the global MeVisLab installation directory, or into your defined user package. We will use the user package directory, because then the installed packages remain available in your packages even if you uninstall or update MeVisLab. In addition to that, no administrative rights are necessary if you did install MeVisLab for all users.&lt;/p&gt;</description></item><item><title>Example 2: Brain Parcellation Using PyTorch</title><link>https://mevislab.github.io/examples/pull/132/tutorials/thirdparty/pytorch/pytorchexample2/</link><pubDate>Fri, 30 Jun 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/132/tutorials/thirdparty/pytorch/pytorchexample2/</guid><description>&lt;h1 id="example-2-brain-parcellation-using-pytorch"&gt;Example 2: Brain Parcellation Using PyTorch&lt;/h1&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this example, you are using a pretrained PyTorch deep learning model (HighRes3DNet) to perform a full brain parcellation.&lt;/p&gt;
&lt;p&gt;HighRes3DNet is a 3D residual network presented by Li et al. in &lt;a href="https://link.springer.com/chapter/10.1007/978-3-319-59050-9_28" target="_blank" rel="noopener"&gt;On the Compactness, Efficiency, and Representation of 3D Convolutional Networks: Brain Parcellation as a Pretext Task&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="steps-to-do"&gt;Steps to Do&lt;/h2&gt;
&lt;p&gt;Add a &lt;code&gt;LocalImage&lt;/code&gt; module to your workspace and select the file &lt;em&gt;MRI_Head.dcm&lt;/em&gt;. For PyTorch it is necessary to resample the data to a defined size. Add a &lt;code&gt;Resample3D&lt;/code&gt; module to the &lt;code&gt;LocalImage&lt;/code&gt; and open the panel. Change &lt;em&gt;Keep Constant&lt;/em&gt; to &lt;em&gt;Voxel Size&lt;/em&gt; and define &lt;em&gt;Image Size&lt;/em&gt; as 176, 217, 160.&lt;/p&gt;</description></item><item><title>Example 3: Segment Persons in Webcam Videos</title><link>https://mevislab.github.io/examples/pull/132/tutorials/thirdparty/pytorch/pytorchexample3/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://mevislab.github.io/examples/pull/132/tutorials/thirdparty/pytorch/pytorchexample3/</guid><description>&lt;h1 id="example-3-segment-persons-in-webcam-videos"&gt;Example 3: Segment Persons in Webcam Videos&lt;/h1&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This tutorial is based on &lt;a href="tutorials/thirdparty/opencv/thirdpartyexample2" title="Example 2: Face Detection with OpenCV"&gt;Example 2: Face Detection with OpenCV&lt;/a&gt;. You can reuse some of the scripts already developed in the other tutorial.&lt;/p&gt;
&lt;h2 id="steps-to-do"&gt;Steps to Do&lt;/h2&gt;
&lt;p&gt;Add the macro module developed in the previous example to your workspace.&lt;/p&gt;
&lt;p&gt;&lt;p class="page-image"&gt;
 &lt;a data-modal="bs-lightbox" href="images/tutorials/thirdparty/pytorch_example3_1.png" title="WebcamTest module"&gt;&lt;img id="WebcamTest module" class="img-fluid rounded" src="images/tutorials/thirdparty/pytorch_example3_1.png" alt="WebcamTest module" title="WebcamTest module" /&gt;&lt;/a&gt;
 &lt;figcaption class="figure-caption"&gt;WebcamTest module&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/p&gt;
&lt;p&gt;Open the internal network of the module via middle mouse button 



&lt;img width="22px" src="images/mmb.svg" alt="Middle Mouse Button / Mouse Wheel" /&gt;
 and right-click 


&lt;img width="22px" src="images/rmb.svg" alt="Right Mouse Button" /&gt;

 on the tab of the workspace showing the internal network. Select &lt;em&gt;Show Enclosing Folder&lt;/em&gt;.&lt;/p&gt;</description></item></channel></rss>